{"pages":[{"title":"分类","text":"","link":"/categories/index.html"},{"title":"关于","text":"欢迎邮件来咨询:shaowenxing@dxy.cn","link":"/about/index.html"},{"title":"标签","text":"","link":"/tags/index.html"}],"posts":[{"title":"第一期","text":"如何记录?1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980// 63题func uniquePathsWithObstacles(obstacleGrid [][]int) int { var length = len(obstacleGrid) var leng = len(obstacleGrid[0]) if length == 0 || leng == 0 { return 0 } if obstacleGrid[0][0] == 1 { return 0 } var tmp = make([][]int, length) for i := 0; i &lt; length; i++ { for y := 0; y &lt; leng; y++ { if i == 0 { if obstacleGrid[i][y] == 1 { tmp[i] = append(tmp[i], 0) continue } if y &gt; 0 { if tmp[i][y-1] == 0 { tmp[i] = append(tmp[i], 0) continue } } tmp[i] = append(tmp[i], 1) continue } if y == 0 { if obstacleGrid[i][y] == 1 { tmp[i] = append(tmp[i], 0) continue } if i &gt; 0 { if tmp[i-1][y] == 0 { tmp[i] = append(tmp[i], 0) continue } } tmp[i] = append(tmp[i], 1) continue } if obstacleGrid[i][y] == 1 { tmp[i] = append(tmp[i], 0) continue } tmp[i] = append(tmp[i], tmp[i][y-1]+tmp[i-1][y]) } } return tmp[len(tmp)-1][len(tmp[0])-1]}//64题 最小路径func minPathSum(grid [][]int) int { current := grid[0][0] var length = len(grid) var leng = len(grid[0]) var tmp = make([][]int, length) // 初始化 tmp[0] = append(tmp[0], grid[0][0]) for y := 1; y &lt; leng; y++ { tmp[0] = append(tmp[0], tmp[0][y-1]+grid[0][y]) current = tmp[0][y] } for i := 1; i &lt; length; i++ { for y := 0; y &lt; leng; y++ { if y == 0 { tmp[i] = append(tmp[i], tmp[i-1][y]+grid[i][y]) current = tmp[i][y] continue } if tmp[i-1][y] &gt; tmp[i][y-1] { tmp[i] = append(tmp[i], tmp[i][y-1]+grid[i][y]) } else { tmp[i] = append(tmp[i], tmp[i-1][y]+grid[i][y]) } current = tmp[i][y] } } return current}","link":"/2021/06/09/leetcode/tmp1/"},{"title":"android和nodejs开源镜像","text":"android开源镜像和加速运行虚拟机东软学院镜像 android东软 设置 Android SDK Manager 使用国内镜像12345678910android -&gt; 主界面 -&gt; 点击菜单 &quot;Tools&quot; -&gt; 点击菜单项 &quot;Options...&quot;，弹出窗口： &quot;Android SDK Manager - Settings&quot; : -&gt; 设置 &quot;HTTP Proxy Server&quot; 为 `mirrors.neusoft.edu.cn` -&gt; 设置 &quot;HTTP Proxy port&quot; 为 `80` -&gt; 勾选中 &quot;Force https://... sources to be fetched using http://...&quot; -&gt; 点击 &quot;Close&quot; 按钮 -&gt; 点击菜单 &quot;Packages&quot; -&gt; 点击菜单项 &quot;Reload&quot; 命令行更新123456789查询更新的类目：android list sdk --extended --proxy-host mirrors.neusoft.edu.cn --proxy-port 80 -s更新制定的：android update sdk --no-ui --filter 2 --proxy-host mirrors.neusoft.edu.cn --proxy-port 80 -s安装 id: 2 or &quot;android-21&quot;Android 21 的SDK。安装的时候提示接受license:Do you accept the license 'android-sdk-preview-license-52d11cd2' [y/n]:选择y同意之后继续安装。等待安装成功。使用国内的镜像服务器安装，服务稳定，下载速度快，不需要FQ。注：其中id为32是extra-android-m2repository，android的Support Libraries。 错误 1234567891011121314151617181920212223错误 Cannot run program &quot;/var/lib/jenkins/tools/android-sdk/build-tools/23.0.1/aapt&quot;: error=2, No such file or directory at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048) at com.android.builder.png.AaptProcess$Builder.start(AaptProcess.java:163) at com.android.builder.png.QueuedCruncher$1.creation(QueuedCruncher.java:106) at com.android.builder.tasks.WorkQueue.run(WorkQueue.java:203) at java.lang.Thread.run(Thread.java:745)Caused by: java.io.IOException: error=2, No such file or directory at java.lang.UNIXProcess.forkAndExec(Native Method) at java.lang.UNIXProcess.&lt;init&gt;(UNIXProcess.java:248) at java.lang.ProcessImpl.start(ProcessImpl.java:134) at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029) ... 4 moreThread(png-cruncher_2) has a null payload因为aapt是32的位，不能在64位的系统上面运行，需要安装32位的支持。CentOS: sudo yum install libz.so.1Ubuntu: sudo yum apt-get install lib32z1 （可选），选中 所需的各种 API版本 并下载安装 123456789101112131415-&gt; 点击菜单 &quot;Tools&quot;-&gt; 点击菜单项 &quot;Manage AVDs&quot;，弹出窗口: &quot;Android Virtual Device (AVD) Manager&quot; : -&gt; 点击 &quot;Create&quot; 按钮 -&gt; AVD Name : 随意输入，比如 &quot;test1&quot; -&gt; Device : 比如 &quot;Nexus One (3.7&quot;, 480 x 800: hdpi)&quot; -&gt; Taget : 比如 &quot;Android 4.4.2 - API Level 19&quot; -&gt; CPU/ABI : 通常为 &quot;Intel Atom (x86)&quot; -&gt; Keyboard : 勾选中 &quot;Hardware keyboard present&quot; -&gt; Skin : 选中 &quot;Skin with dynamic hardware controls&quot; -&gt; Front Camera : &quot;None&quot; -&gt; Back Camera : &quot;None&quot; -&gt; Memory Options : RAM : 1024M, VM Heap: 32M -&gt; Internal Sotrage : 2048M -&gt; SD Card : 2048M -&gt; Emulation Options: 选中 &quot;Use Host GPU&quot; Ubuntu 下面模拟器加速: 安装 kvm12345678910111213sudo apt-get install qemu-kvm libvirt-bin ubuntu-vm-builder bridge-utilssudo adduser `whoami` kvmsudo adduser `whoami` libvirtd# 检验是否安装成功sudo virsh -c qemu:///system list# 列出所有的 avdandroid list avd# 选择一个并启动（使用 kvm）# 注意：下面命令中的 &quot;test1&quot; 是 avd 的名称emulator -avd test1 -qemu -m 2047 -enable-kvm nodejs换数据源1npm config set registry https://registry.npm.taobao.org 也可以使用snpm(smart-npm)12345678910111213npm install --global smart-npm --registry=https://registry.npm.taobao.org/Linux 用户可以在 ~/.bashrc 文件中加一行alias npm=smart-npmMac 用户可以在 ~/.bash_profile 文件中加一行alias npm=smart-npm Window 用户需要先定位到 npm.cmd 和 smart-npm.cmd 两个文件，然后用 smart-npm.cmd 替换 npm.cmd（注意备份原来的 npm.cmd），同时注意修改下 smart-npm.cmd 文件里的路径，否则运行 npm 会报找不到文件错误（如果不明白，建议不要替换，直接使用 snpm 或 smart-npm）可以使用命令 where smart-npm 来定位到 smart-npm.cmd 文件所在的位置。如：在我的系统上执行 where smart-npm 的结果是：C:\\Users\\Mora&gt;where smart-npmC:\\Program Files\\nodejs\\smart-npmC:\\Program Files\\nodejs\\smart-npm.cmd同理可以定位到 npm.cmd 的位置卸载npm uninstall --global smart-npm mac无法识别android手机1234插上手机打开终端，输入：system_profiler SPUSBDataType，将输出结果记住。拔下手机，重复以上动作。在终端里输入echo &quot;0x2207&quot; &gt; ~/.android/adb_usb.ini 红色为你的设备VendorIDadb kill-server","link":"/2020/06/23/2019/android/"},{"title":"nodeJs&#x2F;Bower初始化&#x2F;gulp的使用","text":"使用bower的项目初始化npm和bower的作用 npm是主要用来安装各种运行类工具的 bower用来下载类库的 初始化项目 安装nodeJs，不会请看首页进行安装 新建项目进行安装bower: sudo npm install bower -g,(更好的管理可以先:npm init初始化项目) 。请参考 npm –help 安装完成，输入:bower init ;初始化项目。进行完成 例子，安装vue: bower install vue 。这个样下载好了vue.js。 会在当前目录下生成bower_components文件夹，作为下载的文件 为项目配置上gulp : npm install gulp –&gt; 学习：参考网址 gulp使用123456789简单输出一行字，按照上面参考网址中的例子，在任务中输出一句话 先进行 const gutil = require('gulp-util'); 然后在任务中输入:gutil.log('hello word'); var gulp = require('gulp'); const gutil = require('gulp-util'); gulp.task('default', function() { gutil.log('hello word''); });在这里会抛错，找不到gulp-util。这里就要执行:npm install gulp-util,而不是bower，bower是管理js类库的命令行输入gulp 就能看到打印的语句了 npm安装之后出现命令无法运行(windows下比如gulp)123451. 安装路径默认是C盘，当前没有加到path命令导致无法运行。在安装之后都会有安装的目录提示2. 自定义安装目录：npm config set cache &quot;D:\\nodejs\\node_cache&quot;npm config set prefix &quot;D:\\nodejs\\node_global&quot;3. 将global路径放到path中去。可以运行安装的应用了","link":"/2020/06/23/2019/bower/"},{"title":"android开发&#x2F;微信开发&#x2F;android调试","text":"无法安装软件 adb uninstall net.sourceforge.simcpux / 这样可以将手机中的软件删除干净 移动app支付的时候调用起微信客户端的进行sign的key全部是小写，和公众号的不一样，公众号的驼峰标示。 用电脑版Chrome进行调试1231. 准备已就绪，在chrome地址栏输入“chrome://inspect“即可进入调试页面，对应的设备下方会显示chrome打开的网页和手机上打开的App，网页下方的四个按键分别对应审查、置顶、重载和关闭对应网页，右上方的输入框可输入要打开的网页链接。2. 打开的app运行在android4.4以上系统，同时使用的事chrome浏览器内核3. 第一次打开网页的审查会一片空白，这是因为第一次需要翻墙链接 android进行生成签名12345678910keytool -genkeypair \\ -keyalg RSA \\ -keysize 1024 \\ -sigalg SHA1withRSA \\ -dname &quot;CN=www.xxxx.net, OU=R&amp;D, O=\\&quot;xxx xxx Tech Co., Ltd\\&quot;, L=WenZhou, S=Zhejiang, C=CN&quot; \\ -validity 3650 \\ -alias (别名) \\ -keypass (此处是密码) \\ -keystore app.jks \\ -storepass (此处是密码) 签名12345678910jarsigner -keystore app.jks \\ -storepass (此处是上一个填写密码) \\ -storetype jks \\ -keypass AmEd3ERCxEf \\ -digestalg SHA1 \\ -sigalg SHA1withRSA \\ -tsa http://timestamp.digicert.com \\ -signedjar (加密后apk地址)android-release-signed.apk \\ (加密前apk地址)android-release-unsigned.apk \\ (上面填写的别名) 验证1234567jarsigner -verify \\ -keystore app.jks \\ -storetype jks \\ -tsa http://timestamp.digicert.com \\ -digestalg SHA1 \\ -sigalg SHA1withRSA \\ (加密后apk地址)android-release-signed.apk","link":"/2020/06/23/2019/androidDevelop/"},{"title":"jvm性能调试工具调试远程程序","text":"远程调试程序性能 不论使用什么工具调试，都需要jvm开启远程调试功能 本案列使用tomcat运行war包程序进行调试 tomcat开启jvm远程调试 请参考另外一篇文章tomcat设置启动参数，讲解了如何配置tomcat启动参数 在脚本中添加 12345JAVA_OPTS='-Dcom.sun.management.jmxremote.port=8999 -Dcom.sun.management.jmxremote.ssl=false-Dcom.sun.management.jmxremote.authenticate=false' 或者 JAVA_OPTS=’-Dcom.sun.management.jmxremote.port=1099 -Dcom.sun.management.jmxremote.ssl=false-Dcom.sun.management.jmxremote.authenticate=false -Djava.rmi.server.hostname=192.168.1.54 其他配置’ 备注: 123 在Java启动时，JMX会绑定一个接口，RMI也会绑定一个接口，在复杂网络环境下，有可能你通过打开防火墙允许了JMX端口的通过，但是由于没有放行RMI，远程连接也是会失败的。这是因为JMX在远程连接时，会随机开启一个RMI端口作为连接的数据端口，这个端口会被防火墙给阻止，以至于连接超时失败。在Java7u25版本后，可以使用 -Dcom.sun.management.jmxremote.rmi.port参数来指定这个端口；好消息是，你可以将这个端口和jmx.port的端口设置成一个端口，这样防火墙就只需要放行一个端口就可以了。 参数说明 123451. -Dcom.sun.management.jmxremote.port ：这个是配置远程 connection 的端口号的，要确定这个端口没有被占用2. -Dcom.sun.management.jmxremote.ssl=false 指定了 JMX 是否启用 ssl3. -Dcom.sun.management.jmxremote.authenticate=false 指定了JMX 是否启用鉴权（需要用户名，密码鉴权） 2,3两个是固定配置，是 JMX 的远程服务权限的4. -Djava.rmi.server.hostname ：这个是配置 server 的 IP 的","link":"/2020/06/23/2019/JVM%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95/"},{"title":"linux下crontab使用","text":"使用linux带有的crontab 如果没有该命令，自行安装 crontab命令 12345678910111213141516cron服务提供crontab命令来设定cron服务的，以下是这个命令的一些参数与说明: crontab -u //设定某个用户的cron服务，一般root用户在执行这个命令的时候需要此参数 crontab -l //列出某个用户cron服务的详细内容 crontab -r //删除没个用户的cron服务 crontab -e //编辑某个用户的cron服务 比如说root查看自己的cron设置:crontab -u root -l 再例如，root想删除fred的cron设置:crontab -u fred -r 在编辑cron服务时，编辑的内容有一些格式和约定，输入:crontab -u root -e */30 * * * * sh xx/java.sh &gt;&gt; var/logs/ftp_`date +&quot;\\%Y\\%m\\%d&quot;`.log 2&gt;&amp;1 进入vi编辑模式，编辑的内容一定要符合下面的格式:*/1 * * * * ls &gt;&gt; /tmp/ls.txt 任务调度的crond常驻命令 crond 是linux用来定期执行程序的命令。当安装完成操作系统之后，默认便会启动此 任务调度命令。crond命令每分锺会定期检查是否有要执行的工作，如果有要执行的工 作便会自动执行该工作。 新增一条一般使用 crontab -u xx -e ；这里编辑的是该用户的定时任务 编辑完后重启，将会开始运行","link":"/2020/06/23/2019/crontab/"},{"title":"docker开发","text":"docker运行docker的安装1一个大写的略过 docker 登陆1sudo docker login --username=xxxxx@qq.com registry.cn-hangzhou.aliyuncs.com docker自动构建gitHub项目(阿里云为例子) 先github或者阿里云git创建项目:以下为例子 进入阿里云开发者;登陆，创建我的镜像进入我的镜像仓库 选择创建镜像仓库 这里会要求建立一个密码，用于登陆docker使用，这里会先以账户名建立一个namespace。 下面选择阿里云Code创建，构建设置可以设置：代码自动构建，不使用缓存 1自动构建是在代码有变动的时候会重新编译镜像。 使用代码构件，最顶层要有一个Dockerfile文件，会按照该文件进行构件 进入详细信息，里面就会列举下载地址，包括如下下载，并且重新发布 配置固定的ip第一步：安装最新版的Docker备注：操作系统自带的docker的版本太低，不支持静态IP，因此需要自定义安装。root@localhost:# apt-get updateroot@localhost:# apt-get install curlroot@localhost:# curl -fsSL https://get.docker.com/ | shroot@localhost:# docker -vDocker version 1.10.3, build 20f81dd 第二步：创建自定义网络备注：这里选取了172.18.0.0网段，也可以指定其他任意空闲的网段docker network create –subnet=172.18.0.0/16 shadownet注：shadown为自定义网桥的名字，可自己任意取名。 第三步：在你自定义的网段选取任意IP地址作为你要启动的container的静态IP地址备注：这里在第二步中创建的网段中选取了172.18.0.10作为静态IP地址。这里以启动shadowsocks为例。docker run -d -p 2001:2001 –net shadownet –ip 172.18.0.10 oddrationale/docker-shadowsocks -s 0.0.0.0 -p 2001 -k 123456 -m aes-256-cfb 其他备注1：这里是固定IP地址的一个应用场景的延续，仅作记录用，可忽略不看。备注2：如果需要将指定IP地址的容器出去的请求的源地址改为宿主机上的其他可路由IP地址，可用iptables来实现。比如将静态IP地址172.18.0.10出去的请求的源地址改成公网IP104.232.36.109(前提是本机存在这个IP地址)，可执行如下命令：iptables -t nat -I POSTROUTING -o eth0 -d 0.0.0.0/0 -s 172.18.0.10 -j SNAT –to-source 104.232.36.109 121. 获取docker容器的IP使用命令:docker inspect 容器ID2. 然后过虑出 IPAddress 即可查看 Docker 的IP :docker inspect 容器ID | grep IPAddress 容器修改后创建镜像推送，阿里云为例 sudo docker commit [容器的名字] [nameSpace]/[名字]:[版本] 1注： 这里已经创建了一个新的image镜像文件 推送到阿里云上面，需要重新命名 1234$ sudo docker login --username=xxx xxx$ sudo docker tag [ImageId] xxx:[镜像版本号]$ sudo docker push xxx:[镜像版本号]其中xxx请参考自己的仓库的信息 docker容器和主机互相拷贝文件121.容器到主机 docker cp &lt;containerId&gt;:/file/path/within/container /host/path/target2. 主机到容器，反过来就可以 docker容器启动1234567 1. docker run -dti -p 11:11 -v E:/worke:/data --name nginx --restart always nginxId 2. 使用在Docker run的时候使用--restart参数来设置。 3. no - container：不重启 / on-failure - container:退出状态非0时重启 / always:始终重启 4. -d 后台启动 -t -i ? / -p 映射的端口 / -v 挂载的目录 / --name 重定义名字 5. 一个gitlab的例子: docker run -t -i --detach --hostname 10.2.2.189 --publish 8443:443 --publish 80:80 --publish 8022:22 --name gitlab --restart always --volume /home/le/gitlab/config:/etc/gitlab --volume /home/le/gitlab/logs:/var/log/gitlab --volume /home/le/gitlab/data:/var/opt/gitlab --privileged=true registry.cn-hangzhou.aliyuncs.com/lab99/gitlab-ce-zh(22和443端口经常会被占用，这里看自己的情况修改) docker mq启动1234567891011121314151617docker run --name='activemq' -d \\-e 'ACTIVEMQ_NAME=amqp-srv1' \\-e 'ACTIVEMQ_REMOVE_DEFAULT_ACCOUNT=true' \\-e 'ACTIVEMQ_ADMIN_LOGIN=admin' -e 'ACTIVEMQ_ADMIN_PASSWORD=fJbbIDUzllkv' \\-e 'ACTIVEMQ_WRITE_LOGIN=producer_login' -e 'ACTIVEMQ_WRITE_PASSWORD=TgVodjA1WYoR' \\-e 'ACTIVEMQ_READ_LOGIN=consumer_login' -e 'ACTIVEMQ_READ_PASSWORD=YRq49Vz6kv3X' \\-e 'ACTIVEMQ_JMX_LOGIN=jmx_login' -e 'ACTIVEMQ_JMX_PASSWORD=3RincOQObyK5' \\-e 'ACTIVEMQ_STATIC_TOPICS=topic1;topic2;topic3' \\-e 'ACTIVEMQ_STATIC_QUEUES=queue1;queue2;queue3' \\-e 'ACTIVEMQ_MIN_MEMORY=1024' -e 'ACTIVEMQ_MAX_MEMORY=4096' \\-e 'ACTIVEMQ_ENABLED_SCHEDULER=true' \\-v /data/activemq:/data/activemq \\-v /var/log/activemq:/var/log/activemq \\-p 8161:8161 \\-p 61616:61616 \\-p 61613:61613 \\docker.io/webcenter/activemq 容器挂载目录权限不够1加上 --privileged=true 参数，给与容器特殊权限 docker pull镜像很慢 因为pull直接是国外的镜像，docker hub在中国没有cdn分发。 阿里云开发者 使用阿里云的镜像加速，在阿里云开发者注册帐号。在控制台-&gt;docker镜像仓库-&gt;加速器 在这里会有每个人的专属加速的url网址，下面有介绍如何使用 docker镜像 容器转成镜像： 1sudo docker commit &lt;CONTAINER ID&gt; imagename01 容器转成文件： 1sudo docker export &lt;CONTAINER ID&gt; &gt; /home/export.tar 镜像转成文件： 12sudo docker save imagename01 &gt; /home/save.tar注：一般情况下，save.tar比export.tar大一点点而已，export比较小，因为它丢失了历史和数据元metadata 文件转成镜像： 1cat /home/export.tar | sudo docker import - imagename02:latest save.tar文件转成镜像： 1docker load &lt; /home/save.tar 注： save和export的区别是 save会记录历史，export只记录当前的镜像查看转成的镜像：sudo docker images","link":"/2020/06/23/2019/docker/"},{"title":"es父子文档","text":"es join概念 es父子文档在6.x后已经变更了说明。去掉了type:parent 改为join概念 es官网文档链接地址 特别申明，join中注意routing字段。routing参数是强制的，就会抛出错误。123IndexRequest request = new IndexRequest(INDEX, TYPE,i) .source(map) .routing(&quot;2&quot;); 在嵌套的文档中，实际情况是所有内部的对象集中在同一个分块中的Lucene文档，这对于对象便捷地连接根文档而言，是非常有好处的。父子文档则是完全不同的ES文档，所以只能分别搜索它们，效率更低。对于文档的索引、更新和删除而言，父子的方式就显得出类拔萃了。这是因为父辈和子辈文档都是独立的ES文档，各自管理。举例来说，如果一个分组有很多活动，要增加一个新活动，那么就是增加一篇新的活动文档。如果使用嵌套类型的方式，ES不得不重新索引分组文档，来囊括新的活动和全部已有活动，这个过程就会更慢。","link":"/2020/06/23/2019/elasticleftjoin/"},{"title":"elasticsearch附加参数含义(持续补充)","text":"可选参数： 1234567891011121314keep_first_letter启用此选项时，例如：刘德华&gt; ldh，默认值：truekeep_separate_first_letter启用该选项时，将保留第一个字母分开，例如：刘德华&gt; l，d，h，默认：假的，注意：查询结果也许是太模糊，由于长期过频limit_first_letter_length 设置first_letter结果的最大长度，默认值：16keep_full_pinyin当启用该选项，例如：刘德华&gt; [ liu，de，hua]，默认值：truekeep_joined_full_pinyin当启用此选项时，例如：刘德华&gt; [ liudehua]，默认值：falsekeep_none_chinese 在结果中保留非中文字母或数字，默认值：truekeep_none_chinese_together保持非中国信一起，默认值：true，如：DJ音乐家- &gt; DJ，yin，yue，jia，当设置为false，例如：DJ音乐家- &gt; D，J，yin，yue，jia，注意：keep_none_chinese必须先启动keep_none_chinese_in_first_letter第一个字母保持非中文字母，例如：刘德华AT2016- &gt; ldhat2016，默认值：truekeep_none_chinese_in_joined_full_pinyin保留非中文字母加入完整拼音，例如：刘德华2016- &gt; liudehua2016，默认：falsenone_chinese_pinyin_tokenize打破非中国信成单独的拼音项，如果他们拼音，默认值：true，如：liudehuaalibaba13zhuanghan- &gt; liu，de，hua，a，li，ba，ba，13，zhuang，han，注意：keep_none_chinese和keep_none_chinese_together应首先启用keep_original 当启用此选项时，也会保留原始输入，默认值：falselowercase 小写非中文字母，默认值：truetrim_whitespace 默认值：trueremove_duplicated_term当启用此选项时，将删除重复项以保存索引，例如：de的&gt; de，默认值：false，注意：位置相关查询可能受影响","link":"/2020/06/23/2019/elasticsearchproperties/"},{"title":"fastdfs安装测试","text":"安装略过配置tracker 进入到 /etc/fdfs 目录下，复制模版文件tracker.conf.sample到 tracker.conf 创建数据文件和日志文件目录：mkdir -pv /data/fastdfs/tracker 编辑 tracker.conf 文件，测试的时候只需要修改以下参数即可12345disabled=false #启用配置文件port=22122 #设置 tracker 的端口号base_path=/data/fastdfs/tracker #设置 tracker 的数据文件和日志目录（需预先创建）http.server_port=8080 #设置 http 端口号 这个http.server_port=8080 指的是在tracker服务器上启动http服务进程，如:apache或者nginx 启动时所监听的端口，这个似乎是可以不用管的，因为tracker本身就没有安装http服务 运行tracker直接使用 fdfs_trackerd 来启动tracker进程，然后使用netstat 查看端口是否起来。 [root@wangyinxiang fdfs]# fdfs_trackerd /etc/fdfs/tracker.conf restart 配置storage 进入到 /etc/fdfs 目录下，复制/usr/fastdfs/fastdfs-5.05/conf/* 下面的所有文件到当前目录下(/etc/fdfs) 编辑配置文件 storage.conf 测试的时候，只需修改以下内容即可：12345678910复制代码 [root@wangyinxiang /etc/fdfs]# vim storage.conf disabled=false#启用配置文件 group_name=group1 #组名，根据实际情况修改 port=23000 #设置 storage 的端口号 base_path=/data/fastdfs/storage #设置 storage 的日志目录（需预先创建） store_path_count=1 #存储路径个数，需要和 store_path 个数匹配 store_path0=/data/fastdfs/storage #存储路径 tracker_server=10.1.20.245:22122 #tracker 服务器的 IP 地址和端口号 http.server_port=8080 #设置storage上启动的http服务的端口号，如安装的nginx的端口号 运行：1[root@wangyinxiang /etc/fdfs]# fdfs_storaged /etc/fdfs/storage.conf restart 查看端口是否起来123[root@wangyinxiang /etc/fdfs]# netstat -antp | grep storagetcp 0 0 0.0.0.0:23000 0.0.0.0:* LISTEN 10333/fdfs_storagedtcp 0 0 10.1.20.245:57886 10.1.20.245:22122 ESTABLISHED 10333/fdfs_storaged 可以使用 fdfs_monitor 来查看一下storage的状态，看是否已经成功注册到了tracker123fdfs_monitor /etc/fdfs/storage.conf也可以以下命令来监控服务器的状态：fdfs_monitor /etc/fdfs/client.conf 注：看到ACTIVE,就说明已经成功注册到了tracker。 测试 客户端上传文件 FastDFS安装包中，自带了客户端程序，通过程序可以进行文件上传。在使用这个客户端程序之前，首先需要配置client.conf，然后再进行文件上传及下载。 a、修改/etc/fdfs/client.conf文件,修改如下：12345base_path=/home/yuqing/fastdfs--&gt; base_path=/home/soar/fastdfs_tracker tracker_server=192.168.209.121:22122 --&gt; tracker_server=10.1.20.245:22122 (ip根据自己本机的处理)http.tracker_server_port=80 -&gt;http.tracker_server_port=8080 #支持http##include http.conf -&gt;#include http.conf 进入/usr/local/bin/目录，上传文件，执行 12sudo fdfs_test /etc/fdfs/client.conf upload a.txt 注：a.txt可以在/usr/local/bin/目录下自己创建一个 如果命令行反馈类似如下： 说明上传完成。","link":"/2020/06/23/2019/fastdfs/"},{"title":"git常用命令&#x2F;git windows工具使用&#x2F;mac","text":"Git常用命令分支合并和rebase1234567git merge &lt;branch&gt; # 将branch分支合并到当前分支git merge origin/master --no-ff # 不要Fast-Foward合并，这样可以生成merge提交git rebase master &lt;branch&gt; # 将master rebase到branch，相当于： git co &lt;branch&gt; &amp;&amp; git rebase master &amp;&amp; git co master &amp;&amp; git merge &lt;branch&gt;git cherry-pick &lt;commit id&gt; # 合并单个commit到当前的分支当中 Git补丁管理(方便在多台机器上开发同步时用)12345git diff &gt; ../sync.patch # 生成补丁git apply ../sync.patch # 打补丁git apply --check ../sync.patch #测试补丁能否成功 Git暂存管理1234567git stash # 暂存git stash list # 列所有stashgit stash apply # 恢复暂存的内容git stash drop # 删除暂存区 Git远程分支管理1234567891011121314151617181920212223git pull # 抓取远程仓库所有分支更新并合并到本地git pull --no-ff # 抓取远程仓库所有分支更新并合并到本地，不要快进合并git fetch origin # 抓取远程仓库更新git merge origin/master # 将远程主分支合并到本地当前分支git co --track origin/branch # 跟踪某个远程分支创建相应的本地分支git co -b &lt;local_branch&gt; origin/&lt;remote_branch&gt; # 基于远程分支创建本地分支，功能同上git push # push所有分支git push origin master # 将本地主分支推到远程主分支git push -u origin master # 将本地主分支推到远程(如无远程主分支则创建，用于初始化远程仓库)git push origin &lt;local_branch&gt; # 创建远程分支， origin是远程仓库名git push origin &lt;local_branch&gt;:&lt;remote_branch&gt; # 创建远程分支git push origin :&lt;remote_branch&gt; #先删除本地分支(git br -d &lt;branch&gt;)，然后再push删除远程分支 Git远程仓库管理123456789GitHubgit remote -v # 查看远程服务器地址和仓库名称git remote show origin # 查看远程服务器仓库状态git remote add origin git@ github:robbin/robbin_site.git # 添加远程仓库地址git remote set-url origin git@ github.com:robbin/robbin_site.git # 设置远程仓库地址(用于修改远程仓库地址) git remote rm &lt;repository&gt; # 删除远程仓库 创建远程仓库12345678910111213141516171819git clone --bare robbin_site robbin_site.git # 用带版本的项目创建纯版本仓库scp -r my_project.git git@ git.csdn.net:~ # 将纯仓库上传到服务器上mkdir robbin_site.git &amp;&amp; cd robbin_site.git &amp;&amp; git --bare init # 在服务器创建纯仓库git remote add origin git@ github.com:robbin/robbin_site.git # 设置远程仓库地址git push -u origin master # 客户端首次提交git push -u origin develop # 首次将本地develop分支提交到远程develop分支，并且trackgit remote set-head origin master # 设置远程仓库的HEAD指向master分支也可以命令设置跟踪远程库和本地库git branch --set-upstream master origin/mastergit branch --set-upstream develop origin/develop windows中git工具sourceTree的使用 在电脑中先要安装git windows版本 点此下载 sourceTree可以百度去其他下载站下载，官网有被强同时安装的时候要输入google账户，下载站的关闭后在打开后就不需要了 安装完后要在windows中生成ssh key。鼠标右键桌面点击git base here，弹出命令框 命令框中键入命令：ssh-keygen -t rsa -C “email@email.com“，在你的用户目录就会生成 .ssh文件夹 打开id_rsa.pub文件，在你需要上传的git上添加ssh key sourceTree打开-&gt;工具-&gt;选项-&gt;ssh客户端配置，选择ssh链接。sourceTree的ssh配置完成。接下来可以克隆新建仓库了 git远程分支的操作12345678910111213141516171819git branch &lt;branch&gt; //创建新的分支git checkout &lt;branch&gt; //就可以进入新的分支git push origin &lt;branch&gt; // 将新的分支推上远程git push origin :&lt;branch&gt; // 删除远程分支git branch -d &lt;branch&gt; // 删除本地分支 ** git pull 提示拉哪个分支代码 ** git pull origin &lt;branch&gt; // 可以使用这个命令，也可以使用下一行代码直接固定 **git branch --set-upstream-to=origin/&lt;branch&gt;删除未提交的文件# 删除 untracked filesgit clean -f# 连 untracked 的目录也一起删掉git clean -fd# 连 gitignore 的untrack 文件/目录也一起删掉 （慎用，一般这个是用来删掉编译出来的 .o之类的文件用的）git clean -xfd# 在用上述 git clean 前，墙裂建议加上 -n 参数来先看看会删掉哪些文件，防止重要文件被误删git clean -nxfdgit clean -nfgit clean -nfd git中文路径名或者文件名被转义1git config --global core.quotepath false // 将转义设为关闭 git添加tag标签12git tag -a v2.0.0 -m &quot;商城更改重大版本&quot;git push origin --tag // 将本地的tag标签进行全部推送 git添加的分支要对应远程1git branch --set-upstream-to=origin/2.0.x 2.0.x gitk出现错误123456789101112Error in startup script: unknown color name &quot;lime&quot; (processing &quot;-fore&quot; option) invoked from within&quot;$ctext tag conf m2 -fore [lindex $mergecolors 2]&quot; (procedure &quot;makewindow&quot; line 347) invoked from within&quot;makewindow&quot; (file &quot;/usr/local/bin/gitk&quot; line 12434)方法1:brew cask install tcl (未测试)方法2:cp /usr/local/bin/gitk /usr/local/bin/gitk.bkp vi /usr/local/bin/gitk :%s/lime/&quot;#99FF00&quot;/g","link":"/2020/06/23/2019/git/"},{"title":"windows下使用git命令","text":"在windows是使用git 在windows的git bash中用ssh-keygen -t rsa -C “XXX@company.com“生成了密钥对 这样会在c/Users/[用户组]/.ssh/id_rsa下面生成ssh文件","link":"/2020/06/23/2019/gitWindows/"},{"title":"gitlib备份sh脚本","text":"gitLib定时备份代码 在备份的电脑创建git账户。useradd gitlib 。生成ssh密钥放入gitlib中 编写sh脚本 12345678910111213141516171819202122#!/bin/sh# 用来定时备份test12的git代码# 当前shell脚本所在的目录TIME=&quot;date +%Y-%m-%d.%H:%M:%S&quot;DIR=&quot;$( cd &quot;$( dirname &quot;${BASH_SOURCE[0]}&quot; )&quot; &amp;&amp; pwd )&quot;# 获取gitlib上的需要备份的项目PROJECT=(xxx zzz yyy)# 遍历上面的项目，确保在一组当中for DATA in ${PROJECT[@]} do DIR=&quot;$( cd &quot;$( dirname &quot;${BASH_SOURCE[0]}&quot; )&quot; &amp;&amp; pwd )&quot; echo &quot;`$TIME` ----$DATA开始进行备份 $DIR&quot;; if [ -d $DIR/$DATA ]; then cd $DIR/$DATA back=`git pull` cd $DIR else back=`git clone git@git.kingsilk.xyz:kingsilk/$DATA.git` #echo &quot;xxx&quot; fi done; 执行 chmod +x script.sh赋予执行权限 gitlib定时拉取代码 表示每小时执行一次备份 12crontab -e0 * * * * /home/gitlib/back/gitLibBack.sh 2&gt;&amp;1 &gt;&gt; /home/gitlib/back/gitLibBack.log gitlab命令 123456789docker run --detach \\ --hostname 10.2.2.189 \\ --publish 7043:443 --publish 7070:80 --publish 7022:22 \\ --name gitlabs \\ --restart always \\ --volume /srv/gitlab/config:/etc/gitlab \\ --volume /srv/gitlab/logs:/var/log/gitlab \\ --volume /srv/gitlab/data:/var/opt/gitlab \\ registry.cn-hangzhou.aliyuncs.com/acs-sample/gitlab-sameersbn:latest","link":"/2020/06/23/2019/gitlibBack/"},{"title":"gitlab-runner配置使用","text":"gitlab-runner是和gitlab紧密结合的构建工具，本篇文章使用docker进行构建(docker自己参考百度) jenkins是很流行的可以和很多其他工具结合的一个构建工具。 gitlab-runner看名字就知道只和gitlab结合。 docker pull镜像速度很慢 参考 文档 关于gitlab-ci 网上一搜很多关于安装gitlab-ci和gitlab-runner。 这里我说下，新版gitlab从8.0以上起，就已经集成了gitlab-ci。不需要额外安装。只需要安装gitlab-runner docker安装gitlab，最新的版本 docker pull sameersbn/gitlab:latest (官方镜像) 运行gitlab，443 22端口经常会冲突。这里我替换掉了，个人看情况使用 123456789docker run --detach \\ --hostname ipxxx.xxx.xx \\ --publish 7043:443 --publish 7070:80 --publish 7022:22 \\ --name gitlabs \\ --restart always \\ --volume /srv/gitlab/config:/etc/gitlab \\ --volume /srv/gitlab/logs:/var/log/gitlab \\ --volume /srv/gitlab/data:/var/opt/gitlab \\ sameersbn:latest 更详细参考gitlab配置github docker安装gitlab-runner docker pull gitlab/gitlab-runner 运行gitlab-runner 1234docker run -d --name gitlab-runner --restart always \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -v /srv/gitlab-runner/config:/etc/gitlab-runner \\ gitlab/gitlab-runner:latest 详细参考docker-gitlab-runner 配置Gitlab Runner 进入gitlab-runner容器里面 要在gitlab中添加一个runner，只需要执行:gitlab-runner register 进行注册管道 1234567891011121314151617gitlab-runner registerPlease enter the gitlab-ci coordinator URL (e.g. https://gitlab.com )## 输入你的gitlab地址 在gitlab项目的设置中查看pipelines中的url。不是项目的urlPlease enter the gitlab-ci token for this runner## gitlab的token(在gitlab的Admin Area中) 或者仓库的token(仓库-&gt;设置-&gt;Runner)Please enter the gitlab-ci description for this runner## Runner描述信息Please enter the gitlab-ci tags for this runner (comma separated):## Runner的标签 可以指定仓库 只使用固定标签的Runner构建Whether to run untagged builds [true/false]:[false]: ## 这里我选择true，意思是是否在打了tag的运行。false是在tag上运行，true提交了就可以使用该管道编译Whether to lock Runner to current project [true/false]:[false]: ## 是否锁住管道，暂时没弄明白 false 吧Please enter the executor: parallels, shell, ssh, virtualbox, docker+machine, docker-ssh+machine, docker, docker-ssh, kubernetes:docker ## 这里我们选择shell 先来个简单的Runner registered successfully. Feel free to start it, but if it's running already the config should be automatically reloaded! 上面的图形说明 gitlab-runner配置好了。在要项目的根路径添加.gitlab-ci.yml 才会运行 简单的运行 123456789101112131415161718before_script: - echo &quot;before_script&quot;# 定义 stagesstages: - build - test# 定义 jobjob1: stage: test script: - echo &quot;I am job1&quot; - echo &quot;I am in test stage&quot;# 定义 jobjob2: stage: build script: - echo &quot;I am job2&quot; - echo &quot;I am in build stage&quot; 项目推上去就可以看到编译的结果打印输入上面的echo 这里我多写的只是如何使用，可以参考概念说明，2者结合能够真正掌握它的意思gitlab-runner的概念说明","link":"/2020/06/23/2019/gitlab-runner/"},{"title":"java开发文档规范","text":"代码添加注释 文档参考处groovy doc文档 以下自己见解 12345678910111213141516171819202122/** * 在此处添加对整个类的大致说明 * 添加@符后面会直接添加到文档的说明处 * @version 1.0 */class Person { /** 在这里添加对属性的注释 */ String name /** * 对方法的说明，此行开始到@param处一直是方法的说明 * * @param otherPerson ;对参数名的解释，请加(;)符号分割， * @return 简单的renturn介绍，到后面都是return的介绍 * @return 这里也算return的介绍，但是会换行。也可以不加，建议加 * @throws 方法抛出的异常 */ String greet(String otherPerson) { // 在方法体内注册 使用 //；使用/** xxx */会是注释和下一个方法无法绑定， &quot;Hello ${otherPerson}&quot; }} disruptor","link":"/2020/06/23/2019/groovyDoc/"},{"title":"grails3开发","text":"grails3开发gradle的依赖本地项目1234注：gradle 在我们国内有时候快有时候慢，gradle是google的项目grails引入其他项目做为依赖项目，官网介绍在专门的一张plugins中--&gt;在主工程目录settings.gradle 添加 include '额外工程名',还有includeFlat。include/includeFlat 意思都是引入，但是层级不一样。自行学习--&gt;在build.gradle中添加compile project(':额外工程名') gradle的学习 代码csdn地址1234567新建gradleTestOne，gradleTestTwo作为子项目，用于多模块构建，为了方便，作为子节点存在，使用include引用。不使用includeFlat创建java项目：格式如下:└── src └── main └── java └── OneTestIDEA在右侧栏有gradle project的窗口，可以提供快捷的操作，不需要在命令行执行gradle build，run命令 grails2升级grails3123456789101112问题1:org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'redisMessageListenerContainer' defined in class path resource [org/springframework/session/data/redis/config/annotation/web/http/RedisHttpSessionConfiguration.class]: Unsatisfied dependency expressed through constructor argument with index 0 of type [org.springframework.data.redis.connection.RedisConnectionFactory]: No qualifying bean of type [org.springframework.data.redis.connection.RedisConnectionFactory] is defined: expected single matching bean but found 2: redisConnectionFactory,jedisConnectionFactory; nested exception is org.springframework.beans.factory.NoUniqueBeanDefinitionException: No qualifying bean of type [org.springframework.data.redis.connection.RedisConnectionFactory] is defined: expected single matching bean but found 2: redisConnectionFactory,jedisConnectionFactory解决:grails3是不是不支持resouce注入 1. 在src/main/groovy/ @EnableRedisHttpSession // &lt;1&gt; public class Config { @Bean public JedisConnectionFactory connectionFactory() { JedisConnectionFactory jedisConnectionFactory = new JedisConnectionFactory(); return jedisConnectionFactory; // &lt;2&gt; } } 2. 记得在init/Application上加上@ComponentScan(&quot;上面文件路径包名&quot;) grails3的domain时候save不出错误日志1failOnError: true","link":"/2020/06/23/2019/grailsGradle/"},{"title":"idea的一些常用设置","text":"idea的一些常用设置 更改背景颜色 12File-&gt;settings-&gt;editor-&gt;colors&amp;Fonts-&gt;General右边复制一份，选择：Text-&gt;Default text 勾选background 选择199 237 204；RGB：#C7EDCC 更换提示按键 1234File-&gt;settings-&gt;keyMap 右边选择eclipse 同时点击保存复制修改代码提示按键：点击搜索 1. 移除原来的Cycle Expand Word 的 Alt+斜杠 快捷键绑定。 2. 在 Basic 上点击右键,去除原来的 Ctrl+空格 绑定,然后添加 Alt + 斜杠 快捷键。 更换字体 12File-&gt;settings-&gt;editor-&gt;colors&amp;Fonts-&gt;Fontsize：16 字体：courier New 项目清空缓存 12File -&gt; Invalidate cachesBuild-&gt;Reubuild Project 关闭面板1搜索ctrl+W 去除掉，选择：editor tabs-&gt;close添加ctrl+w","link":"/2020/06/23/2019/idea/"},{"title":"idea中调试tomcat代码","text":"idea中调试Tomcat源代码 代码跟踪时tomcat进入的代码有时候会错误。和正在使用tomcat不符合。在pom下新增以下代码进行指定123456&lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat&lt;/groupId&gt; &lt;artifactId&gt;tomcat-catalina&lt;/artifactId&gt; &lt;version&gt;8.5.35&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt;","link":"/2020/06/23/2019/ideaDebugTomcat8/"},{"title":"ios推送证书的设置","text":"苹果推送证书设置为你的 App 创建 App IDiOS 中每个 App 都需要对应一个 App ID，同一个公司可能会使用类似于 com.example.* 这样通用的 App ID，但是如果要在 App 中加入消息推送功能，那么是不能使用通用 ID 的，需要为之单独创建一个。 首先登陆 iOS Dev Center ，然后进入 Member Center，然后选择 Certificates，Identifiers &amp; profiles，如下图：然后点击下图红框中的任意条目，进入证书界面，如下图:在进入证书界面后，在左边的Identifiers选择中选定App IDs，点右上角加号创建Appid，如下图：在创建 App ID 的过程中，需要勾选 Push 服务，如下图:进入提交页面，push服务处于configurable状态，如下图:点击submit后到确认页面，如下图:点击done后到初始页面，然后再次选择自己创建的appid，如下图:在下图中选择edit按钮，配置推送的环境，如图:然后配置好对应的推送环境，个人版和企业版的开发环境都是选择创建Development SSL Certificate类型的。个人版和企业版的发布环境。发布环境分以下三种：1. in-house必须是企业开发账户（企业内）（299美金） 2.ad-hoc个人账户或公司Company账户（99美金），但只用于内部测试（总共100个设备）.3.上线Appstore只能是个人账户或公司Company账户（99美金））如下图:如果你是为已有的 App 增加消息推送功能，那么打开原有的 App ID，开启 Push Notification 选项即可。流程跟上面的一样。 创建及下载证书点击 Create Certificate按钮后会出现“About Creating a Certificate Signing Request (CSR)”，如下图：到了这里，需要停下制作 CSR 文件，制作过程比较简单，下面是制作的过程。打开 Mac 系统软件’钥匙串访问’，选择 ‘证书助理’ 及 ‘从证书颁发机构请求证书’，制作 CSR 文件，如下图:生成证书后，返回到 “About Creating a Certificate Signing Request (CSR)” 的界面，点击 continue，然后在 “Choose File” 选择生成的CSR文件，最后点击 Generate，生成证书。如下图:在证书制作已经完成。下载并双击用“钥匙串访问” 程序打开后，在左边一栏，上面选择登录，下面选择证书，然后选择刚刚打开的证书，切记不要展开它，直接右击导出p12，如下图：将文件保存为 .p12 格式，输入密码，如图所示：最后进入终端，到证书目录下，运行以下命令将p12文件转换为pem证书文件： 1openssl pkcs12 -in MyApnsCert.p12 -out MyApnsCert.pem -nodes 提示需要输入密码，输入刚才导出 p12 时的密码即可。 生成appProvisioning Profile的创建 点击下图的+按钮开始创建profile选择profile的环境选择创建profile的appid和开发者证书，并选择设备，最后生成profile最后下载profile配置到xcode中进行开发测试 iOS推送简介12345678在 iOS 设备上（模拟器无法使用推送），系统收到通知后这样处理：在屏幕上弹出一些选项，或者在屏幕顶部显示横幅（banner）如下图左App 的角标数值发生变化，具体表现为 App icon 右上角的小红点及数字，如邮件中的红点伴随推送消息的提示声音当应用处于前台运行时，系统是不会在屏幕上显示通知，但是仍会调用相应的 API。只有真机可以使用推送功能。 推送证书验证 通知的两种推送环境 12在使用 iOS 远程推送功能时，有两种不同的环境。开发环境（Development）以及生产环境（Production）。App 当前使用的推送环境与 Xcode - Build Settings - Code Signing - Provisioning Profile 文件的模式一致。 证书与证书校验 12345678910111213141516171819与 APNs 之间是加密的连接，因此需要使用证书来加密连接。每个的推送环境有自己单独的推送证书，即开发证书和生产证书。在将证书最终转为 pem 格式后，可通过与 APNs 连接来测试证书是否有效。开发环境：openssl s_client -connect gateway.sandbox.push.apple.com:2195 -cert MyApnsDev.pem生产环境：openssl s_client -connect gateway.push.apple.com:2195 -cert MyApnsPro.pem当输入完命令回车后，终端首先会输出很多相关信息。当连接建立失败时，会直接 close 掉。当连接建立成功时，终端会停止输出，并等待你输入，你可以随便输入一些字符后摁回车，然后连接才会关闭。\u0001","link":"/2020/06/23/2019/iphoneAPN/"},{"title":"centos安装docker","text":"centos安装dockercentos内核低于3.8处理，通过yum安装 第一步，先看目前的内核版本 uname -r 第二步，导入public key: rpm –import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org 第三步，安装ELRepo: rpm -Uvh http://www.elrepo.org/elrepo-release-6-6.el6.elrepo.noarch.rpm 第四步，安装内核 123在yum的ELRepo源中，有mainline（4.6）、long-term（3.10）这2个内核版本，考虑到long-term更稳定，会长期更新，所以选择这个版本。查看ELRepo源中内核：http://elrepo.org/linux/kernel/el6/x86_64/RPMS/安装命令： yum --enablerepo=elrepo-kernel install kernel-lt -y 第五步，编辑grub.conf，修改Grub引导顺序 1vim /etc/grub.conf 确认刚安装好的内核在哪个位置，然后设置default值（从0开始），一般新安装的内核在第一个位置，所以设置default=0。 第六步，重启，查看内核版本号 参考资料：http://elrepo.org/tiki/tiki-index.php","link":"/2020/06/23/2019/installDocker/"},{"title":"iptables删除规则","text":"删除iptables的规则第一种办法 iptables -t nat -L -n –line-numbers (|grep [端口/ip]) 查看当前有几条规则 iptables -t nat -D PREROUTING 1 删除序列号为1的规则 第二种办法（第一种我试过有时候没用） iptables-save &gt;/tmp/somefile vim /tmp/somefile 找到对应的nat规则 iptables-restore &lt; /tmp/somefile","link":"/2020/06/23/2019/iptables/"},{"title":"java使用jni调用本地","text":"Java调用JNI调用过程 首先需要java的方法需要native 做修饰。 通过javac和javah生成.h文件。 通过c++编程生成dll文件 加载生成的DLL库文件.(后面代码详细讲解) 先看看java代码(分是否package)。这里是没有package的123456789101112import java.util.Map;public class NativeOfficeConverter { /** * 将 * @param path 需要转换的文件路径 * @param outDir 输出的文件目录 * @return 转换后的文件目录 * key有3个: code path imgPath * code不等于200 转换失败。等于200 path转换后的目录，等于传入的outDir。imgPath等同于path。可自定义 */ public native Map&lt;String,String&gt; docToHtmlConvert(String path,String outDir);} javac -encoding UTF-8 NativeOfficeConverter.java javah NativeOfficeConverter // 别加class后缀。 .h文件就生成了 有package的 javah com.test.NativeOfficeConverter 1这个命令需要在同com平级的目录上执行，同时.h文件会生成在当前目录。javah中有一个-d可以指定。看help 生成dll库 放入到java系统中123456// 加载生成的DLL库文件static { // 2选1 load加载的是全路径。loadLibrary需要dll文件放入到系统环境变量中。预先已经加载 System.loadLibrary(&quot;LibJniTest&quot;); System.load(&quot;LibJniTest&quot;);}","link":"/2020/06/23/2019/javajniclass/"},{"title":"java中doc转html,poi openoffice libreoffice","text":"doc转htmlPOI，Office，libreoffice，openoffice linux中无法调用windows的office组件来进行转换。微软office组件解析最佳 linux下libreoffice解析最佳 poi工具适用于简单转换。无法兼容doc下的数学公式。只对普通文本有效果 openoffice存在同样与poi一样的问题。结论：windows下可以使用libreoffice 微软office。linux只有libreoffice libreoffice在java中使用 libreoffice链接 安装步骤。 大写的省略 安装完成后需要启动监听端口: soffice -headless -accept=”socket,port=8100;urp;” 部分电脑可能需要输入：soffice -headless -accept=”socket,host=127.0.0.1,port=8100;urp;” -nofirststartwizard java中使用 百度的结果 123456781. 引入maven：--------------------- &lt;dependency&gt; &lt;groupId&gt;com.artofsolving&lt;/groupId&gt; &lt;artifactId&gt;jodconverter&lt;/artifactId&gt; &lt;version&gt;2.2.2&lt;/version&gt; &lt;/dependency&gt;注： com.artofsolving 已经不维护。maven仓库版本最高只有2.2.1 。而且不支持docx的解析。2.2.2需要自己去其他地方下载---------------------------- artofsolving已经代码公开，目前已经由org.jodconverter 接手 123456maven引入： &lt;dependency&gt; &lt;groupId&gt;org.jodconverter&lt;/groupId&gt; &lt;artifactId&gt;jodconverter-local&lt;/artifactId&gt; &lt;version&gt;4.2.2&lt;/version&gt; &lt;/dependency&gt; github连接地址:https://github.com/sbraconnier/jodconverter","link":"/2020/06/23/2019/javaDocToHtmlAndOffice/"},{"title":"jenkins安装和gitlib hooks配置","text":"jenkins安装 docker pull xxx jenkins配置gitlibhooks Jenkins插件安装 1234567891011Jenkins其实没有什么需要特别配置的，由于这次任务中需要利用Jenkins与git，gitlab协作，所以需要安装一些插件。在主面板上点击Manage Jenkins -&gt; Manage Plugins。由于公司使用代理连接外网，首先需要为Jenkins插件安装配置proxy。点击Advanced标签即进入proxy设置页面。Aailable标签下就是可以安装的插件。要让Jenkins可以自动build git repo中的代码，需要安装GIT Client Plugin和GIT Plugin。要想Jenkins可以收到Gitlab发来的hook从而自动build，需要安装 Gitlab Hook Plugin。要让Jenkins可以在build完成之后根据TAP（test anything protocol）文件生成graph，需要安装 TAP Plugin。 安装gitlib-hooks地址 安装gitlib-hooks报错 jenkins在安装Git hook plugins提示失败: OS : CentOS 6.5 64位 Jenkins : 1.638 JDK : 1.8.0_66 Ruby-runtime : 0.13 问题 : gitlab hook plugin无法安装的原因是因为ruby-runtime无法安装. &lt;!--hexoPostRenderEscape:&lt;figure class=&quot;highlight plaintext&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;java.io.IOException: Failed to dynamically deploy this plugin&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at hudson.model.UpdateCenter$InstallationJob._run(UpdateCenter.java:1308)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at hudson.model.UpdateCenter$DownloadJob.run(UpdateCenter.java:1107)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at java.util.concurrent.FutureTask.run(Unknown Source)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at hudson.remoting.AtmostOneThreadExecutor$Worker.run(AtmostOneThreadExecutor.java:104)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at java.lang.Thead.run(Unknown Source)&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;:hexoPostRenderEscape--&gt; 解决办法: 看上去是在下载过程中文件出现了问题. 首先关闭Jenkins.找到jenkins主目录下面的插件目录,我的目录在/home/web/.jenkins/plugins, 删除相关文件gitlab-hook.jpi和ruby-runtime.jpi 重启jenkins, 试着重新安装.还是无法安装成功,报错信息,应该是下载文件的网络问题:手动下载相关的文件,现在地址在这里, 找到相关的插件,然后选择版本.下载到本地 进入jenkins的系统设置-&gt;插件管理-&gt;高级-&gt;上传插件,把下载到本地文件的插件上传到jenkins的服务器进行安装. ruby文件比较大，直接上传可能会抛错，可以直接下载，放到${host}/jenkins/plugins中，然后重启 还是报错: &lt;!--hexoPostRenderEscape:&lt;figure class=&quot;highlight plaintext&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;52&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;java.io.IOException: Failed to dynamically deploy this plugin&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at hudson.model.UpdateCenter$InstallationJob._run(UpdateCenter.java:1328)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at hudson.model.UpdateCenter$DownloadJob.run(UpdateCenter.java:1126)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at java.util.concurrent.FutureTask.run(FutureTask.java:266)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at hudson.remoting.AtmostOneThreadExecutor$Worker.run(AtmostOneThreadExecutor.java:110)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at java.lang.Thread.run(Thread.java:745)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Caused by: java.io.IOException: Failed to install ruby-runtime plugin&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at hudson.PluginManager.dynamicLoad(PluginManager.java:487)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at hudson.model.UpdateCenter$InstallationJob._run(UpdateCenter.java:1324)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;... 5 more&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Caused by: java.io.IOException: Failed to initialize&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at hudson.ClassicPluginStrategy.load(ClassicPluginStrategy.java:441)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at hudson.PluginManager.dynamicLoad(PluginManager.java:478)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;... 6 more&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Caused by: java.lang.ClassCircularityError: org/jruby/RubyClass&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at java.lang.Class.forName0(Native Method)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at java.lang.Class.forName(Class.java:348)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at org.jenkinsci.bytecode.ClassWriter.loadClass(ClassWriter.java:97)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at org.jenkinsci.bytecode.ClassWriter.getCommonSuperClass(ClassWriter.java:64)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at org.kohsuke.asm5.ClassWriter.getMergedType(ClassWriter.java:1654)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at org.kohsuke.asm5.Frame.merge(Frame.java:1426)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at org.kohsuke.asm5.Frame.merge(Frame.java:1374)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at org.kohsuke.asm5.MethodWriter.visitMaxs(MethodWriter.java:1475)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at org.kohsuke.asm5.tree.MethodNode.accept(MethodNode.java:833)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at org.kohsuke.asm5.commons.JSRInlinerAdapter.visitEnd(JSRInlinerAdapter.java:187)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at org.jenkinsci.bytecode.Transformer$1$1.visitEnd(Transformer.java:107)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at org.kohsuke.asm5.MethodVisitor.visitEnd(MethodVisitor.java:877)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at org.kohsuke.asm5.ClassReader.readMethod(ClassReader.java:1021)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at org.kohsuke.asm5.ClassReader.accept(ClassReader.java:693)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at org.kohsuke.asm5.ClassReader.accept(ClassReader.java:506)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at org.jenkinsci.bytecode.Transformer.transform(Transformer.java:113)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at hudson.ClassicPluginStrategy$AntClassLoader2.defineClassFromData(ClassicPluginStrategy.java:800)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at jenkins.util.AntClassLoader.getClassFromStream(AntClassLoader.java:1310)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at jenkins.util.AntClassLoader.findClassInComponents(AntClassLoader.java:1366)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at jenkins.util.AntClassLoader.findClass(AntClassLoader.java:1326)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at jenkins.util.AntClassLoader.loadClass(AntClassLoader.java:1079)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at java.lang.ClassLoader.loadClass(ClassLoader.java:357)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at org.jenkinsci.jruby.RubyClassConverter.&amp;lt;init&amp;gt;(RubyClassConverter.java:12)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at org.jenkinsci.jruby.JRubyXStream.register(JRubyXStream.java:25)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at ruby.RubyRuntimePlugin.initRubyXStreams(RubyRuntimePlugin.java:44)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at ruby.RubyRuntimePlugin.start(RubyRuntimePlugin.java:28)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at hudson.ClassicPluginStrategy.startPlugin(ClassicPluginStrategy.java:449)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;at hudson.ClassicPluginStrategy.load(ClassicPluginStrategy.java:438)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;... 7 more&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;网上继续寻找问题,在Jenkins的官网找到一个issue, 描述的就是这个问题. Phellipe Ribeiro最后给出了一个在CentOS的临时解决方案:&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;编辑Jenkins的配置文件 /etc/sysconfig/jenkins 的JENKINS_JAVA_OPTIONS&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;修改后 : JENKINS_JAVA_OPTIONS=&amp;quot;-Djava.awt.headless=true -Dhudson.ClassicPluginStrategy.noBytecodeTransformer=true&amp;quot;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;:hexoPostRenderEscape--&gt; 如果安装没有问题，或者已经修好了，可以重新gitlib-hooks插件 在gitLab项目中添加web hook(Project Settings –&gt; WebHooks)原文参考地址 &lt;!--hexoPostRenderEscape:&lt;figure class=&quot;highlight plaintext&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;gitlab的web hook有很多种，可以满足不同的需求，因为我们的需求是push代码的时候触发，所以选的是Push events.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Url的作用:这个地方填的url是gitlab发请求用的。其实它的原理就是当开发人员在git上的操作触发这个hook时，gitlab就向这个url发一个post请求。请求中带着一堆参数比如提交者是谁，提交的分支是哪个，commit号是多少等等。接受这个请求的那端可以利用这些信息去处理后续的一些事情，比如部署测试通知等等。&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;此处，由于我们在jenkins上安装了gitlab hook插件，所以我们只需要按照它的使用方法在url里填上以下链接即可：&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;http://your-jenkins-server/gitlab/notify_commit&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;:hexoPostRenderEscape--&gt; 在jenkins里需要自动触发的job里的“源码管理”部分添加设置，如下图。填好git仓库url和需要检测的分支名称","link":"/2020/06/23/2019/jenkins/"},{"title":"java自定义calssloader","text":"自定义classloder自定义之前需要熟悉的双亲委派机制 双亲委派是为了保证jvm同时只存在一个Object对象。都由父类加载。父类无法找到才由子类进行查找 但在web容器中：如tomcat 不能使用这种。每个war包由自己的jar包。这时候就要进行容器隔离。 所有classloader都有父类加载器。但不是父类。由方法parent指定。 顶级的Boostrap ClassLoader：这个是由c++实现的，所以在方法区并没有Class对象的实例存在。用于加载JAVA_HOME/bin目录下的jar包 扩展类加载器（Extension ClassLoader）：它负责用于加载JAVA_HOME/lib/ext目录中的，或者被java.ext.dirs系统变量指定所指定的路径中所有类库，开发者可以直接使用扩展类加载器。java.ext.dirs系统变量所指定的路径的可以通过程序来查看。System.getProperty(“java.ext.dirs”) 应用程序类加载器（Application ClassLoader）：负责加载用户类路径上指定的类库。开发者可以直接使用这个类加载器。ps：在没有指定自定义类加载器的情况下，这就是程序的默认加载器。 自定义类加载器（User ClassLoader）： 123456loadClass()和findClass()方法区别: 自定义时候覆盖loadClass()方法可以保证同一个类存在多份。自行实现类加载 findClass()方法还是先由先由父类进行加载，查看是否加载多。没有加载在交由子类。 场景一：tomcat容器隔离。这时候需要覆盖loadClass()。同一个war包会有同样一个jar包，可以版本不同，能够同时存在.findClass()则无法处理。再一次加载后查看缓存已经存在直接进行加载。场景二:tomcat中servlet-api.jar以及公共jar包。这个需要在jvm中只有一份。就需要只覆盖findClass()。 tomcat有不同的clasloader加载不同的场景 自定义classloader 代码链接","link":"/2020/06/23/2019/javaClassLoader/"},{"title":"jmeter测试工具","text":"使用jmeter进行压力测试使用jmeter 建立请求，这里就不写了。 压力测试 使用压力测试有一列(aggregate graph) 123 聚合报告如下图所示，每一列的含义分别表示请求名称，请求总数，请求的平均响应时间（毫秒），50%的请求的响应时间，90%的请求的响应时间，95%的请求的响应时间，99%的请求的响应时间，最小的响应时间，最大的响应时间，错误的请求率（错误请求数/总的请求数），吞吐量（每秒处理的请求数），接收的字节速率，发送的字节速率","link":"/2020/06/23/2019/jmetertest/"},{"title":"jre添加https证书","text":"自己新建https证书，以及使用其他人的https 自己新建证书：输入如下命令：keytool -genkey -alias ssodemo -keyalg RSA -keysize 1024 -keypass zhoubang -validity 365 -keystore E:\\zhoubang.keystore -storepass 123456中间的内容参数自己替换 123456789101112各参数含义：-genkeypair 生成密钥-keyalg 指定密钥算法，这时指定RSA,-keysize 指定密钥长度，默认是1024位,这里指定2048，长一点，我让你破解不了（哈哈...）,-siglag 指定数字签名算法，这里指定为SHA1withRSA算法-validity 指定证书有效期，这里指定36500天，也就是100年，我想我的应用用不到那么长时间-alias 指定别名，这里是ssodemo -keystore 指定密钥库存储位置，这里存在d盘-dname 指定用户信息，不用一个一个回答它的问题了；【注意】：第一个让你输入的“您的名字与姓氏是什么”，请必须输入在C:\\Windows\\System32\\drivers\\etc\\hosts文件中加入的服务端的域名。我这里也就是server.zhoubang85.com，为何这么做？首先cas只能通过域名来访问，不能通过ip访问，同时上方是生成证书，所以要求比较严格，所以如果不这么做的话，及时最终按照教程配置完成，cas也可以正常访问,访问一个客户端应用虽然能进入cas验证首页，但是，当输入信息正确后，cas在回调转入你想访问的客户端应用的时候，会出现No subject alternative names present错误异常信息，这个错误也就是在上面输入的第一个问题答案不是域名导致、或者与hosts文件配置的不一致导致。 导出数字证书:在cmd下输入如下命令：keytool -exportcert -alias cas.server.com -keystore d:/tomcat.keystore -file d:/tomcat.cer -rfc 1导出数字证书，即根据刚才生成的tomcat.keystore文件生成一个tomcat.cer文件，在生成的过程中输入的密码也是123456 配置tomcat的https证书 123456789101112配置cas服务器tomcat将tomcat中server.xml中的连接器配置改为：&lt;Connector port=&quot;8443&quot; protocol=&quot;org.apache.coyote.http11.Http11Protocol&quot; maxThreads=&quot;150&quot; SSLEnabled=&quot;true&quot; scheme=&quot;https&quot; secure=&quot;true&quot; clientAuth=&quot;false&quot; sslProtocol=&quot;TLS&quot; keystoreFile=&quot;tomcat.keystore&quot; keystorePass=&quot;123456&quot;/&gt; 同时将生成的tomcat.keystore复制到tomcat的主目录下，即与conf目录在同一个目录下;启动tomcat，然后访问https://cas.server.com:8443/cas 可以访问的只是有警告，因为浏览器没有进行证书认证。我们可以将生成的tomcat.cer导入到浏览器中，不导入也可以；如果要导入的，各个浏览器不导也步骤大体相似，以IE浏览器为例：点击 工具-&gt;Internet选项-&gt;内容-&gt;证书-&gt;受信任的根证书颁发机构-&gt;导入-&gt;下一步-&gt;浏览-&gt;选择d:/tomcat.cer-&gt;下一步,一路确认下去，直到证书导入成功。如果导入在受信任的根证书颁发机构 中可以找到名字为cas.server.com的证书. 至此cas服务器商配置完毕. 证书导入java中的cacerts证书库：keytool -import -alias cacerts -keystore {java路径\\jre\\lib\\security\\cacerts} -file {证书路径.cer} -trustcacerts 123此时命令行会提示你输入cacerts证书库的密码， 你敲入changeit就行了，这是java中cacerts证书库的默认密码， 你自已也可以修改的。 以后更新时，先删除原来的证书，然后导入新的证书 keytool -list -keystore cacerts keytool -delete -alias akazam_email -keystore cacerts keytool -import -alias akazam_email -file akazam_email.cer -keystore cacerts -trustcacerts 使用网站上的证书时候 123456进入某个https://www.xxx.com开头的网站,把要导入的证书下载过来， 在该网页上右键 &gt;&gt; 属性 &gt;&gt; 点击&quot;证书&quot; &gt;&gt; 再点击上面的&quot;详细信息&quot;切换栏 &gt;&gt; 再点击右下角那个&quot;复制到文件&quot;的按钮 就会弹出一个证书导出的向导对话框，按提示一步一步完成就行了。 例如：保存为abc.cer,放在C盘下","link":"/2020/06/23/2019/jreHttps/"},{"title":"java性能调试工具","text":"jvm中常用工具和命令 jstack – 如果Java程序崩溃生成core文件，jstack工具可以用来获得core文件的java stack和native stack的信息，从而可以轻松地知道java程序是如何崩溃和在程序何处发生问题。另外，jstack工具还可以附属到正在运行的java程序中，看到 当时运行的java程序的java stack和native stack的信息, 如果现在运行的java程序呈现hung的状态，jstack是非常有用的。目前只有在Solaris和Linux的JDK版本里面才有。 jconsole – jconsole是基于Java Management Extensions (JMX)的实时图形化监测工具，这个工具利用了内建到JVM里面的JMX指令来提供实时的性能和资源的监控，包括了Java 程序的内存使用，Heap size, 线程的状态，类的分配状态和空间使用等等。 jvisualvm-最新出现的功能强大的工具 jinfo – jinfo可以从core文件里面知道崩溃的Java应用程序的配置信息，目前只有在Solaris和Linux的JDK版本里面才有。 jmap – jmap 可以从core文件或进程中获得内存的具体匹配情况，包括Heap size, Perm size等等，目前只有在Solaris和Linux的JDK版本里面才有。 jdb – jdb 用来对core文件和正在运行的Java进程进行实时地调试，里面包含了丰富的命令帮助您进行调试，它的功能和Sun studio里面所带的dbx非常相似，但 jdb是专门用来针对Java应用程序的。 jstat – jstat利用了JVM内建的指令对Java应用程序的资源和性能进行实时的命令行的监控，包括了对Heap size和垃圾回收状况的监控等等。 jps – jps是用来查看JVM里面所有进程的具体状态, 包括进程ID，进程启动的路径等等。 具体使用 jmap的使用.pid 使用ps命令获取 1234567891. 查看整个JVM内存状态 jmap -heap [pid]要注意的是在使用CMS GC 情况下，jmap -heap的执行有可能会导致JAVA 进程挂起2. 查看JVM堆中对象详细占用情况jmap -histo [pid]3. 导出整个JVM 中内存信息jmap -dump:format=b,file=文件名 [pid] jstat的具体使用 option： 参数选项 -t： 可以在打印的列加上Timestamp列，用于显示系统运行的时间 -h： 可以在周期性数据数据的时候，可以在指定输出多少行以后输出一次表头 vmid： Virtual Machine ID（ 进程的 pid） interval： 执行每次的间隔时间，单位为毫秒 count： 用于指定输出多少次记录，缺省则会一直打印 option 可以从下面参数中选择 123456789101112-class 显示ClassLoad的相关信息；-compiler 显示JIT编译的相关信息；-gc 显示和gc相关的堆信息；-gccapacity 显示各个代的容量以及使用情况；-gcmetacapacity 显示metaspace的大小-gcnew 显示新生代信息；-gcnewcapacity 显示新生代大小和使用情况；-gcold 显示老年代和永久代的信息；-gcoldcapacity 显示老年代的大小；-gcutil 显示垃圾收集信息；-gccause 显示垃圾回收的相关信息（通-gcutil）,同时显示最后一次或当前正在发生的垃圾回收的诱因；-printcompilation 输出JIT编译的方法信息； 示例一：-class 1234567显示加载class的数量，及所占空间等信息。jstat -class &lt;pid&gt;Loaded : 已经装载的类的数量Bytes : 装载类所占用的字节数Unloaded：已经卸载类的数量Bytes：卸载类的字节数Time：装载和卸载类所花费的时间 示例二： -compiler 12345678显示VM实时编译(JIT)的数量等信息。jstat -compiler &lt;pid&gt;Compiled：编译任务执行数量Failed：编译任务执行失败数量Invalid ：编译任务执行失效数量Time ：编译任务消耗时间FailedType：最后一个编译失败任务的类型FailedMethod：最后一个编译失败任务所在的类及方法 示例三： -gc 12345678910111213141516171819显示gc相关的堆信息，查看gc的次数，及时间。jstat –gc &lt;pid&gt;S0C：年轻代中第一个survivor（幸存区）的容量 （字节）S1C：年轻代中第二个survivor（幸存区）的容量 (字节)S0U ：年轻代中第一个survivor（幸存区）目前已使用空间 (字节)S1U ：年轻代中第二个survivor（幸存区）目前已使用空间 (字节)EC ：年轻代中Eden（伊甸园）的容量 (字节)EU ：年轻代中Eden（伊甸园）目前已使用空间 (字节)OC ：Old代的容量 (字节)OU ：Old代目前已使用空间 (字节)MC：metaspace(元空间)的容量 (字节)MU：metaspace(元空间)目前已使用空间 (字节)YGC ：从应用程序启动到采样时年轻代中gc次数YGCT ：从应用程序启动到采样时年轻代中gc所用时间(s)FGC ：从应用程序启动到采样时old代(全gc)gc次数FGCT ：从应用程序启动到采样时old代(全gc)gc所用时间(s)GCT：从应用程序启动到采样时gc用的总时间(s) 示例四： -gccapacity 12345678910111213141516171819202122可以显示，VM内存中三代（young,old,perm）对象的使用和占用大小jstat -gccapacity &lt;pid&gt;NGCMN ：年轻代(young)中初始化(最小)的大小(字节)NGCMX ：年轻代(young)的最大容量 (字节)NGC ：年轻代(young)中当前的容量 (字节)S0C ：年轻代中第一个survivor（幸存区）的容量 (字节)S1C ： 年轻代中第二个survivor（幸存区）的容量 (字节)EC ：年轻代中Eden（伊甸园）的容量 (字节)OGCMN ：old代中初始化(最小)的大小 (字节)OGCMX ：old代的最大容量(字节)OGC：old代当前新生成的容量 (字节)OC ：Old代的容量 (字节)MCMN：metaspace(元空间)中初始化(最小)的大小 (字节)MCMX ：metaspace(元空间)的最大容量 (字节)MC ：metaspace(元空间)当前新生成的容量 (字节)CCSMN：最小压缩类空间大小CCSMX：最大压缩类空间大小CCSC：当前压缩类空间大小YGC ：从应用程序启动到采样时年轻代中gc次数FGC：从应用程序启动到采样时old代(全gc)gc次数 示例五：-gcmetacapacity 12345678910111213metaspace 中对象的信息及其占用量。jstat -gcmetacapacity&lt;pid&gt;MCMN:最小元数据容量MCMX：最大元数据容量MC：当前元数据空间大小CCSMN：最小压缩类空间大小CCSMX：最大压缩类空间大小CCSC：当前压缩类空间大小YGC ：从应用程序启动到采样时年轻代中gc次数FGC ：从应用程序启动到采样时old代(全gc)gc次数FGCT ：从应用程序启动到采样时old代(全gc)gc所用时间(s)GCT：从应用程序启动到采样时gc用的总时间(s) 示例六： -gcnew 1234567891011121314年轻代对象的信息。jstat -gcnew &lt;pid&gt;S0C ：年轻代中第一个survivor（幸存区）的容量 (字节)S1C ：年轻代中第二个survivor（幸存区）的容量 (字节)S0U ：年轻代中第一个survivor（幸存区）目前已使用空间 (字节)S1U ：年轻代中第二个survivor（幸存区）目前已使用空间 (字节)TT：持有次数限制MTT：最大持有次数限制DSS：期望的幸存区大小EC：年轻代中Eden（伊甸园）的容量 (字节)EU ：年轻代中Eden（伊甸园）目前已使用空间 (字节)YGC ：从应用程序启动到采样时年轻代中gc次数YGCT：从应用程序启动到采样时年轻代中gc所用时间(s) 示例七： -gcnewcapacity 1234567891011121314年轻代对象的信息及其占用量jstat -gcnewcapacity &lt;pid&gt;NGCMN ：年轻代(young)中初始化(最小)的大小(字节)NGCMX ：年轻代(young)的最大容量 (字节)NGC ：年轻代(young)中当前的容量 (字节)S0CMX ：年轻代中第一个survivor（幸存区）的最大容量 (字节)S0C ：年轻代中第一个survivor（幸存区）的容量 (字节)S1CMX ：年轻代中第二个survivor（幸存区）的最大容量 (字节)S1C：年轻代中第二个survivor（幸存区）的容量 (字节)ECMX：年轻代中Eden（伊甸园）的最大容量 (字节)EC：年轻代中Eden（伊甸园）的容量 (字节)YGC：从应用程序启动到采样时年轻代中gc次数FGC：从应用程序启动到采样时old代(全gc)gc次数 示例八： -gcold 12345678910111213old代对象的信息jstat -gcold &lt;pid&gt;MC ：metaspace(元空间)的容量 (字节)MU：metaspace(元空间)目前已使用空间 (字节)CCSC:压缩类空间大小CCSU:压缩类空间使用大小OC：Old代的容量 (字节)OU：Old代目前已使用空间 (字节)YGC：从应用程序启动到采样时年轻代中gc次数FGC：从应用程序启动到采样时old代(全gc)gc次数FGCT：从应用程序启动到采样时old代(全gc)gc所用时间(s)GCT：从应用程序启动到采样时gc用的总时间(s) 示例九：-gcoldcapacity 1234567891011old代对象的信息及其占用量jstat -gcoldcapacity &lt;pid&gt;OGCMN ：old代中初始化(最小)的大小 (字节)OGCMX ：old代的最大容量(字节)OGC ：old代当前新生成的容量 (字节)OC ：Old代的容量 (字节)YGC ：从应用程序启动到采样时年轻代中gc次数FGC ：从应用程序启动到采样时old代(全gc)gc次数FGCT ：从应用程序启动到采样时old代(全gc)gc所用时间(s)GCT：从应用程序启动到采样时gc用的总时间(s) 示例十： - gcutil 12345678910111213统计gc信息jstat -gcutil &lt;pid&gt;S0 ：年轻代中第一个survivor（幸存区）已使用的占当前容量百分比S1 ：年轻代中第二个survivor（幸存区）已使用的占当前容量百分比E ：年轻代中Eden（伊甸园）已使用的占当前容量百分比O ：old代已使用的占当前容量百分比P ：perm代已使用的占当前容量百分比YGC ：从应用程序启动到采样时年轻代中gc次数YGCT ：从应用程序启动到采样时年轻代中gc所用时间(s)FGC ：从应用程序启动到采样时old代(全gc)gc次数FGCT ：从应用程序启动到采样时old代(全gc)gc所用时间(s)GCT：从应用程序启动到采样时gc用的总时间(s) 示例十一：-gccause 123456显示垃圾回收的相关信息（通-gcutil）,同时显示最后一次或当前正在发生的垃圾回收的诱因。jstat -gccause &lt;pid&gt;LGCC：最后一次GC原因GCC：当前GC原因（No GC 为当前没有执行GC） 示例十二： -printcompilation 1234567当前VM执行的信息。jstat -printcompilation &lt;pid&gt;Compiled ：编译任务的数目Size ：方法生成的字节码的大小Type：编译类型Method：类名和方法名用来标识编译的方法。类名使用/做为一个命名空间分隔符。方法名是给定类中的方法。上述格式是由-XX:+PrintComplation选项进行设置的 网络代理，访问限制网站 通过 命令行参数 指定 如果只需要考虑代理 HTTP 协议请求，只需添加如下命令行参数： -Dhttp.proxyHost=127.0.0.1 -Dhttp.proxyPort=1080 想要 HTTP 和 HTTPS 协议的请求都通过代理访问网络，可以追加上： -Dhttps.proxyHost=127.0.0.1 -Dhttps.proxyPort=1080 最终填写的值为： -Dhttp.proxyHost=127.0.0.1 -Dhttp.proxyPort=1080 -Dhttps.proxyHost=127.0.0.1 -Dhttps.proxyPort=1080 议 属性（代理主机/代理端口/不使用代理的主机列表） 默认值HTTP http.proxyHost http.proxyPort 80http.nonProxyHosts HTTPS https.proxyHost https.proxyPort 443https.nonProxyHosts FTP ftp.proxyHost ftp.proxyPort 80ftp.nonProxyHosts SOCKS socksProxyHost socksProxyPort 1080","link":"/2020/06/23/2019/jvmDebug/"},{"title":"jstorm安装配置开发","text":"jstorm记录安装 官方网站参考http://www.jstorm.io/ github https://github.com/alibaba/jstorm1官网已经有详细介绍了，这里就不重复 简介JStorm集群包含两类节点：主控节点（Nimbus）和工作节点（Supervisor）。其分别对应的角色如下： 主控节点（Nimbus）上运行Nimbus Daemon。Nimbus负责接收Client提交的Topology，分发代码，分配任务给工作节点，监控集群中运行任务的状态等工作。Nimbus作用类似于Hadoop中JobTracker。 工作节点（Supervisor）上运行Supervisor Daemon。Supervisor通过subscribe Zookeeper相关数据监听Nimbus分配过来任务，据此启动或停止Worker工作进程。每个Worker工作进程执行一个Topology任务的子集；单个Topology的任务由分布在多个工作节点上的Worker工作进程协同处理。123Nimbus和Supervisor节点之间的协调工作通过Zookeeper实现。此外，Nimbus和Supervisor本身均为无状态进程，支持Fail Fast；JStorm集群节点的状态信息或存储在Zookeeper，或持久化到本地，这意味着即使Nimbus/Supervisor宕机，重启后即可继续工作。这个设计使得JStorm集群具有非常好的稳定性。 概念 Storm组件和Hadoop组件对比 jstorm hadoop 角色 Nimbus JobTracker Supervisor TaskTracker Worker Child 应用名称 Topology Job 编程接口 Spout/Bolt Mapper/Reducer 接下来解释几个重要的概念： topology 1jstorm所执行的任务，其实就是一个topology，一个topology可以包含多个spout，多个bolt，多级bolt spout 1流的来源 bolt 1可以说是流的去处（这里可以进行业务处理）","link":"/2020/06/23/2019/jstormDeveloper/"},{"title":"jvm的常用运行参数以及内存分配和垃圾收集器的工作","text":"jvm的运行参数jvm的配置参数 -Xms40m //初始内存 -Xmx256m //最大内存 -Xmn16m //最小内存 -XX:PermSize=128M // 永久带的内存 -XX:MaxPermSize=256M // 永久带的最大内存（一般默认64MB） -XX:SurvivorRatio=8 // 新生代中Eden区域与Survivor区域的容量比值 -XX:MaxTenuringThreshold=15 // 一般jvm默认值15 晋升到老年代的对象年龄，每个对象坚持一次MinorGC之后，年龄就增加1，当超过这个参数的值时就进入老年代 jvm常用一些配置参数 GC参数 1234567891011-XX:+PrintGC 每次触发GC的时候打印相关日志-XX:+PrintGCDetails 更详细的GC日志-XX:+PrintHeapAtGC 每次GC时打印堆的详细详细信息-XX:+PrintGCApplicationConcurrentTime 打印应用程序执行时间-XX:+PrintGCApplicationAtoppedTime 打印应用程序由GC引起的停顿时间-XX:+PrintReferenceGC 跟踪系统内的软引用，弱引用，虚引用和finallize队列。 类跟踪 1234567-verbose:class 跟踪类的加载和卸载-XX:+TraceClassLoading 单独跟踪类加载-XX:+TraceClassUnloading 单独跟踪类卸载-XX:+PrintClassHistogram 查看运行时类的分布情况，使用时在控制台按ctrl+break 系统参数查看 12345-XX:+PrintVMOptions 运行时，打印jvm接受的命令行显式参数-XX:+PrintCommandLineFlags 打印传递jvm的显式和隐式参数-XX:+PrintFlagsFinal 打印所有系统参数值 堆 123456789-Xms 堆初始值-Xmx 堆最大可用值-Xmn 新生代大小，一般设为整个堆的1/3到1/4左右-XX:SurvivorRatio 设置新生代中eden区和from/to空间的比例关系n/1-XX:NewRatio 设置老年代与新生代的比 垃圾回收器 12345 Concurrent Mark-Sweep GC ：CMS回收器 Mark Sweep Compact GC： 串行GC（Serial GC） Parallel GC with 2 thread(s)： 并行GC（ParNew）","link":"/2020/06/23/2019/jvmXmSurvivor/"},{"title":"jstack定位死循环代码","text":"定位正在运行的程序死循环处(linux处使用)查看java的pid ps -ef | grep java 或者使用 top找到你的java程序的进程id, 定位 pid top -Hp $pid查看耗cpu时间最多的几个线程, 记录下线程的id.注：这里的进程是10进制的。 jstack $pid &gt; stack.log 生成dump文件。将上面线程的id换成16进制，加上0x$id 。查找dump出来的文件。就是该线程的堆栈信息 统计线程数量 ps -hH $pid| wc -l cpu运行top 按1键看每个数据,z 彩色 c是， f是 us是用户的，运行一些数据会飙升 sy系统调度资源 ni 运行已调整优先级的用户进程的CPU时间 id 空闲的， wa 等待 hi 处理硬件中断的CPU时间 si 处理软件中断的CPU时间 场景1：java启动100个cpu密集型任务，在24核上处理，假设平均的分在每一核心上执行， us或者sy很高，us执行，sy调度。id和wa很低 查看程序占用端口 linux : netstat -naop windows: netstat -ano |findstr 62045","link":"/2020/06/23/2019/linuxJstackJava/"},{"title":"log4j2的使用和配置项说明","text":"log4j2结合springboot初始化项目 pom文件引入12345678910 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt; &lt;/dependency&gt;-- 一下distuptor需要根据log4j2的配置。是否需要异步输入日志来判断 &lt;dependency&gt; &lt;groupId&gt;com.lmax&lt;/groupId&gt; &lt;artifactId&gt;disruptor&lt;/artifactId&gt; &lt;version&gt;3.4.2&lt;/version&gt; &lt;/dependency&gt; 文档地址springboot logger 4.4.6章节 demo文件 文件默认加载:log4j2-spring.xml or log4j2.xml 。这里推荐使用前者 配置演示文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!--设置log4j2的自身log级别为ERROR--&gt;&lt;!--日志级别以及优先级排序: OFF &gt; FATAL &gt; ERROR &gt; WARN &gt; INFO &gt; DEBUG &gt; TRACE &gt; ALL --&gt;&lt;!--Configuration后面的status，这个用于设置log4j2自身内部的信息输出，可以不设置，当设置成trace时，你会看到log4j2内部各种详细输出--&gt;&lt;!--monitorInterval：监控间隔，例如：monitorInterval=”600” 指log4j2每隔600秒（10分钟），自动监控该配置文件是否有变化，如果变化，则自动根据文件内容重新配置--&gt;&lt;configuration status=&quot;INFO&quot; monitorInterval=&quot;30&quot;&gt; &lt;Properties&gt; &lt;!-- 配置日志文件输出目录 --&gt; &lt;Property name=&quot;LOG_HOME&quot;&gt;E:\\\\work\\\\logs&lt;/Property&gt; &lt;Property name=&quot;LOG_BUSINESS_LEVEL&quot;&gt;INFO&lt;/Property&gt; &lt;Property name=&quot;LOG_LEVEL&quot;&gt;INFO&lt;/Property&gt; &lt;Property name=&quot;LOG_SQL_LEVEL&quot;&gt;TRACE&lt;/Property&gt; &lt;/Properties&gt; &lt;!--先定义所有的appender--&gt; &lt;appenders&gt; &lt;!--这个输出控制台的配置--&gt; &lt;Console name=&quot;Console&quot; target=&quot;SYSTEM_OUT&quot;&gt; &lt;!--输出日志的格式--&gt; &lt;PatternLayout pattern=&quot;%d [%t] %-5p [%c] - %m%n&quot;/&gt; &lt;/Console&gt; &lt;!--business的日志记录追加器--&gt; &lt;RollingRandomAccessFile name=&quot;businessFile&quot; fileName=&quot;${LOG_HOME}/leke-business.log&quot; immediateFlush=&quot;false&quot; append=&quot;true&quot; filePattern=&quot;${LOG_HOME}/business-%d{yyyy-MM-dd}-%i.log.gz&quot;&gt; &lt;PatternLayout pattern=&quot;%d [%t] %-5p [%c] - %m%n&quot;/&gt; &lt;!-- 该日志文件只会打印INFO等级的日志 --&gt; &lt;Filters&gt; &lt;!--WARN(含WARN)以上的级别信息直接拒绝，WARN以下交由下一个过滤器--&gt; &lt;ThresholdFilter level=&quot;WARN&quot; onMatch=&quot;DENY&quot; onMismatch=&quot;NEUTRAL&quot;/&gt; &lt;!--接收上一个过滤器来的内容:大于DEBUG信息通过，低于INFO信息的拒绝--&gt; &lt;ThresholdFilter level=&quot;DEBUG&quot; onMatch=&quot;ACCEPT&quot; onMismatch=&quot;DENY&quot; /&gt; &lt;/Filters&gt; &lt;Policies&gt; &lt;SizeBasedTriggeringPolicy size=&quot;1000 MB&quot;/&gt; &lt;TimeBasedTriggeringPolicy/&gt; &lt;/Policies&gt; &lt;/RollingRandomAccessFile &gt; &lt;!--exception的日志记录追加器--&gt; &lt;RollingRandomAccessFile name=&quot;exceptionFile&quot; fileName=&quot;${LOG_HOME}/exception.log&quot; immediateFlush=&quot;false&quot; append=&quot;true&quot; filePattern=&quot;${LOG_HOME}/exception-%d{yyyy-MM-dd}-%i.log.gz&quot;&gt; &lt;!--WARN(含WARN)以上的级别信息通过，低于WARN的拒绝执行--&gt; &lt;Filters&gt; &lt;ThresholdFilter level=&quot;WARN&quot; onMatch=&quot;ACCEPT&quot; onMismatch=&quot;DENY&quot;/&gt; &lt;/Filters&gt; &lt;PatternLayout pattern=&quot;%d [%t] %-5p [%c] - %m%n&quot;/&gt; &lt;Policies&gt; &lt;SizeBasedTriggeringPolicy size=&quot;1000 MB&quot;/&gt; &lt;TimeBasedTriggeringPolicy/&gt; &lt;/Policies&gt; &lt;/RollingRandomAccessFile &gt; &lt;Async name=&quot;Async&quot;&gt; &lt;appender-ref ref=&quot;Console&quot;/&gt; &lt;appender-ref ref=&quot;businessFile&quot;/&gt; &lt;appender-ref ref=&quot;exceptionFile&quot;/&gt; &lt;/Async&gt; &lt;/appenders&gt; &lt;!--然后定义logger，只有定义了logger并引入的appender，appender才会生效--&gt; &lt;loggers&gt; &lt;root level=&quot;WARN&quot;&gt; &lt;appender-ref ref=&quot;Async&quot;/&gt; &lt;/root&gt; &lt;!--这个是异步输出日志文件。性能高，添加该项依赖要加入disruptor包--&gt; &lt;AsyncLogger name=&quot;com.alibaba.nacos.client.naming&quot; level=&quot;info&quot; additivity=&quot;false&quot;&gt; &lt;appender-ref ref=&quot;Console&quot;/&gt; &lt;/AsyncLogger&gt; &lt;!--同步输出日志文件。--&gt; &lt;Logger name=&quot;com.example.demo.controller&quot; level=&quot;WARN&quot; additivity=&quot;false&quot;&gt; &lt;appender-ref ref=&quot;Console&quot;/&gt; &lt;appender-ref ref=&quot;businessFile&quot;/&gt; &lt;appender-ref ref=&quot;exceptionFile&quot;/&gt; &lt;/Logger&gt; &lt;/loggers&gt;&lt;/configuration&gt; 结合springboot的使用 springboot中的YML文件配置优先级高于log4j2.xml 可以在YML配置多环境多配置 YML有以下配置。那么整体的日志级别是INFO。非上面XML中配置的WARN。同时controller也一样是info级别的日志也会输出1234567logging: level: root: INFO com: example: demo: controller: INFO 配置项说明 onMatch和onMismatch都有三个属性值，分别为Accept、DENY和NEUTRAL 分别介绍这两个配置项的三个属性值：123456onMatch=&quot;ACCEPT&quot; 表示匹配该级别及以上onMatch=&quot;DENY&quot; 表示不匹配该级别及以上onMatch=&quot;NEUTRAL&quot; 表示该级别及以上的，由下一个filter处理，如果当前是最后一个，则表示匹配该级别及以上onMismatch=&quot;ACCEPT&quot; 表示匹配该级别以下onMismatch=&quot;NEUTRAL&quot; 表示该级别及以下的，由下一个filter处理，如果当前是最后一个，则不匹配该级别以下的onMismatch=&quot;DENY&quot; 表示不匹配该级别以下的","link":"/2020/06/23/2019/log4j2InfoAndUse/"},{"title":"xcodebuild找不到","text":"xcode找不到1231. 直接appStore上下载不会有问题2. 自己额外下载会有可能变更安装目录，造成找不到xcodebuild3. 解决原因:sudo xcode-select -s (/Applications/Xcode.app/Contents/Developer|你的安装地址 )","link":"/2020/06/23/2019/macXcode/"},{"title":"mongodb的安装&#x2F;启动&#x2F;集群","text":"mongodb的安装 复制mongo.conf 进行配置文件 12345678910111213141516171819202122232425262728# mongod.conf# for documentation of all options, see:# http://docs.mongodb.org/manual/reference/configuration-options/net: port: 27010 bindIp: 127.0.0.1processManagement: pidFilePath: /data0/mongod/mongod1.pid fork: truestorage: dbPath: /data0/mongod/data/shard1 directoryPerDB: truesystemLog: destination: file path : /data0/mongod/log/shard1/mongodb.log logAppend: truereplication: replSetName: rs0 oplogSizeMB: 1000# security:# authorization: enabled单机不需要replication参数 运行 我的mongodb 12345678910111213bin/mongod -f xxx/mongod.conf 启动服务bin/mongod -shutdown -f xxx/mongod.conf 停止服务mongod 密码验证，刚开始。注释上面security：进入mongodb /use admin库创建超级用户db.createUser({ user: &quot;admin&quot;, pwd: &quot;admin&quot;, roles: [{ role: &quot;userAdminAnyDatabase&quot;, db: &quot;admin&quot; }]})在开启上面配置文件的 security。这时候mongodb将使用密码访问 mongodb开机启动 12345678910111213141516171819202122232425262728[Unit]Description=MongoDB ServerAfter=network.target[Service]User=mongodGroup=mongodType=forkingPIDFile=/data0/mongod/mongod1.pidExecStartPre=ExecStart=/usr/local/mongodb1/bin/mongod -f /usr/local/mongodb1/mongod.confExecReload=/usr/local/mongodb1/bin/kill -s HUP $MAINPIDExecStop=/usr/local/mongodb1/bin/kill -s QUIT $MAINPIDWorkingDirectory=/data0/mongodRestart=alwaysLimitFSIZE=infinityLimitCPU=infinityLimitAS=infinityLimitNOFILE=64000LimitRSS=infinityLimitNPROC=64000PrivateTmp=true[Install]WantedBy=multi-user.target mongodb集群服务 mongodb配置一组relica sets。 仲裁节点(偶数台需要，奇数台不需要，作用是偶数台电脑，照成投票平均，仲裁节点可以增加票数) 注：请先登陆到admin数据库在进行操作，否则后续操作会出错 (重点) 123456789ntpdate ntp.api.bz 集群时，首先执行命令 同步时钟（重要）mongod1.conf。可以多复制几个，使用一个mongod同时运行。mongo -port xx // 链接到其中一台mongodb服务器上去configx = {_id:&quot;rs0&quot;,version:1,members:[{_id:0,host:'127.0.0.1:27010',priority :2},{_id:1,host:'127.0.0.1:27020',priority:1},{_id:2,host:'127.0.0.1:27030',priority:1}]} // 添加各个节点上去rs.initiate(configx) // 初始化一个 replica setsrs.conf() // 查看获取的配置 rs.reconfig(configx,{force:true}) // reconfig() 用来重新执行文档，force:true 是否覆盖以前rs.status() // 查看状态。备注:从库只读 需要 rs.slaveOk();可以设置为只读 不可以写 mongod sharding configServer配置 12345678910configServer的配置和mongod1.conf要多加如下面一句话。只需要dbpath和logpath换下就行**sharding:** **clusterRole: configsvr**configServer也需要dbpath另外#replication:replSetName：xxx 尽量别和replica set中的重名。否则mongos添加shard时通过Id会有可能找成configServer。非一台电脑可以不换，只需要不冲突就行, configx = {_id:&quot;configrs0&quot;,configsvr: true,members:[{_id:0,host:'127.0.0.1:27010',priority :2},{_id:1,host:'127.0.0.1:27020',priority:1},{_id:2,host:'127.0.0.1:27030',priority:1}]} // 添加各个节点上去 mongod sharding mongos路由的配置 1234567891011121314151617net: port: 20000 bindIp: test13.kingsilk.xyzprocessManagement: pidFilePath: /data0/mongod/mongos.pid #fork: truesystemLog: destination: file path : /data0/mongod/log/mongos/mongodb.log logAppend: truesharding: configDB: xxxxxxxx:27000,xxxxxx:28000,xxxxxxx:29000mongos.conf 配置文件启动：mongos -f mongos.conf 集群后的配置 12键入：mongo -host xx -port xx mongos的地址sh.addShard(&quot;rs0/xxx:27010,txx:27020,xxx27030&quot;); // 刚才输入的一组replica set。如果rs0和configServer中的replicationName一样。则可能会添加失败.修改Id 别冲突 mongodb密码登录 一些快速创建密码账户，可以略过不用看12345678910111213141516171819202122232425262728293031db.createUser( { user: &quot;admin&quot;, pwd: &quot;admin&quot;, roles: [ { role: &quot;userAdminAnyDatabase&quot;, db: &quot;admin&quot; } ] })db.createUser( { user: &quot;repl&quot;, pwd: &quot;replication&quot;, roles: [ { role: &quot;readWrite&quot;, db: &quot;admin&quot; } ] })db.createUser( { user:&quot;root&quot;, pwd:&quot;root&quot;, roles:[&quot;root&quot;] }) 集群的密码配置(先看完上面的) linux 命令行：openssl rand -base64 741 &gt; mongodb-keyfile linux 命令行： chmod 600 mongodb-keyfile https://docs.mongodb.org/manual/tutorial/configure-ssl/ mongos认证 mongos.conf的配置 123456789101112131415161718192021222324252627net: port: 20000 bindIp: 127.0.0.1processManagement: pidFilePath: /data0/mongod/mongos.pid #fork: true#storage:# dbPath: /data0/mongod/data/mongos# directoryPerDB: truesystemLog: destination: file path : /data0/mongod/log/mongos/mongodb.log logAppend: truesharding: configDB: configServer1:27000,configServer2:28000,configServer3:29000#replication:# replSetName: rs0# oplogSizeMB: 1000security:# authorization: enabled keyFile: mongodb-keyfile安全需要先注释，进入admin添加用户后在打开，和mongodb一样，这里不重复了运行:mongos -f mongos.conf 将所有的mongod.conf和config.conf 添加上 123security:authorization: enabledkeyFile: mongodb-keyfile mongos.conf只需要添加keyFile,不需要authorization。添加这个之前现在mongos无密码登陆创建用户先 进入mongos到admin 123456sh.addShard(&quot;rs0/xxxxxxxx:27010,xxxxxxxxxxx:27030,xxxxxxxxxxxxxx:27030&quot;);需要在admin中添加。副本集也要在admin中添加，否则无法添加#指定uba分片生效db.runCommand( { enablesharding :&quot;uba&quot;});#指定数据库里需要分片的集合和片键db.runCommand( { shardcollection : &quot;uba.table1&quot;,key : {id: 1} } )","link":"/2020/06/23/2019/mongodb/"},{"title":"log4j平滑升级log4j2","text":"log4j升级 log4j在异步日志打印下性能极大提升，好处多多 log4j2可以选择异步与同步日志打印.使用异步打印必须配置disruptor包 12345 &lt;dependency&gt; &lt;groupId&gt;com.lmax&lt;/groupId&gt; &lt;artifactId&gt;disruptor&lt;/artifactId&gt; &lt;version&gt;3.4.2&lt;/version&gt;&lt;/dependency&gt; log4j2的xml配置中有AsyncLogger和Logger配置区别。Async就是异步配置 log4j2有包架构不匹配。当原有系统不方便需改时。可以使用桥接包 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-1.2-api&lt;/artifactId&gt; &lt;version&gt;2.13.0&lt;/version&gt; &lt;/dependency&gt; 参考其他文章 log4j平稳升级","link":"/2020/06/23/2019/log4juploadlog4j2/"},{"title":"mongo操作","text":"mongodb使用总结【grom】非内嵌类使用many-to-one or one-to-one等问题1若非内嵌类，则不能使用类似belongsTo = [xx:XX] 或者 hasOne = [xx:XX] 或者 XX xx等的关联方式，需要指定使用String xxId 【grom】非内嵌类使用one-to-many等问题12若非内嵌类，则不能使用类似List&lt;XX&gt; xxs的关联方式，否则虽不会报错，但是却不能正常保存（保存的都为null）；然而可以使用hasMany = [xxs: XX]的方式 【grom】数组查询12345678910111213假设Cart中有List&lt;String&gt; strIds；则可以针对数组进行各式查询：* 精确查询 -- （包括数组的顺序） -- 查询出strIds为[&quot;a0&quot;,&quot;a1&quot;,&quot;a2&quot;]的数据 def cartList = Cart.createCriteria().list { eq(&quot;strIds&quot;, [&quot;a0&quot;,&quot;a1&quot;,&quot;a2&quot;]) }* 模糊查询 -- 数组包含即可 -- 查询出所有strIds中包含a8的数据 def cartList = Cart.createCriteria().list { eq(&quot;strIds&quot;, &quot;a8&quot;) }* 下标查询 -- 查询出所有strIds中下标8的值为a8的数据 def cartList = Cart.createCriteria().list { eq(&quot;strIds.8&quot;, &quot;a8&quot;) } mongo CRUD导出 12导出使用mongodump命令。mongodump --help查看命令的帮助。可以批量导出数据库表* [地址](http://docs.mongodb.org/manual/reference/program/mongodump/) 导入1导入备份 mongorestore命令。该命令可以导入一个文件夹下所有集合。mongoimport只能导入单个json 地址 添加用户 12345678use test db.createUser( { user:&quot;user123&quot;, pwd:&quot;12345678&quot;, roles:[ &quot;readWrite&quot;, { role:&quot;changeOwnPasswordCustomDataRole&quot;, db:&quot;admin&quot; } ] } ) * [地址](http://docs.mongodb.org/manual/tutorial/change-own-password-and-custom-data/)修改用户12345678use test db.updateUser( &quot;user123&quot;, { pwd: &quot;KNlZmiaNUp0B&quot;, customData: { title: &quot;Senior Manager&quot; } } ) 地址 db.getCollection(‘order’).find({“logistics”:{ $in: [null],$exists:true}}) // 数值为null 字段也在 mongo客户端 robomongo 建立唯一索引db.getCollection(‘xxx’).ensureIndex({id:1},{unique:true})","link":"/2020/06/23/2019/mongo/"},{"title":"mongodb常用命令","text":"mongodb常用操作 添加用户名 12345db.createUser( { user: &quot;test&quot;, pwd: &quot;test&quot;, roles: [ { role: &quot;dbOwner&quot;, db: &quot;test&quot; } ]}); 删除数据库 12db.dropDatabase()这将删除选定的数据库。如果还没有选择任何数据库，然后它会删除默认的 ' test' 数据库 删除用户 1db.system.users.remove({user:&quot;java1&quot;}); 克隆数据库 1db.copyDatabase(fromdb, todb, fromhost, username, password) // username是fromdb的数据库名 更新数据 12345678910111).update()命令db.collection.update( criteria, objNew, upsert, multi )db.collection.update( {id:&quot;11&quot;}, {$set:{id:&quot;22&quot;}}, {multi:true} ) // 将所有id=11的更新成id=22criteria : update的查询条件，类似sql update查询内where后面的objNew : update的对象和一些更新的操作符（如$,$inc...）等，也可以理解为sql update查询内set后面的upsert : 这个参数的意思是，如果不存在update的记录，是否插入objNew,true为插入，默认是false，不插入。multi : mongodb默认是false,只更新找到的第一条记录，如果这个参数为true,就把按条件查出来多条记录全部更新。db.test0.update( { &quot;count&quot; : { $gt : 1 } } , { $set : { &quot;test2&quot; : &quot;OK&quot;} } ); 只更新了第一条记录db.test0.update( { &quot;count&quot; : { $gt : 3 } } , { $set : { &quot;test2&quot; : &quot;OK&quot;} },false,true ); 全更新了 管道概念，参考官方网址 1234567查询一个条件后进行一个条件db.oldUser.aggregate({$project:{address:1,gender: 1}},{$skip:1},{$limit:1});上面语句意思是，返回数据只包含address和gender字段，略过第一条数据，只返回一条数据。如果limit和skip反过来，则是返回一条数据，同时略过，则返回为空。管道按照顺序来db.oldUser.aggregate({$match:{ $or:[ {origin:&quot;淘宝&quot;,$or:[{address:&quot;上海&quot;},{_id:&quot;111&quot;},{address:&quot;杭州&quot;}]},{origin:&quot;淘宝&quot;,_id:&quot;111&quot;}] } });// 查询字段 (来自淘宝同时地址要是上海或者id是xxx或者是杭州)或者(来自淘宝同时id是xxx) db.oldUser.aggregate({$match:{ $or:[{origin:&quot;淘宝&quot;]}}，{$match:{ $or:[{address:&quot;天猫&quot;]}});// and查询，既要是来自淘宝，同时地址还是天猫的 查询字段为空 123456db.getCollection('maodoudou').find({scroe:{$in:[null], $exists: true}}) // 查询该字段存在，值为nulldb.getCollection('maodoudou').find({scroe:{$in:[null], $exists: false}}) // 查询该字段值为null，不管字段是否存不存在，没有字段也视为nulldb.getCollection('adc').find({$or:[{_id:&quot;110000&quot;},{_id:&quot;110101&quot;}]}) // mongodb or查询db.getCollection('adc').find({$and:[{_id:&quot;110000&quot;},{name:&quot;北京市&quot;}]}) // and查询db.hotelBillsOrder.aggregate({$unwind: &quot;$orderItems&quot;},{$group:{_id:null,count:{$sum:&quot;$orderItems.day&quot;}}})","link":"/2020/06/23/2019/mongodbCmd/"},{"title":"mysql知识点(B&#x2F;B+数据结构)","text":"mysql知识点先放出友情链接 B树 b+ lsm mysql索引讲解 mysql全文索引处理 mysql页分裂 B+树可以存储多少行数据 mysql全篇总结 事务的说明探讨参考：1 mysql知识点 mysql事务实现:MVCC概念 组合索引：innodb 索引会带上当前的索引，同时加上主键Id,order 也会用索引 mysql order by 工作过程:文章1 | 文章2 12345上诉排序问题：sql为:select city,name,age from t where city in ('杭州','苏州') order by name limit 1000;这时候怎么办？1： 组合索引的排序规则是city_name 这时候city=杭州 但是name排序不对。2： 业务上分别拆分成2条:select city,name,age from t where city='杭州' order by name limit 1000;and select city,name,age from t where city='苏州' order by name limit 1000; 然后再业务代码中进行name排序取出前1000.也是一种方法 mysql explan 中type含义: 文章 B树 B+数区别 :文章 12345678B树和B+树的区别这都是由于B+树和B具有这不同的存储结构所造成的区别，以一个m阶树为例。 1. 关键字的数量不同；B+树中分支结点有m个关键字，其叶子结点也有m个，其关键字只是起到了一个索引的作用，但是B树虽然也有m个子结点，但是其只拥有m-1个关键字。 2. 存储的位置不同；B+树中的数据都存储在叶子结点上，也就是其所有叶子结点的数据组合起来就是完整的数据，但是B树的数据存储在每一个结点中，并不仅仅存储在叶子结点上。 3. 分支结点的构造不同；B+树的分支结点仅仅存储着关键字信息和儿子的指针（这里的指针指的是磁盘块的偏移量），也就是说内部结点仅仅包含着索引信息。 4. 查询不同；B树在找到具体的数值以后，则结束，而B+树则需要通过索引找到叶子结点中的数据才结束，也就是说B+树的搜索过程中走了一条从根结点到叶子结点的路径。","link":"/2020/06/23/2019/mysql%E7%9F%A5%E8%AF%86%E7%82%B9/"},{"title":"mvn私服配置","text":"maven私服配置 下载nexus直接运行bin目录 ./nexus start启动; 浏览器输入http://localhost:8081/nexus maven需要配置。在~/.m2/setting.xml,添加一下内容 12345678910111213141516171819202122232425262728293031323334353637&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;settings xmlns=&quot;http://maven.apache.org/SETTINGS/1.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd&quot;&gt; &lt;pluginGroups&gt; &lt;/pluginGroups&gt; &lt;proxies&gt; &lt;/proxies&gt; &lt;servers&gt; &lt;/servers&gt; &lt;mirrors&gt; &lt;mirror&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;name&gt;kingsilk&lt;/name&gt; &lt;url&gt;http://mvn.kingsilk.xyz/content/groups/public/&lt;/url&gt; &lt;id&gt;kingsilk&lt;/id&gt; &lt;/mirror&gt; &lt;/mirrors&gt; &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;downloadSources&lt;/id&gt; &lt;properties&gt; &lt;downloadSources&gt;true&lt;/downloadSources&gt; &lt;downloadJavadocs&gt;true&lt;/downloadJavadocs&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;activeProfiles&gt; &lt;activeProfile&gt;downloadSources&lt;/activeProfile&gt; &lt;/activeProfiles&gt;&lt;/settings&gt; 1.nexus下载地址选择对应的包 clean install -Dmaven.test.skip=true","link":"/2020/06/23/2019/nexus/"},{"title":"nginx上传图片错误和代理resolver错误","text":"nginx日常使用 使用 在上传图片时候，使用电脑浏览器未有错误，手机客户端浏览器会抛错。nginx缓存大小 1234astcgi_buffers 32 8k;client_body_buffer_size 1024k;client_max_body_size 10m;nginx http.conf http中 nginx proxy_pass 问题：no resolver defined to resolve xxx.xxx 原因是Nginx0.6.18以后的版本中启用了一个resolver指令，在使用变量来构造某个server地址的时候一定要用resolver指令来制定DNS服务器的地址。在nginx的配置文件中的http{}部分添加一行resolver 8.8.8.8;即可 引申问题 由于resolver加入 8.8.8.8那么域名都会解析到广域网中的ip。 如果需要将域名解析至特定的ip。可以自己搭建一个dns服务器。 windows中搭建方法： 自行搜索，暂无看到好的解决方案。windows server可以支持 linux 中搭建方法12345678910111213141516171819brew install dnsmasqvim /usr/local/etc/dnsmasq.conf 该路径下没有在etc中vim /etc/dnsmasq.conf&gt;&gt;把以下注释打开domain-neededbogus-privcache-size=51200listen-address=127.0.0.1resolv-file=/etc/resolv.conf&gt;&gt; 启动 /etc/init.d/dnsmasq start 注：默认nobady用户。提示无权限修改上面conf中usre配置。填写对应用户&gt;&gt; 在nginx配置中增加location ~ /testa { resolver 127.0.0.1; // 本句 proxy_pass http://beta.test.com; ＃apache环境}","link":"/2020/06/23/2019/nginxMaxBuff/"},{"title":"nodejs简介","text":"参考 从Java到Node.js Ghost 基于Node.js的开源博客系统 How To Install Node.js on an Ubuntu 14.04 server NODE.JS为什么会成为企业中的首选技术 PayPal为什么从Java迁移到Node.js，性能提高一倍，文件代码减少44% who use nodejs? stackedit cnodejs nodeschool npm@taobao 安装二进制安装打开 nodejs 官网的下载页, 下载二进制安装包 12345678910sudo mkdir /usr/local/nodejssudo tar zxvf node-v0.12.1-linux-x64.tar.gz -C /usr/local/nodejssudo vi /etc/profile.d/xxx.sh # 追加以下配置export NODEJS_HOME=/usr/local/nodejs/node-v0.12.1-linux-x64export PATH=$NODEJS_HOME/bin:$PATHcd /usr/local/nodejs/node-v0.12.1-linux-x64sudo chmod 777 binsudo chmod 777 lib/node_modules Ubuntu参考这里 123456curl -sL https://deb.nodesource.com/setup | sudo bash -#sudo add-apt-repository ppa:chris-lea/node.js#sudo apt-get updateapt-cache policy nodejssudo apt-get install nodejssudo apt-get install build-essential Http Hello world新建 hi.js，内容如下 123456var http = require('http');http.createServer(function (req, res) { res.writeHead(200, {'Content-Type': 'text/plain'}); res.end('Hello World\\n');}).listen(1337, '127.0.0.1');console.log('Server running at http://127.0.0.1:1337/'); 然后运行： 1node hi.js 最后浏览器访问 http://127.0.0.1:1337/ Centos使用Linux二进制包。 使用 nvm 1234su - curl -sL https://deb.nodesource.com/setup | sudo bash -su -nvm install v0.10.34 npm使用国内淘宝的镜像 通过 config 命令 12npm config set registry https://registry.npm.taobao.orgnpm info underscore 通过命令行参数 1npm --registry https://registry.npm.taobao.org info underscore 通过修改 ~/.npmrc 加入以下内容 1registry = https://registry.npm.taobao.org","link":"/2020/06/23/2019/nodejs/"},{"title":"oracle一些用到的语法总结","text":"sql developer 工具打开多个窗口，工具默认是只能打开一个窗口。在 工具&gt;首选项&gt;数据库&gt;ObjectViewer 中，将自动冻结对象查看器窗口,即可，如下图","link":"/2020/06/23/2019/oracleDevelopment/"},{"title":"oracle一些用到的语法总结","text":"用到的工作上一些语法 DECODE语句，”DECODE”(expr, [search, result]*, default) ，全局简介： 1234567举例说明：现定义一table名为output，其中定义两个column分别为monthid（var型）和sale（number型），若sale值=1000时翻译为 D，=2000时翻译为C，=3000时翻译为B，=4000时翻译为A，如是其他值则翻译为Other；SQL如下：Select monthid , decode (sale,1000,'D',2000,'C',3000,'B',4000,'A',’Other’) sale from output特殊情况：若只与一个值进行比较Select monthid ,decode（sale， NULL，‘---’，sale） sale from output round() 四舍五入使用，SELECT ROUND(column_name,decimals) FROM table_name 123参数 描述column_name 必需。要舍入的字段。decimals 非必需，默认0，返回int。规定要返回的小数位数 sql结合以上2点防止生成百分比防止除数是0 1decode(xx, 0, 0, to_char(round(ddd / xxx * 100, 2), 'fm990.99'))","link":"/2020/06/23/2019/oracleSql/"},{"title":"canal的同步使用","text":"otter同步信息","link":"/2020/06/23/2019/otterAndCanal/"},{"title":"phonegap&#x2F;cordova","text":"安装phonegap过程安装node.js1前往https://nodejs.org/en/下载最新安装包，并将目录放置path中 安装phonegap1sudo npm install -g phonegap cordova12sudo npm install -g cordova cordova是phonegap提交给apache开源代码的品牌，cordova是核心代码。phoengap如上层框架 创建app123456789101112phonegap create myapp或者cordova create myappcd myappcordova platform add browser/cordova platform add android 将项目加到哪个平台中去cordova run android 运行该项目cordova build -release发布生产版本注：android需要添加path， sudo vi /etc/profild.d/xxx.sh 当前环境变量名。 exprot ANDROID_HOME=/xxxxx/xxxx/sdk exprot PATH=$ANDROID_HOME/platform-tools:$PATH exprot PATH=$ANDROID_HOME/tools:$PATH cordova常用命令 cd myapp 进入工作目录 cordova serve 或者phonegap serve 直接运行html代码 cordova build 编译代码 cordova plugin ls 当前使用的插件 cordova rm * 移除插件 cordova plugin add cordova-plugin-device 添加可以获取设备信息的插件 http://cordova.apache.org/plugins/ 插件查找网站 http://docs.phonegap.com/zh/edge/guide_cli_index.md.html#%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%95%8C%E9%9D%A2 参考中文网 http://cordova.apache.org/docs/zh/6.0.0/config_ref/index.html 最新的cordova中文文档 http://cordova.apache.org/docs/en/latest/guide/overview/ 官方文档 app的在线更新code-push使用12345678910111213141516171819使用code-push 微软提供插件,安装命令：cordova plugin add cordova-plugin-code-push安装后要使用code-push命令，需要另外安装：npm install -g code-push-cli，github地址:https://github.com/Microsoft/code-push/tree/master/cli安装好code-push就要进行注册登陆，可以是使用github和microsoft账号，登陆会给出一个key进行登陆，使用命令:code-push register code-push app add (you app name)添加一个appcode-push deployment ls (you app name) -k 查看你的app的keycode-push release myapp &lt;path_to_your_app&gt;/platforms/android/assets/www 0.0.1 --deploymentName Production/Staging 将自己的代码推上去( Production/Staging 2选1) 在app的config.xml添加一下内容 &lt;platform name=&quot;android&quot;&gt; &lt;preference name=&quot;CodePushDeploymentKey&quot; value=&quot;你的app的key&quot; /&gt; &lt;/platform&gt; &lt;platform name=&quot;ios&quot;&gt; &lt;preference name=&quot;CodePushDeploymentKey&quot; value=&quot;你的app的key&quot; /&gt; &lt;/platform&gt;InstallMode IMMEDIATE: 立即更新app. ON_NEXT_RESTART: 更新是下载，但没有立即安装。新的内容将在下一次应用程序启动时可用. ON_NEXT_RESUME: 的更新下载，但不立即安装。新的内容将在下一次申请恢复或重新启动，无论事件发生的第一. wechat微信插件使用1234567891011$scope.shares = function () {// 发送到朋友圈 Wechat.share({ text: &quot;豆豆你好&quot;, scene: Wechat.Scene.TIMELINE // share to Timeline }, function () { alert(&quot;Success&quot;); }, function (reason) { alert(&quot;Failed: &quot; + reason); });} Cordova使用crosswalk更换内置的浏览器 crosswalk官方文档 121. cordova plugin add cordova-plugin-crosswalk-webview2. cordova build android 使用百度云进行推送消息 参考资料百度云推送","link":"/2020/06/23/2019/phonegap/"},{"title":"redis安装","text":"安装 12安装到自己定义目录中，记住目录#自启动添加 vim /etc/init.d/redis centos 准备 init.d 脚本（可以搜索 redis rpm，找到rpm包后解压获取相应的init.d脚本，然后在再其基础上修改配置项） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#!/bin/sh# chkconfig: 2345 10 90# description:redis#### redis init file for starting up the redis daemon#### chkconfig: - 20 80## description: Starts and stops the redis daemon.### Source function library.#REDISPORT=6379 EXEC=/data0/soft/redis/redis-3.0.3/src/redis-server REDIS_CLI=/data0/soft/redis/redis-3.0.3/src/redis-cli PIDFILE=/var/run/redis.pid CONF=&quot;/data0/soft/redis/redis-3.0.3/redis.conf&quot; case &quot;$1&quot; in start) if [ -f $PIDFILE ] then echo &quot;$PIDFILE exists, process is already running or crashed&quot; else echo &quot;Starting Redis server...&quot; $EXEC $CONF fi if [ &quot;$?&quot;=&quot;0&quot; ] then echo &quot;Redis is running...&quot; fi ;; stop) if [ ! -f $PIDFILE ] then echo &quot;$PIDFILE does not exist, process is not running&quot; else PID=$(cat $PIDFILE) echo &quot;Stopping ...&quot; $REDIS_CLI -p $REDISPORT SHUTDOWN while [ -x ${PIDFILE} ] do echo &quot;Waiting for Redis to shutdown ...&quot; sleep 1 done echo &quot;Redis stopped&quot; fi ;; restart|force-reload) ${0} stop ${0} start ;; *) echo &quot;Usage: /etc/init.d/redis {start|stop|restart|force-reload}&quot; &gt;&amp;2 exit 1 esac 并修改其中的配置项 vi /etc/init.d/redis 1234exec=&quot;/data/software/redis/redis-2.8.14/src/redis-server&quot;pidfile=&quot;/data/store/redis/redis.pid&quot; # 应当与redis.conf中的配置保持一致REDIS_CONFIG=&quot;/data/software/redis/redis-2.8.14/redis.conf&quot;REDIS_USER=redis 最后为 init.d 脚本修改权限 1234chmod u+x /etc/init.d/redischkconfig --add redischkconfig --list redischkconfig --level 345 redis on 启动 1service redis start #centos7 12345vi /usr/lib/systemd/system/redis.service systemctl enable redissystemctl start redis 批量删除redis-cli -h 127.0.0.1 -p 7001 -c keys “xxxx*” | xargs redis-cli -h 127.0.0.1 -p 7001 -c del {}","link":"/2020/06/23/2019/redis/"},{"title":"ubuntu server修改键盘布局","text":"ubuntu server修改键盘布局123456789101112方法1：也许是以前的Ubuntu版本可以用这个命令改，现在的键盘布局被独立分开设置，于是我尝试了一下，发现正确的命令应该是：“ sudo dpkg-reconfigure keyboard-configuration ”，这个才对，使用这个命令后会出现非常人性化的伪图形界面供我们设置。方法2：另外，如果觉得不够“爽快”，想直接修改配置文件的同学们可以用一下这种方法：sudo vim /etc/default/keyboard把里面XKBLAYOUT变量的值改为“us”，然后在终端（文字终端，不是虚拟终端，也就是Ctrl+Alt+F2或F3或F4.......）运行命令：setupcon。最后为了让它立即生效，键入，sudo udevadm trigger --subsystem-match=input --action=change（sudo应该是有无都可以的），或者重启电脑即可。","link":"/2020/06/23/2019/serverKeyWord/"},{"title":"shadowsocks安装","text":"安装pip3yum install python34-pip -ypip3 install shadowsocks 编辑配置文件vim /etc/shadows.conf{ “server”:”0.0.0.0”, “port_password”:{ “9001”:”vb6Zx5ty”, “9002”:”vb6Zx5ty”, “9003”:”vb6Zx5ty” }, “timeout”:300, “method”:”aes-256-cfb”, “fast_open”: false} #注：配置文件中，启动了三个监听端口 启动ssserver -c /etc/shadows.conf -d start &amp;","link":"/2020/06/23/2019/shadowsocks/"},{"title":"shell脚本的一些语法","text":"记录自己的一些使用shell脚本的数据 获取进程的pid号：ps -ef | grep tomcat/ | grep -v grep | awk ‘{print $2}’ 123这个脚本首先用ps -ef | grep tomcat-tuiguang/ 获得了进程信息中包含 tomcat-tuiguang/ 的进程信息，这样出来的结果中会包含grep本身，所以我们需要用 | grep -v grep 来排除grep本身，然后通过 awk '{print $2}'来打印出要找的进程。上述例子中只是将进程id号打印出来，当然也可以修改为将tomcat进程kill掉，如下脚本：ps -ef | grep tomcat-tuiguang/ | grep -v grep | awk '{print $2}' | sed -e &quot;s/^/kill -9 /g&quot; | sh - 获取脚本的全路径: DIR=”$( cd “$( dirname “${BASH_SOURCE[0]}” )” &amp;&amp; pwd )” 获取当前系统时间: IME=”date +%Y-%m-%d.%H:%M:%S”","link":"/2020/06/23/2019/shell/"},{"title":"sonarQube代码配置","text":"java代码规范工具安装和Idea下的使用1234567预置条件1.已安装JAVA环境2.已安装有MySQL数据库软件下载地址：http://www.sonarqube.org/downloads/下载SonarQube与SonarQube Runner中文补丁包下载：http://docs.codehaus.org/display/SONAR/Chinese+Pack 数据库配置 1234567进入数据库命令#mysql -u root -pmysql&gt; CREATE DATABASE sonar CHARACTER SET utf8 COLLATE utf8_general_ci; mysql&gt; CREATE USER 'sonar' IDENTIFIED BY 'sonar';mysql&gt; GRANT ALL ON sonar.* TO 'sonar'@'%' IDENTIFIED BY 'sonar';mysql&gt; GRANT ALL ON sonar.* TO 'sonar'@'localhost' IDENTIFIED BY 'sonar';mysql&gt; FLUSH PRIVILEGES; 安装sonar 12345#vi conf/sonar.propertiessonar.jdbc.username=sonarsonar.jdbc.password=sonarsonar.jdbc.url=jdbc:mysql://test12.kingsilk.xyz:3306/sonar?useUnicode=true&amp;characterEncoding=utf8&amp;rewriteBatchedStatements=true&amp;useConfigs=maxPerformance将上面几行注释打开 启动服务 1234目录切换至sonar的&lt;install_directory&gt;/bin/linux-x86-64/目录，启动服务#./sonar.sh start 启动服务#./sonar.sh stop 停止服务#./sonar.sh restart 重启服务 安装sonar-runner 123sonar是一个平台，运行还需要其他插件http://docs.sonarqube.org/display/SCAN/Analyzing+with+SonarQube+Scanner包含(maven jenkins) 添加到jenkins中 1234567http://docs.sonarqube.org/display/SCAN/Analyzing+with+SonarQube+Scanner+for+Jenkins jenkins添加sonarQbue plugins在system config中填写 SonarQube servers必须配置：SonarQube Scanner ，用来扫描windows中配置：SonarQube Scanner for MSBuild在jenkins任务中进行配置：add build step添加:Execute SonarQube Scanner 。","link":"/2020/06/23/2019/sonar/"},{"title":"android&#x2F;cordova&#x2F;splashscreen说明","text":"配置说明 自动隐藏启动页面AutoHideSplashScreen（默认为：true) 1&lt;preference name=&quot;AutoHideSplashScreen&quot; value=&quot;true&quot; /&gt; 显示启动页面的时间长度SplashScreenDelay(默认为：3000) 123&lt;preference name=&quot;SplashScreenDelay&quot; value=&quot;3000&quot; /&gt;若想禁用启动页面，可设置为：&lt;preference name=&quot;SplashScreenDelay&quot; value=&quot;0&quot;/&gt;如果是iOS平台上想禁止启动页面，还需要添加&lt;preference name=&quot;FadeSplashScreenDuration&quot; value=&quot;0&quot;/&gt; 启动页面淡入淡出的效果 12345是否显示淡入淡出效果FadeSplashScreen(默认为：true)&lt;preference name=&quot;FadeSplashScreen&quot; value=&quot;false&quot;/&gt;淡入淡出效果的执行时间长度FadeSplashScreenDuration(默认为：500)&lt;preference name=&quot;FadeSplashScreenDuration&quot; value=&quot;750&quot;/&gt;注意：FadeSplashScreenDuration时间是包含在SplashScreenDelay的时间里的。 启动页面是否允许旋转（默认为：true） 1234&lt;preference name=&quot;ShowSplashScreenSpinner&quot; value=&quot;false&quot;/&gt;插件还可以通过js代码调用，提供有以下两个方法：navigator.splashscreen.hide();//隐藏启动页面navigator.splashscreen.show();//显示启动页面 在Android平台下的特殊设置 1234&lt;preference name=&quot;SplashMaintainAspectRatio&quot; value=&quot;true|false&quot; /&gt;&lt;preference name=&quot;SplashShowOnlyFirstTime&quot; value=&quot;true|false&quot; /&gt;SplashMaintainAspectRatio：选填项，默认为false。当设置为true时，则不会拉伸图片来填充屏幕，会以图片原始比例显示图片。SplashShowOnlyFirstTime：选填项，默认为true。当设置为false时，APP通过navigator.app.exitApp()代码退出app后，在下次打开APP时，还会显示启动页面。若为true时，就不会出现。","link":"/2020/06/23/2019/splashscreen/"},{"title":"tengine的安装和使用","text":"由于官方的 Nginx 缺乏一些常用特性。比如： 对于负载均衡，nginx 不支持 sticky session 方式。如果使用 ip hash, 也可能会负载不均衡。 不支持对后台服务的health check。 因此，服务器上决定使用 Tengine 来取代 Nginx 官方版。 安装 安装依赖 123456yum install openssl openssl-devel# 或者sudo apt-get install openssl libssl-devsudo apt-get install build-essentialsudo apt-get install linux-kernel-headerssudo apt-get install gcc libpcre3 libpcre3-dev zlib1g-dev 下载、编译并安装 12345678910mkdir /usr/local/tenginecd /tmpwget http://tengine.taobao.org/download/tengine-2.1.0.tar.gztar zxvf tengine-2.1.0.tar.gzchown -R root:root tengine-2.1.0cd tengine-2.1.0./configure --prefix=/usr/local/tengine/tengine-2.1.0 --user=nginxmakemake install 修改配置 12345678910cd /usr/local/tengine/tengine-2.1.0mkdir conf/conf.dvi conf/nginx.conf# 1. 启用 &quot;log_format main ...&quot;# 2. 在 &quot;http {...}&quot; 的 最后一行 加入 &quot;include conf.d/*.conf;&quot;# 3. 在最开始，设置 `user www`, 以非root 用户运行# 4. 修改 worker_process 为 CPU 核心数量useradd wwwchown -R www:www logs centos 7 新建 systemd 所需的 service 文件： vi /usr/lib/systemd/system/tengine.service : 12345678910111213141516171819[Unit]Description=Tengine ServerAfter=network.target[Service]Type=forkingExecStartPre=/usr/local/tengine/tengine-2.1.0/sbin/nginx -tExecStart=/usr/local/tengine/tengine-2.1.0/sbin/nginxExecReload=/bin/kill -s HUP $MAINPIDExecStop=/bin/kill -s QUIT $MAINPIDWorkingDirectory=/usr/local/tengine/tengine-2.1.0/PIDFile=/usr/local/tengine/tengine-2.1.0/logs/nginx.pidRestart=alwaysUser=rootLimitNOFILE=65535PrivateTmp=true[Install]WantedBy=multi-user.target 启用、启动 123systemctl enable tenginesystemctl start tenginesystemctl status tengine centos 6 下载 init.d 脚本。从 这里 为 CentOS 下载 Red Hat /etc/init.d/nginx, 并保存到 /etc/init.d/nginx 修改 /etc/init.d/nginx , 12345678910 nginx=&quot;/usr/local/tengine-2.1.0/sbin/nginx&quot; NGINX_CONF_FILE=&quot;/usr/local/tengine-2.1.0/conf/nginx.conf&quot; ``` ### ubuntu参考[这里](http://wiki.nginx.org/Upstart)1. make sudo apt-get install libpcre3 libpcre3-devsudo apt-get install openssl libssl-dev 1231. `vi /etc/init/tengine.conf` mac123456789101112131415161718192021---------------------------- 需要PCRE依赖，没报错跳过装nginx的时候报错：./configure: error: the HTTP rewrite module requires the PCRE library.[##]、访问ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre下载完成之后，使用CD命令进入到相应的下载文件夹，执行命令：sudo tar xvfz pcre-8.12.tar.gz 解压文件解压完成之后，执行命令cd pcre-8.12sudo ./configure --prefix=/usr/local --enable-utf8 sudo make sudo make install ---------------------------- 需要openssl依赖，没报错跳过================= openssl 不需要安装，tengin中使用的时源码包，下面介绍的只是如果安装的方法安装/替换:openssl如果你是32位系统的mac，那么输入 ./config --prefix=/usr/local/openssl 如果你是64位系统的mac，那么输入 ./Configure darwin64-x86_64-cc --prefix=/usr/local/openssl sudo make sudo make install================--------------------------- mac开发编译tengine12345678910./configure --with-openssl=/usr/local --prefix=/usr/local/openssl --with-pcre=/usr/pcre注：上面制定的路径都是未编译的文件夹，直接解压缩的。xxxxxxxxxxxxxxx 64位电脑注意，过程中有5秒时间要求输入以下，也可以不输./Configure darwin64-x86_64-cc, 该解决方法可能不行，还是会出现下面的问题(注)：出现ld: symbol(s) not found for architecture x86_64 。 这是由于64位电脑编译openssl错误导致的解决方法：手动修改:vi objs/Makefile ./config --prefix=/Users/xxx/Downloads/openssl-1.0.1e/.openssl no-shared no-threads改成./Configure darwin64-x86_64-cc --prefix=/Users/xxx/Downloads/openssl-1.0.1e/.openssl no-shared no-threads注：改了上面的问题还是会出现，这时候删除openssl文件，重新解压，在重新重第一不开始 tengine1234567891011121314151617181920description &quot;tengine http daemon&quot; start on (filesystem and net-device-up IFACE=lo) stop on runlevel [!2345] env DAEMON=/usr/local/tengine/tengine-2.1.0/sbin/nginx env PID=/usr/local/tengine/tengine-2.1.0/logs/nginx.pid expect fork respawn respawn limit 10 5 #oom never pre-start script $DAEMON -t if [ $? -ne 0 ] then exit $? fi end script exec $DAEMON 启动 12sudo service tengine statussudo service tengine start tengine使用演示配置1.复杂配置 12345678910111213141516171819202122232425262728293031323334353637383940414243 server { listen *:80; server_name {{域名}}; root /404; client_max_body_size 20m; ignore_invalid_headers off; access_log logs/{{成功日志}}.access.log main; error_log logs/{{错误日志}}.error.log;#GZIP配置 gzip on; gzip_min_length 1k; gzip_buffers 4 16k; gzip_http_version 1.0; gzip_comp_level 2; gzip_types text/plain text/css application/javascript text/javascript application/x-javascript text/xml application/xml application/xml+rss application/json; gzip_vary off; gzip_disable &quot;MSIE [1-6]\\.&quot;; location ~ /local/test/(\\d+) { # 这个必须在前面 set $p $1; proxy_pass http://localhost:$p; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; } location ~ /local/test/ { set $p 9999; if ( $arg__ddnsPort ~ &quot;^(\\d*)$&quot; ) { set $p $1; } proxy_pass http://localhost:$1; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; } } 2.简单配置没有变量 1234567891011121314151617181920212223242526server {listen *:16000;server_name {{域名}};root html;index index.html index.htm;access_log logs/{{成功日志}}.access.log main;error_log logs/{{错误日志}}.error.log;`//alias会直接使用定义的路径.root会在定义的路径后面加上location`location /local/test/ { (alias/root) /home/zll/work/git-repo/kingsilk/qh-wap-front/target/dist/;} location /local/test/16000/ { alias /home/zll/work/git-repo/kingsilk/qh-wap-front/target/dist/;}location /local/test/16000/api/ { proxy_pass http://localhost:16030;proxy_set_header Host $host; # ??? $http_host;proxy_set_header X-Real-IP $remote_addr;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;proxy_set_header X-Forwarded-Proto $scheme;} }","link":"/2020/06/23/2019/tengine/"},{"title":"ssh转发","text":"ssh转发使用代理1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465http://www.inet.no/dante/Dante -- Proxy communication solutionssh的三个强大的端口转发命令：QUOTE:ssh -C -f -N -g -L listen_port:DST_Host:DST_port user@Tunnel_Hostssh -C -f -N -g -R listen_port:DST_Host:DST_port user@Tunnel_Hostssh -C -f -N -g -D listen_port user@Tunnel_Host-f 参数：表示连接成功后，转入后台运行。-N 参数：表示只连接远程主机，不打开远程shell；-T 参数：表示不为这个连接分配TTY；-p port Connect to this port. Server must be on the same port.被登录的ssd服务器的sshd服务端口。-L port:host:hostport将本地机(客户机)的某个端口转发到远端指定机器的指定端口. 工作原理是这样的, 本地机器上分配了一个 socket 侦听 port 端口, 一旦这个端口上有了连接, 该连接就经过安全通道转发出去, 同时远程主机和 host 的 hostport 端口建立连接. 可以在配置文件中指定端口的转发. 只有 root 才能转发特权端口. IPv6 地址用另一种格式说明: port/host/hostport-R port:host:hostport将远程主机(服务器)的某个端口转发到本地端指定机器的指定端口. 工作原理是这样的, 远程主机上分配了一个 socket 侦听 port 端口, 一旦这个端口上有了连接, 该连接就经过安全通道转向出去, 同时本地主机和 host 的 hostport 端口建立连接. 可以在配置文件中指定端口的转发. 只有用 root 登录远程主机才能转发特权端口. IPv6 地址用另一种格式说明: port/host/hostport-D port指定一个本地机器 “动态的'’ 应用程序端口转发. 工作原理是这样的, 本地机器上分配了一个 socket 侦听 port 端口, 一旦这个端口上有了连接, 该连接就经过安全通道转发出去, 根据应用程序的协议可以判断出远程主机将和哪里连接. 目前支持 SOCKS4 协议, 将充当 SOCKS4 服务器. 只有 root 才能转发特权端口. 可以在配置文件中指定动态端口的转发.-C Enable compression.压缩数据传输。-N Do not execute a shell or command.不执行脚本或命令，通常与-f连用。-g Allow remote hosts to connect to forwarded ports.在-L/-R/-D参数中，允许远程主机连接到建立的转发的端口，如果不加这个参数，只允许本地主机建立连接Linux命令行下SSH端口转发设定笔记(转)原文:http://be-evil.org/post-167.html在Windows下面我们可以很方便的使用putty等ssh工具来实现将服务器上的端口映射到本机端口来安全管理服务器上的软件或者服务 那么我们换到在Liunx下我们应该怎么做呢？ssh -L 本地端口:服务器地址:服务器端口 用户名@服务器地址 -N参数详解:-L 端口映射参数 本地端口 - 这个任意即可，只要本机没有其他的程序占用这个端口就行服务器地址 - 你需要映射的服务器地址（名称/ip）服务器端口 - 远程的服务器端口-N - 不使用Shell窗口，纯做转发的时候用，如果你在映射完成后继续在服务器上输入命令，去掉这个参数即可例子A:我们想远程管理服务器上的MySQL,那么使用下面命令ssh -L 3306:127.0.0.1:3306 user@emlog-vps -N运行这个命令之后，ssh将会自动将服务器的3306映射到本机的3306端口，我们就可以使用任意MySQL客户端连接 localhost:3306即可访问到服务器上的MySQL了。例子B:一次同时映射多个端口ssh -L 8888:www.host.com:80-L 110:mail.host.com:110 \\ 25:mail.host.com:25 user@host -N这个命令将自动把服务器的80，110，25端口映射到本机的8888，110和25端口 以上命令在ubuntu 9.10 上测试通过... 样例 样例内网穿透:ssh -CfNg -R 0.0.0.0:8080:127.0.0.1:8080 root@ip12345说明:A有公网IP. B是内网.执行上面的语句,访问外网8080端口时候,会穿透到内网上服务器的8080端口.备注:如果发现A服务器监听的是本地地址,只允许本地开放.那么需要修改A机器的ssh配置.1. vi /etc/ssh/sshd_config2. 打开 GatewayPort（删除前面的 # 号，将其设置为 yes）3. systemctl restart sshd ssh对方机子非22端口123456789101112131415161718192021222324252627282930 windows路径: C:\\Users\\Administrator\\.sshlinux路径: /home/administrator/.ssh如果该路径下没有config文件，则创建一个。config中添加如下内容：如是以域名访问的则添加如下内容：（注意修改xxx为你的远程仓库的名称）Host xxxHostName xxx.comPort 3333如是以ip访问的，则添加如下内容:（注意修改ip为你的远程仓库ip）Host &quot;211.111.xx.xxx&quot;Port 3333注意如果 git 是 ssh 方式免密认证方式登录的话，且你的私钥文件名字不是 id_rsa 则还需要在 config 文件中填加：IdentityFile ~/.ssh/&lt;你的密钥名&gt;config中还可以指定User，如User &quot;git&quot;","link":"/2020/06/23/2019/sshforwrod/"},{"title":"配置使用tomcat的session集中存储","text":"session存储集群中有4种存储session的方式 Session Sticky 。 每次请求都到一台机子中去 Session Replication 每个容器对session进行同步复制 Session数据集中存储 使用redis Cookie Based 数据放到cookie中传输 tomcat中配置Session Replication tomcat复制2份 端口勿冲突,不需要做任何修改，在这一行的下面加入如下代码：1234567891011121314151617181920212223242526272829303132333435363738394041-- tomcat中有这么一行代码，打开注释即可 &lt;Cluster className=&quot;org.apache.catalina.ha.tcp.SimpleTcpCluster&quot; channelSendOptions=&quot;8&quot;&gt; &lt;Manager className=&quot;org.apache.catalina.ha.session.DeltaManager&quot; expireSessionsOnShutdown=&quot;false&quot; notifyListenersOnReplication=&quot;true&quot;/&gt; &lt;Channel className=&quot;org.apache.catalina.tribes.group.GroupChannel&quot;&gt; &lt;Membership className=&quot;org.apache.catalina.tribes.membership.McastService&quot; address=&quot;228.0.0.4&quot; port=&quot;45564&quot; frequency=&quot;500&quot; dropTime=&quot;3000&quot;/&gt; &lt;Receiver className=&quot;org.apache.catalina.tribes.transport.nio.NioReceiver&quot; address=&quot;auto&quot; port=&quot;4000&quot; autoBind=&quot;100&quot; selectorTimeout=&quot;5000&quot; maxThreads=&quot;6&quot;/&gt; &lt;Sender className=&quot;org.apache.catalina.tribes.transport.ReplicationTransmitter&quot;&gt; &lt;Transport className=&quot;org.apache.catalina.tribes.transport.nio.PooledParallelSender&quot;/&gt; &lt;/Sender&gt; &lt;Interceptor className=&quot;org.apache.catalina.tribes.group.interceptors.TcpFailureDetector&quot;/&gt; &lt;Interceptor className=&quot;org.apache.catalina.tribes.group.interceptors.MessageDispatch15Interceptor&quot;/&gt; &lt;/Channel&gt; &lt;Valve className=&quot;org.apache.catalina.ha.tcp.ReplicationValve&quot; filter=&quot;&quot;/&gt; &lt;Valve className=&quot;org.apache.catalina.ha.session.JvmRouteBinderValve&quot;/&gt; &lt;Deployer className=&quot;org.apache.catalina.ha.deploy.FarmWarDeployer&quot; tempDir=&quot;/tmp/war-temp/&quot; deployDir=&quot;/tmp/war-deploy/&quot; watchDir=&quot;/tmp/war-listen/&quot; watchEnabled=&quot;false&quot;/&gt; &lt;ClusterListener className=&quot;org.apache.catalina.ha.session.JvmRouteSessionIDBinderListener&quot;/&gt; &lt;ClusterListener className=&quot;org.apache.catalina.ha.session.ClusterSessionListener&quot;/&gt; &lt;/Cluster&gt;","link":"/2020/06/23/2019/tomcat-session/"},{"title":"tomcat设置启动参数","text":"tomcat设置启动参数个人倾向不修改原文件进行添加覆盖 可以直接修改catalina.sh本身的启动文件进行添加参数 额外添加文件(后续自己修改添加也比较方便。只知道自己是否添加过文件) 在tomcat/bin目录下新建setenv.sh脚本文件 根据自己的需要进行调整参数。后面注释自己复制的时候去掉，这里只是提供说明 1234567891011121314151617181920212223242526#!/bin/bash // 引入系统变量，大部分linux没有设置全局变量，所以这里需要自己导入变量，比如java环境. /etc/profile.d/air.sh // 打印日志的格式export today=`date +%Y%m%d%H%M%S`export CATALINA_HOME=&quot;$( cd &quot;$( dirname &quot;${BASH_SOURCE[0]}&quot; )&quot; &amp;&amp; cd .. &amp;&amp; pwd )&quot; // 管理进程export CATALINA_PID=${CATALINA_HOME}/tomcat.pid // 以下参数可以查找jvmexport CATALINA_OPTS=' -server -XX:+UnlockCommercialFeatures -XX:+FlightRecorder -Xms2048m -Xmx2048m -Xss256k -XX:ErrorFile=${CATALINA_HOME}/logs/start.at.${today}.hs_err_pid.log -XX:+UseConcMarkSweepGC -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=${CATALINA_HOME}/logs/start.at.${today}.dump.hprof -XX:+PrintGCDateStamps -XX:+PrintGCDetails -Xloggc:${CATALINA_HOME}/logs/start.at.${today}.gc.log -Duser.timezone=GMT+08 -Dfile.encoding=UTF-8 ' 附录：设置java的垃圾回收器 这里有五种可以在应用里使用的垃圾回收类型。仅需要使用JVM开关就可以在我们的应用里启用垃圾回收策略。让我们一起来逐一了解： Serial GC（-XX:+UseSerialGC）：Serial GC使用简单的标记、清除、压缩方法对年轻代和年老代进行垃圾回收，即Minor GC和Major GC。Serial GC在client模式（客户端模式）很有用，比如在简单的独立应用和CPU配置较低的机器。这个模式对占有内存较少的应用很管用。 Parallel GC（-XX:+UseParallelGC）：除了会产生N个线程来进行年轻代的垃圾收集外，Parallel GC和Serial GC几乎一样。这里的N是系统CPU的核数。我们可以使用 -XX:ParallelGCThreads=n 这个JVM选项来控制线程数量。并行垃圾收集器也叫throughput收集器。因为它使用了多CPU加快垃圾回收性能。Parallel GC在进行年老代垃圾收集时使用单线程。 Parallel Old GC（-XX:+UseParallelOldGC）：和Parallel GC一样。不同之处，Parallel Old GC在年轻代垃圾收集和年老代垃圾回收时都使用多线程收集。 并发标记清除（CMS）收集器（-XX:+UseConcMarkSweepGC)：CMS收集器也被称为短暂停顿并发收集器。它是对年老代进行垃圾收集的。CMS收集器通过多线程并发进行垃圾回收，尽量减少垃圾收集造成的停顿。CMS收集器对年轻代进行垃圾回收使用的算法和Parallel收集器一样。这个垃圾收集器适用于不能忍受长时间停顿要求快速响应的应用。可使用 -XX:ParallelCMSThreads=n JVM选项来限制CMS收集器的线程数量。 G1垃圾收集器（-XX:+UseG1GC) G1（Garbage First）：垃圾收集器是在Java 7后才可以使用的特性，它的长远目标时代替CMS收集器。G1收集器是一个并行的、并发的和增量式压缩短暂停顿的垃圾收集器。G1收集器和其他的收集器运行方式不一样，不区分年轻代和年老代空间。它把堆空间划分为多个大小相等的区域。当进行垃圾收集时，它会优先收集存活对象较少的区域，因此叫“Garbage First”。","link":"/2020/06/23/2019/tomcat-setenv/"},{"title":"tomcat开启apr功能","text":"启用apr模式步聚安装依赖库 因为apr模式本质是使用JNI技术调用操作系统IO接口，需要用到相关API的头文件 yum install apr-devel yum install openssl-devel yum install gcc yum install make1注意：openssl库要求在0.9.7以上版本，APR要求在1.2以上版本，用rpm -qa | grep openssl检查本机安装的依赖库版本是否大于或等于apr要求的版本。 安装apr动态库 进入tomcat的bin目录，解压tomcat-native.tar.gz文件，并进入tomcat-native-1.2.7-src/native目录，执行./configure &amp;&amp; make &amp;&amp; make install 命令1apr如何openssh版本错误,手动指定安装目录: ./configure --with-apr=/usr/local/apr --with-ssl=/usr/local/openssl 编辑$TOMCAT_HOME/bin/catalina.sh文件，在虚拟机启动参数JAVA_OPTS中添加java.library.path参数，指定apr库的路径 JAVA_OPTS=”$JAVA_OPTS -Djava.library.path=/usr/local/apr/lib” Tomcat8以下版本，需要指定运行模式，将protocol从HTTP/1.1改成org.apache.coyote.http11.Http11AprProtocol 123&lt;Connector port=&quot;8080&quot; protocol=&quot;org.apache.coyote.http11.Http11AprProtocol&quot;connectionTimeout=&quot;20000&quot;redirectPort=&quot;8443&quot; /&gt; apr和openssl版本错误 apr地址:http://apr.apache.org/download.cgi#apr1 ssl地址:https://www.openssl.org/source/ apr安装1234tar zxvf apr-1.4.5.tar cd apr-1.4.5 ./configure --prefix=/usr/local/apr make &amp;&amp; make install openssl安装1234tar -xvzf openssl-1.1.0e.tar.gzcd openssl-1.1.0e/./config --prefix=/usr/local/openssl --openssldir=/usr/local/opensslmake &amp;&amp; make install","link":"/2020/06/23/2019/tomcatApr/"},{"title":"tomcat开启远程war包上传工程","text":"开启用户管理 编辑tomcat-user.xml文件 添加一下内容123&lt;role rolename=&quot;manager-gui&quot;/&gt; &lt;role rolename=&quot;manager-script&quot;/&gt; &lt;user username=&quot;admin&quot; password=&quot;admin&quot; roles=&quot;manager-gui, manager-script&quot;/&gt; 添加后依然403无法访问 manager 配置有问题，因为只允许本机访问所以其他人无法访问，12345$TOMCAT_HOME/webapps/manager/META-INF/context.xml文件中&lt;Context antiResourceLocking=&quot;false&quot; privileged=&quot;true&quot; &gt; &lt;Valve className=&quot;org.apache.catalina.valves.RemoteAddrValve&quot; allow=&quot;127\\.\\d+\\.\\d+\\.\\d+|::1|0:0:0:0:0:0:0:1&quot; /&gt;&lt;/Context&gt; 只需加入本机ip即可，或者注释掉上面的语句1234&lt;Context antiResourceLocking=&quot;false&quot; privileged=&quot;true&quot; &gt; &lt;Valve className=&quot;org.apache.catalina.valves.RemoteAddrValve&quot; allow=&quot;127\\.\\d+\\.\\d+\\.\\d+|::1|0:0:0:0:0:0:0:1|10.0.1.143&quot; /&gt;&lt;/Context&gt;","link":"/2020/06/23/2019/tomcatOriginWar/"},{"title":"ubuntu一些配置","text":"打印 u盘安装使用 usb-creator-gtk 来创建可以启动U盘。该程序可以到 Ubuntu software center 中查找 ‘Startup disk creator’ 进行安装 显卡驱动1234567lspci -nnk | grep VGA # 查看显卡型号sudo add-apt-repository ppa:xorg-edgers/ppa # 安装 Nvidia 驱动的 ppasudo apt-get updatesudo apt-get purge nvidia* # 移除旧的的显卡驱动# 安装新的驱动。最好通过 start-&gt; Preferences -&gt; Aditional Drivers 选择安装sudo apt-get install nvidia-349 版本ubuntu 所有的版本号以及 codeName : 1lsb_release -a # 查看当前安装的 ubuntu 的版本 dpkg1dpkg -i package.deb apt1234567891011121314151617181920apt-get -s install &lt;package&gt;apt-cache policy &lt;package&gt;apt-cache search &lt;package&gt; # 模糊查找packageapt-show-versions &lt;package&gt;aptitude versions &lt;package&gt;# 查询安装包安装了那些内容dpkg-query -L &lt;package_name&gt;# 列出所有已经安装的软件包dpkg-query -l # 查找指定的文件属于哪一个packagesudo apt-get install apt-filesudo apt-file updateapt-file search filenameapt-file search /path/to/file# 如果通过 dpkg 或 apt-get 安装时，依赖未满足，可以使用该命令删除sudo apt-get remove xxx 778812345678sudo apt-get install rar # rarsudo apt-get install libreoffice # libreofficesudo apt-get install gnome-calculator # 计算器sudo apt-get install curlsudo apt-get install p7zip # 7z7z x xxx.7z -r -o /home/xx # 7z : 解压7z a -t7z -r manager.7z /home/manager/* # 7z : 压缩 修改主机名1234567sudo hostname your-new-hostnamesudo vim /etc/hostnameyour-new-hostnamesudo vim /etc/hosts127.0.1.1 your-new-hostname 中文字体参考这里 1234567sudo apt-get install ttf-wqy-microhei #文泉驿-微米黑sudo apt-get install ttf-wqy-zenhei #文泉驿-正黑sudo apt-get install xfonts-wqy #文泉驿-点阵宋体sudo apt-get install fonts-wqy-microhei fonts-wqy-zenhei # sudo mkfontscale# sudo mkfontdir# sudo fc-cache -fv 输入法123456789101112131415161718192021sudo add-apt-repository ppa:fcitx-team/nightlysudo apt-get updatesudo apt-get install fcitx#sudo apt-get install gnome-language-selectorim-config # or im-switch# 以下三种输入法选择其一就可以了。sudo apt-get install fcitx-googlepinyin sudo apt-get install fcitx-sunpinyin# 搜狗输入法 for linux http://pinyin.sogou.com/linux/# 后续配置# 防止Fcitx的Ctrl+Shift+F进行繁简转换：语言指示图标上右键-&gt;Configure-&gt;Addon# -&gt;选中 &quot;Simple Chinese To Tranditional Chinese&quot; -&gt; 点击底部的Configure按钮# -&gt; 取消相应的快捷键即可。#fcitx -r --enable fcitx-qimpanel#fcitx-qimpanel gedit安装1234567891011sudo apt-cache search geditsudo apt-get install gedit sudo apt-get install gedit-plugins# gmate https://github.com/gmate/gmatesudo apt-add-repository ppa:ubuntu-on-rails/ppasudo apt-get updatesudo apt-get install gedit-gmate# 移除旧的 文本编辑器 leafpadsudo apt-get remove leafpad 配置1234567891011121314View -&gt; 取消选中 'toolbar'Edit -&gt; Preferences : View -&gt; 选中 'Display line numbers' -&gt; 选中 'Highlight current line' -&gt; 选中 'Highlight matching brackets' Editor -&gt; Tab width 设置为 4 -&gt; 选中 'Insert spaces instead tabs' -&gt; 选中 'Enable automatic indentation' -&gt; 取消选中 'Create a backup copy of files before saving' -&gt; 取消选中 'Autosave files every 10 minutes' Font &amp; Colors -&gt; 选择一个自己喜爱的 Color Schema gnome-terminal123456789101112131415161718gnome-terminal : Edit : Profiles : New : xxx : 并设置默认为该 profile: General : 取消选中 Use the system fixed width font，并选择使用 Monospace 14 / ubuntu mono 14 : 选中 Use custom default terminal size ： 120x30: Title and Command : 选中 Run command as login shell // : 选中 Run a cunstom command instead of my shell，并输入 `env TERM=xterm-color /bin/bash`# gnome-terminal 彩色显示vi /etc/profile.d/xxx.shexport TERM=xterm-color# 使命令行提示符只显示父目录，而非整个路径vi ~/.bashrc查找 PS1 并将其中最后的 \\w 替换为 \\W修改ll别名alias ll='ls -lF' 常用快捷键 hot key descrption Alt+1 主键盘上的额数字键，可以快速切换至第N个标签页 Ctrl+Shift+T 开启新的标签页 Ctrl+Shift+C 复制 Ctrl+Shift+V 粘贴 Ctrl+E 清屏 Ctrl+R 搜索历史命令 Ctrl+W 向后删除一个词 Ctrl+C 取消当前行的输入，新开始一行 Ctrl+U 清空当前输入行 Ctrl+D 如果当前行是空白行时，可以退出登录，直到退出当前窗口。 文件管理器 PCManFM123Edit : Preference : General : Default View : Detailed list view Layout : 选中 Filesystem root 桌面图标123456789101112131415# 复制既有应用的图标ll /usr/share/applications/*.desktopcp /usr/share/applications/firefox.desktop ~/Desktop# 自定义一个图标vi ~/Desktop/idea-IU-135.909.desktop[Desktop Entry]Version=1.0Type=ApplicationTerminal=falseIcon[en_US]=gnome-panel-launcherName[en_US]=idea-IU-135.909Exec=env UBUNTU_MENUPROXY= /home/zll/work/idea-IU-135.909/bin/idea.shIcon=/home/zll/work/idea-IU-135.909/bin/idea.png chromium-browser1[me@locahost:~]$ sudo apt-get install chromium-browser NOTICE: 该浏览器中文乱码可以参考这里 1sudo rm /etc/fonts/conf.d/65-droid-sans-fonts.conf service123# 等价于CentOS上的chkconfig[me@localhost:~]$ sudo apt-get install sysv-rc-conf[me@localhost:~]$ sudo sysv-rc-conf --help JDK安装Oracle JDK1234567891011121314sudo apt-get install python-software-propertiessudo add-apt-repository ppa:webupd8team/javasudo apt-get updatesudo apt-get install oracle-java7-installer# 缓存文件# /var/cache/oracle-jdk8-installer/jdk-8u5-linux-x64.tar.gz# abortsudo killall -9 apt-getps aux | grep dpkg # kill themdpkg --configure -asudo dpkg -r oracle-java7-installer qq参考这里 12345678910111213141516171819202122232425262728#sudo add-apt-repository ppa:ubuntu-wine/ppa#sudo apt-get update#sudo apt-get install wine1.7sudo apt-get install \\ libasound2 \\ libgtk2.0-0 \\ liblcms2-2 \\ libpng12-0 \\ libsm6 \\ libncurses5 \\ libcups2 \\ libpulse0 \\ libmpg123-0 \\ libasound2-plugins \\ ttf-wqy-microhei sudo apt-get install libgtk2.0-0:i386sudo apt-get install ia32-libssudo apt-get install lib32ncurses5sudo dpkg -i wine-qqintl_0.1.3-2_i386.debsudo apt-get install -f#sudo apt-get remove wine-qqintlcp /usr/share/applications/qqintl.desktop ~/Desktop python12sudo apt-get install python-devsudo apt-get install python-pip Ruby123456789101112131415# 1.9.3sudo apt-get install ruby1.9.3# FIXME 2.0+wget http://cache.ruby-lang.org/pub/ruby/2.1/ruby-2.1.1.tar.gztar zxvf ruby-2.1.1.tar.gzcd ruby-2.1.1/./configure???# RVMcurl -sSL https://get.rvm.io | bash -s stable# in new consolervm install 2.1.1 常见问题 禁止自动login 1234$ sudo vi /etc/lightdm/lightdm.conf[SeatDefaults]#autologin-user=xxx # comment this line#autologin-user-timeout=0 # comment this line Lununtu 截屏Lununtu Keyboard 123456789101112131415161718192021222324252627282930313233343536373839404142$ vi ~/.config/openbox/lubuntu-rc.xml &lt;keybind key=&quot;W-r&quot;&gt; &lt;action name=&quot;Execute&quot;&gt; &lt;!-- &lt;command&gt;lxsession-default launcher_manager&lt;/command&gt; --&gt; &lt;command&gt;lxpanelctl run&lt;/command&gt; &lt;/action&gt; &lt;/keybind&gt; &lt;!-- Take a screenshot of the current window with scrot when Alt+Print are pressed --&gt; &lt;keybind key=&quot;A-Print&quot;&gt; &lt;action name=&quot;Execute&quot;&gt; &lt;!--&lt;command&gt;lxsession-default screenshot window&lt;/command&gt;--&gt; &lt;command&gt;scrot -u -b&lt;/command&gt; &lt;/action&gt; &lt;/keybind&gt; &lt;!-- Launch scrot when Print is pressed --&gt; &lt;keybind key=&quot;Print&quot;&gt; &lt;action name=&quot;Execute&quot;&gt; &lt;!--&lt;command&gt;lxsession-default screenshot&lt;/command&gt;--&gt; &lt;command&gt;scrot&lt;/command&gt; &lt;/action&gt; &lt;/keybind&gt; &lt;!-- 打开控制台--&gt; &lt;keybind key=&quot;W-t&quot;&gt; &lt;action name=&quot;Execute&quot;&gt; &lt;command&gt;gnome-terminal&lt;/command&gt; &lt;/action&gt; &lt;/keybind&gt; &lt;!-- Lubuntu 锁屏--&gt; &lt;keybind key=&quot;W-l&quot;&gt; &lt;action name=&quot;Execute&quot;&gt; &lt;!-- &lt;command&gt;xscreensaver-command -lock&lt;/command&gt;--&gt; &lt;command&gt;dm-tool lock&lt;/command&gt; &lt;/action&gt; &lt;/keybind&gt;$ openbox --reconfigure SSH123sudo apt-get install openssh-clientsudo apt-get install openssh-serversudo service ssh status 登录画面的number lock1234567891011121314151617181920212223242526# for loginsudo vi /etc/xdg/lubuntu/lxdm/lxdm.conf[base]numlock=1sudo vi /etc/lxdm/default.conf[base]numlock=1# for lock screensudo vi /etc/lightdm/lightdm.conf.d/20-lubuntu.confgreeter-setup-script=/usr/bin/numlockx on# ???sudo apt-get install numlockxecho &quot;/usr/bin/numlockx on&quot; | sudo tee -a /etc/xdg/lxsession/Lubuntu/autostartsudo vi /etc/X11/xinit/xinitrc# 追加一下几行/usr/bin/numlockx on # ???sudo vi /usr/share/lightdm/lightdm.conf.d/60-lightdm-gtk-greeter.confgreeter-setup-script=/usr/bin/numlockx on Adobe Flash Player火狐安装的版本一般都比较低，而Chromium浏览器自带一般相对高些。具体可以通过该网页检测查看。 1234sudo apt-get install flashplugin-installer #sudo apt-get install pepperflashplugin-nonfree#sudo update-pepperflashplugin-nonfree --install 文件关联12vi ~/.local/share/applications/mimeapps.listcat /usr/share/applications/defaults.list Mount UDF/ISO-13346 镜像1sudo mount -t auto /dev/cdrom0 / media/cdrom0 静态IP地址参考这里 先禁用图形化的网络管理工具12345678sudo vi /etc/NetworkManager/NetworkManager.conf[main]plugins=ifupdown,keyfile,ofono#dns=dnsmasq # 注释掉这一行[ifupdown]#managed=falsemanaged=true # 将值改为true 配置静态IP地址12345678910111213sudo vi /etc/network/interfacesauto loiface lo inet loopbackauto eth0iface eth0 inet staticaddress 192.168.115.222gateway 192.168.115.1netmask 255.255.255.0 dns-nameservers 8.8.8.8 8.8.4.4# ??? DNS貌似也可以配置在 /etc/resolvconf/resolv.conf.d/base 重启网络12sudo service network-manager stopsudo service network-manager start 配置DNS1234567891011121314151617181920# 方法1sudo vi /etc/network/interfaces# 追加一下一行dns-nameservers 192.168.101.1# 方法2sudo vi /etc/resolvconf/resolv.conf.d/basenameserver 8.8.8.8# 最后，更新sudo resolvconf -ucat /etc/resolv.confsudo ifdown eth0 &amp;&amp; sudo ifup eth0cat /etc/resolv.conf# 补充# 可以检测dns有没有在没有记录的时候提供替代地址，比如 189so 网址导航服务dig @8.8.8.8 www.not-exist-domain.com winewine 可以让部分Windows程序运行在Linux环境下，主要原理是其重新实现了Windows的API。 安装参考 netbook/laptop screen brightness12345678910111213# done.xrandr -q | grep &quot; connected&quot;xrandr --output LVDS1 --brightness 0.5 #xrandr --output VGA1 --brightness 0.9#xbacklight -inc XX sudo vi /etc/default/grub # GRUB_CMDLINE_LINUX_DEFAULT=&quot;quiet splash&quot;# OK...............GRUB_CMDLINE_LINUX_DEFAULT=&quot;quiet splash acpi_osi=&quot;#GRUB_CMDLINE_LINUX_DEFAULT=&quot;quiet splash acpi_backlight=vendor&quot;sudo update-grub 远程桌面TO windows1sudo apt-get install grdesktop PHP1234567891011121314151617181920212223242526272829303132333435sudo apt-get install nginxsudo apt-get install php5-fpm php5-cli php5-cgi php5-mysqlsudo service php5-fpm statussudo vi /etc/php5/fpm/php.inicgi.fix_pathinfo=0sudo vi /etc/php5/fpm/pool.d/www.confowner = www-datagroup = www-datalisten.owner = www-datalisten.group = www-datalisten.mode = 0660sudo vi /etc/nginx/sites-available/default location ~ \\.php$ { fastcgi_split_path_info ^(.+\\.php)(/.+)$; # # NOTE: You should have &quot;cgi.fix_pathinfo = 0;&quot; in php.ini # # # With php5-cgi alone: # fastcgi_pass 127.0.0.1:9000; # # With php5-fpm: fastcgi_pass unix:/var/run/php5-fpm.sock; fastcgi_index index.php; include fastcgi_params; }sudo service php5-fpm restartsudo service nginx restartvi /usr/share/nginx/html/my.php&lt;?php phpinfo(); ?&gt;# 访问浏览器 http://localhost/my.php 自动挂载Windows分区1234sudo blkid # 查看各个分区的UUIDid # 查看自己当前账户的uid和gidsudo vi /etc/fstabUUID=519CB82E5888AD0F /media/Data ntfs defaults,gid=1000,uid=1000 0 0 环境变量的配置12345 sudo mkdir /etc/profild.d/xx.sh 通常为电脑的名字 在脚本中输入以下内容：(以java为列) ((#!sh /bin/bash)) 这句可以不写 export JAVA_HOME=/usr/local/jdk1.8.0_91export PATH=$JAVA_HOME/bin:$PATH","link":"/2020/06/23/2019/ubuntu/"},{"title":"uml建模","text":"uml建模我使用Astah","link":"/2020/06/23/2019/umlAstah/"},{"title":"ubuntu无法识别windows下的硬盘（双系统）","text":"双系统下ubuntu无法查看windows硬盘12## 错误提示 Error mounting /dev/sdb4 at /media/xxx/xx: Command-line`mount -t &quot;ntfs&quot; -o&quot;uhelper=udisks2,nodev,nosuid,uid=1000,gid=1000,dmask=0077,fmask=0177&quot;&quot;/dev/sdb4&quot; &quot;/media/eden/文檔&quot;' exited with non-zero exit status14: The disk contains an unclean file system (0, 0). 解决办法123456789101112131415161718１、打开终端，输入sudo fdisk -l 可列出所有的分区情况，找到自己windows硬盘的分区； 设备 启动 起点 终点 块数 Id 系统/dev/sda1 * 63 163846934 81923436 7 HPFS/NTFS/exFAT分区 1 未起始于物理扇区边界。/dev/sda2 163846996 859797503 347975254 f W95 扩展 (LBA)分区 2 未起始于物理扇区边界。/dev/sda5 163846998 404500634 120326818+ 7 HPFS/NTFS/exFAT2、得知分区为：/dev/sdb4，创建挂载目录：sudo mkdir /media/xxx/yyy (xxx为用户名，yyy为挂载的硬盘的名字)３、挂载硬盘：mount -t ntfs-3g /dev/sdb4 /media/xxx/yyy/ -o force４、还是不行，网上一搜，用以下命令，大功告成：sudo ntfsfix /dev/sdb6","link":"/2020/06/23/2019/unableDisk/"},{"title":"网址收藏记录","text":"转载比较好的篇幅 问题点: 2台计算机发送超大文件的实现 路由和转发的区别 自定义通信协议注意点有哪些 计算机网络基础知识 tcp/ip协议群简介 1对我们开发一个高可用的网络是一个基础 java内存介绍篇 1文章补充:虽然后面说明了android的。但同属一个概念。 tcp发送和接收数据的原理概念(多篇文章组合观看): 1 2 3 1234567 文章补充说明： 带着问题点去看：当2台计算机发送一个超大文件，那么发送中的数据存储在哪里,发送方存储在路由器中还是内存中，接收端收到部分数据是在内存中还是硬盘中？接收至一半的数据突然中断,何时会被删除?计算机写入一个可以非常快，发送端是一次发送还是如何发送?发送慢是发送端网络慢，还是路由慢 还是接收端慢 重点词:1.窗口 2.收到确认 重点信息:tcp发送信息有一个窗口维持。同时发送的数据需要确认后才会发送下一个序号数据。 部分理解回答： 发送和接收端都有一个缓冲区。发送端每次发送发送的数据需要接收端回复确认才继续发送下一个序号数据 自定义通信协议基础: 1 2 elasticsearch中文记录 华为云学院","link":"/2020/06/23/2019/urlCollection/"},{"title":"vim一些配置","text":"安装CentOS 的最小化安装默认只安装了最小版的VI，可以通过以下命令安装全部功能的Vim： 12yum install vim-common vim-enhanced vim-minimalsudo apt-get install vim 修改环境变量 12[root@h01 ~]# vi /etc/profile.d/custom.shalias vi=vim 或者 12[root@h01 ~]# vi ~/.bashrcalias vi=vim 修改vim配置文件修改用户级别的 需要修改 ~/.vimrc。修改全局的，需要修改 /etc/vimrc （可以通过 :version 看到） 123456789101112131415161718set nocompatibleset numbercolors desertsyntax onset rulerset showcmdset cursorlineset fileencodings=utf-8,gbkset expandtabset tabstop=4set shiftwidth=4set softtabstop=4set fileformats=unixset hlsearchset formatoptions-=croset paste&quot; set list&quot; comment here filetypevi ~/.vim/filetype.vim, 在 vim 中可以通过 :set syntax? 查看当前 syntax 的值 12autocmd BufRead,BufNewFile my.cnf set syntax=dosiniautocmd BufRead,BufNewFile build.gradle set syntax=groovy colorschema123ll /usr/share/vim/vim74/colors# 或者在vim中:colo &lt;tab&gt; 安装vba插件largeFile,Manualwget http://www.drchip.org/astronaut/vim/vbafiles/LargeFile.vba.gzgunzip LargeFile.vba.gzvi LargeFile.vba:source % 1234:source % 将换行符从dos格式变为unix格式参考：1 1234:update Save any changes.:e ++ff=dos Edit file again, using dos file format ('fileformats' is ignored).:setlocal ff=unix This buffer will use LF-only line endings when written.:w Write buffer using unix (LF-only) line endings. 删除BOM头 12:set nobomb:wq 全局替换1:%s/\\t/ /g tab12345678# 显示空白字符:set list# 替换为空格:%s/\\t/ /g# 不显示空白字符:set nolist 命令模式12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# 文件:open pathToFile # 打开指定的文件:bn # 查看下一个文件:bp # 查看上一个文件:args # 查看当前打开的文件列表:split pathToFile # 在分割窗口中打开指定的文件Ctrl+ww # 在分割窗口中循环切换文件:e ftp://192.168.1.101/xxx.txt # 打开远程文件（FTP）:e \\\\sambahost\\share\\xxx.txt # 打开远程文件（Samba）# 光标移动h # 左移1个字符（可前接数字）l # 右移1个字符（可前接数字）k # 上移1个字符（可前接数字）j # 下移1个字符（可前接数字）^ # 移至行首第一个非空白字符0 # 移至行首&lt;Home&gt; # 移至行首$ # 移至行尾（可前接数字）&lt;End&gt; # 移至行尾w # 向后移动1个单词，光标停在单词首部（可前接数字）b # 向后移动1个单词，光标停在单词首部（可前接数字）e # 向后移动1个单词，光标停在单词尾部（可前接数字）ge # 向后移动1个单词，光标停在单词尾部（可前接数字）# 缩进&lt;&lt; # 当前行向左缩进&gt;&gt; # 当前行向右缩进查看当前set的值:set expandtab? # 打印该选项的使用方法和值:set autoindent! # 该选项值取反（针对bool型）:set option&amp; # 重置该选项值为默认值:verbose set textwidth? # 查看值# 进入插入模式i # 在当前光标位置前插入I # 在当前行的行首插入a # 在当前光标位置后插入A # 在当前行的行尾插入o # 在当前行之后插入一行O # 在当前行之前插入一行# 进入 visual 模式v 插入模式123# 缩进C-d # 当前行向左缩进C-t # 当前行向右缩进 visual 模式12&lt; # 当前选区向左缩进&gt; # 当前选区向右缩进","link":"/2020/06/23/2019/vim/"},{"title":"vm下ubuntu server共享主机文件夹","text":"事实上，虚拟机上自带的VMware-tools就可以实现，但是VMware tools需要自己安装，下面介绍一下安装方法： 安装VMware-tools 点击VMware工具栏’’VM”——“install VMware tools…”，这时桌面会出现光盘形状的VMware Tools，而且会自动跳出目录，里面包含两个文件，”manifest.txt”与”VMwareTools-8.4.5-324285.tar.gz”。(server版本的用命令进入(下文)) cd /media/VMware Tools 进入安装文件目录 cp VMwareTools-8.4.5-324285.tar.gz /tmp 将VMware Tools压缩包拷贝到临时文件夹/tmp下(当前目录是没有权限的) cd /tmp 进入临时文件夹 tar -zxvf VMwareTools-8.4.5-324285.tar.gz 解压该压缩文件 cd vmware-tools-distrib 进入该文件夹 ./vmware-install.pl 安装vmware-tools 一路Enter，VMware-tools就安装成功了。 在vm的设置里面共享 点击 VM——setting——options——shared Folders，选择Always enabled，点击下面Add添加windows中的共享文件夹，我选择的是F盘，然后保存修改。 重新启动ubuntu，你就可以在目录/mnt/hgfsz下发现名为”F”的文件夹了，双击就会发现时windows下的F盘的内容，你可以在ununtu下在里面进行读写操作了。","link":"/2020/06/23/2019/vmShare/"},{"title":"红黑树","text":"红黑树 友情博客链接 重点解读 红黑树是近视平衡。插入 删除比平衡二叉树要快，相对查找要略低。但是相对于其他树来说稳定。在极端情况下也不会蜕变为单边树 红黑树中包含最多黑色节点的路径不会超过 log2n，所以加入红色节点之后，最长路径不会超过 2log2n，也就是说，红黑树的高度近似 2log2n 高度和查找性能成反比。高度高查找慢 redis的zset为何用跳表，不用红黑树 Redis 中的有序集合支持的核心操作主要有以下几个：123456789 1.插入一个数据 1.删除一个数据 1.查找一个数据 1.按照区间查找数据 1.迭代输出有序序列其中，插入、删除、查找以及迭代输出有序序列这几个操作，红黑树也可以完成，时间复杂度和跳表是一样的。但是，按照区间查找数据这个操作，红黑树的效率没有跳表高。跳表可以在 O(logn)时间复杂度定位区间的起点，然后在原始链表中顺序向后查询就可以了，这样非常高效。此外，相比于红黑树，跳表还具有代码更容易实现、可读性好、不容易出错、更加灵活等优点，因此 Redis 用跳表来实现有序集合 二叉树遍历理解二叉树中4种遍历方法","link":"/2020/06/23/2019/%E7%BA%A2%E9%BB%91%E6%A0%91/"},{"title":"Mysql8初始化新建库","text":"mysql8安装mysql8 安装完成后，之前的MariaDB就会被覆盖掉 wget -i -c https://dev.mysql.com/get/mysql80-community-release-el7-3.noarch.rpm yum -y install mysql80-community-release-el7-3.noarch.rpm yum -y install mysql-community-server 启动mysql 启动MySQL服务：systemctl start mysqld.service 查看MySQL服务：systemctl status mysqld.service 查看MySQL是不是开机自启，可以执行命令查看开机自启列表1systemctl list-unit-files|grep enabled 进入mysql 此时如果要进入MySQL得找出root用户的密码，输入命令：grep “password” /var/log/mysqld.log12021-05-10T08:10:47.232877Z 6 [Note] [MY-010454] [Server] A temporary password is generated for root@localhost: [这里是密码] MySql需要重新设置密码才能操作数据库。：ALTER USER ‘root’@’localhost’ IDENTIFIED BY ‘123456’;123注意：先登录进去：mysql -u root -p设置密码的时候需要遵守MySQL密码设置规范，如果不符合规范是不能修改成功的。如下图，我将密码设置为123456，它提示我 密码不符合规范 登录后远程连接备注需要重新创建用户的: 123456789设置允许远程连接。如果直接使用命令：GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY '123456'; 会提示一个语法错误，有人说是mysql8的分配权限不能带密码隐士创建账号了，要先创建账号再设置权限。也有的说8.0.11之后移除了grant 添加用户的功能。创建新用户 admin创建用户：CREATE USER 'admin'@'%' IDENTIFIED BY '123456';允许远程连接：GRANT ALL ON *.* TO 'admin'@'%'; 不创建用户: 12345678mysql8下试验通过的:use mysqlupdate mysql.user set host = '%' where user = 'root';FLUSH PRIVILEGES;GRANT ALL PRIVILEGES ON *.* TO 'root'@'%'WITH GRANT OPTION; 创建数据库 http://c.biancheng.net/view/2413.html CREATE DATABASE [数据库表] 语句创建数据库 SHOW CREATE DATABASE [数据库表] 查询创建的库 导出导出数据库 mysqldump -u root -pmima [数据库表] &gt; dbname.sql1234561. 格式:mysqldump -u 用户名 -p 数据库名 表名&gt; 导出的文件名 2. 导出所有库:mysqldump -u root -proot --all-databases &gt;/tmp/all.sql 3. 导出几个:mysqldump -u root -proot --databases db1 db2 &gt;/tmp/user.sql4. 导出一个数据库：mysqldump -u root -proot --skip-add-drop-table nacos_config &gt;d:/nacos_config_db.sql5. 只导出结构:加上 -d 6. --skip-add-drop-table 导出的sql创建表之前都会drop 表.加上该参数会不加drop的sql 导入数据库12341. 常用source 命令2. 进入mysql数据库控制台:mysql -u root -p3. mysql&gt;use 数据库4. 然后使用source命令，后面参数为脚本文件(如这里用到的.sql):mysql&gt;source d:/dbname.sql","link":"/2021/05/10/2021/Mysql8%E5%88%9D%E5%A7%8B%E5%8C%96%E6%96%B0%E5%BB%BA%E5%BA%93/"},{"title":"线上JVM运行调试","text":"jvm调试gc部分 jvm的垃圾收集器状态 jmap -heap [pid] 参考文章:内存分配和垃圾收集器1前面几行中标记有使用的垃圾收集器，以及目前各个分代中的使用和剩余 jvm dump堆文件 jmap -dump:format=b,file=[路径].hprof [pid] 手动gc jmap -histo:live [pid] 查看gc的次数和频率 使用jstat。参考文章:java性能调试工具 在实际使用中发现如下的问题。后面在一篇文章有部分说明:参考文章123456789101. 新生代为680M。SurvivorRatio为8。也就是新生区544M，2个幸存区各68M。但结合线上的jmap和jstat中，这个使用内存量会变，幸存区实际再用低于68M，新生区会大于544。原因：使用的是ps新生代垃圾收集器才会是这个问题。parnew则是按照配置来预先分配parallel scavenge新生代中具体分配策略参见： 备注： Parallel Scavenge 收集器 特点：属于新生代收集器也是采用复制算法的收集器，又是并行的多线程收集器（与ParNew收集器类似）。 该收集器的目标是达到一个可控制的吞吐量。还有一个值得关注的点是：GC自适应调节策略(这就是为啥幸存区不是按照比例的来配置大小的原因)（与ParNew收集器最重要的一个区别） GC自适应调节策略：Parallel Scavenge收集器可设置-XX:+UseAdaptiveSizePolicy参数。当开关打开时不需要手动指定新生代的大小（-Xmn）、Eden与Survivor区的比例（-XX:SurvivorRation）、晋升老年代的对象年龄（-XX:PretenureSizeThreshold）等，虚拟机会根据系统的运行状况收集性能监控信息，动态设置这些参数以提供最优的停顿时间和最高的吞吐量，这种调节方式称为GC的自适应调节策略。 Parallel Scavenge收集器使用两个参数控制吞吐量： XX:MaxGCPauseMillis 控制最大的垃圾收集停顿时间 XX:GCRatio 直接设置吞吐量的大小。 jvm更换垃圾收集器 Serial（串行）收集器 -XX:+UseSerialGC Parallel（并行）收集器 -XX:+UseParallelGC -XX:+UseParallelOldGC CMS（并发）收集器 -XX:+UseParNewGC -XX:+UseConcMarkSweepGC 开启G1收集器的方式 -XX:+UseG1GC 组合说明12345-XX:+UseParNewGC = ParNew + SerialOld这个组合已经很少用（在某些版本中已经废弃）-XX:+UseConc(urrent)MarkSweepGC = ParNew + CMS + Serial Old-XX:+UseParallelGC = Parallel Scavenge + Parallel Old (1.8默认) 【PS + SerialOld】-XX:+UseParallelOldGC = Parallel Scavenge + Parallel Old-XX:+UseG1GC = G1 附带截图 jvm内存管理 Java_JVM参数-XX:MaxDirectMemorySize 与 两种 ByteBuffer: heap,direct ByteBuffer（参考：https://www.cnblogs.com/laoqing/p/10380536.html） ByteBuffer有两种: heap ByteBuffer -&gt; -XX:Xmx 1.1、一种是heap ByteBuffer,该类对象分配在JVM的堆内存里面，直接由Java虚拟机负责垃圾回收； direct ByteBuffer -&gt; -XX:MaxDirectMemorySize 1.2、一种是direct ByteBuffer是通过jni在虚拟机外内存中分配的。通过jmap无法查看该快内存的使用情况。只能通过top来看它的内存使用情况。 1.2.1、JVM堆内存大小可以通过-Xmx来设置，同样的direct ByteBuffer可以通过-XX:MaxDirectMemorySize来设置，此参数的含义是当Direct ByteBuffer分配的堆外内存到达指定大小后，即触发Full GC。注意该值是有上限的，默认是64M，最大为sun.misc.VM.maxDirectMemory()，在程序中中可以获得-XX:MaxDirectMemorySize的设置的值。 1.2.2、没有配置MaxDirectMemorySize的，因此MaxDirectMemorySize的大小即等于-Xmx 1.2.3、Direct Memory的回收机制，Direct Memory是受GC控制的 1.2.4、对于使用Direct Memory较多的场景，需要注意下MaxDirectMemorySize的设置，避免-Xmx + Direct Memory超出物理内存大小的现象 常用参数说明 jvm一些常用参数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566-server ## 服务器模式-Xms2g ## 初始化堆内存大小-Xmx2g ## 堆内存最大值-Xmn256m ## 年轻代内存大小，整个JVM内存=年轻代 + 年老代 + 持久代-Xss256k ## 设置每个线程的堆栈大小-XX:PermSize=256m ## 持久代内存大小-XX:MetaspaceSize=21m ## 最大持久代内存大小-XX:MaxMetaspaceSize=21m ## 最大可分配元空间-XX:MaxDirectMemorySize=21m ## 直接内存分配-XX:ReservedCodeCacheSize=256m ## 代码缓存，存储已编译方法生成的本地代码-XX:+UseCodeCacheFlushing ## 代码缓存满时，让JVM放弃一些编译代码-XX:+DisableExplicitGC ## 忽略手动调用GC, System.gc()的调用就会变成一个空调用，完全不触发GC-Xnoclassgc ## 禁用类的垃圾回收，性能会高一点-XX:+UseConcMarkSweepGC ## 并发标记清除（CMS）收集器-XX:+CMSParallelRemarkEnabled ## 启用并行标记，降低标记停顿-XX:+UseParNewGC ## 对年轻代采用多线程并行回收，这样收得快-XX:+UseCMSCompactAtFullCollection ## 在FULL GC的时候对年老代的压缩，Full GC后会进行内存碎片整理，过程无法并发，空间碎片问题没有了，但提顿时间不得不变长了-XX:CMSFullGCsBeforeCompaction=3 ## 多少次Full GC 后压缩old generation一次-XX:LargePageSizeInBytes=128m ## 内存页的大小-XX:+UseFastAccessorMethods ## 原始类型的快速优化-XX:+UseCMSInitiatingOccupancyOnly ## 使用设定的回收阈值(下面指定的70%)开始CMS收集,如果不指定,JVM仅在第一次使用设定值,后续则自动调整-XX:CMSInitiatingOccupancyFraction=70 ## 使用cms作为垃圾回收使用70％后开始CMS收集-XX:SoftRefLRUPolicyMSPerMB=50 ## Soft reference清除频率，默认存活1s,设置为0就是不用就清除-XX:+AlwaysPreTouch ## 强制操作系统把内存真正分配给JVM-XX:+PrintClassHistogram ## 按下Ctrl+Break后，打印类的信息-XX:+PrintGCDetails ## 输出GC详细日志-XX:+PrintGCTimeStamps ## 输出GC的时间戳（以基准时间的形式）-XX:+PrintHeapAtGC ## 在进行GC的前后打印出堆的信息-XX:+PrintGCApplicationConcurrentTime ## 输出GC之间运行了多少时间-XX:+PrintTenuringDistribution ## 参数观察各个Age的对象总大小-XX:+ParallelRefProcEnabled ## 默认为 false，并行的处理 Reference 对象，如 WeakReference，除非在 GC log 里出现 Reference 处理时间较长的日志，否则效果不会很明显。-XX:+PrintGCApplicationStoppedTime ## GC造成应用暂停的时间-Xloggc:../log/gc.log ## 指定GC日志文件的输出路径-ea ## 打开断言机制，jvm默认关闭-Dsun.io.useCanonCaches=false ## java_home没有配置，或配置错误会报异常-Dsun.awt.keepWorkingSetOnMinimize=true ## 可以让IDEA最小化到任务栏时依然保持以占有的内存，当你重新回到IDEA，能够被快速显示，而不是由灰白的界面逐渐显现整个界面，加快回复到原界面的速度-Djava.net.preferIPv4Stack=true ## 让tomcat默认使用IPv4-Djdk.http.auth.tunneling.disabledSchemes=&quot;&quot; ## 等于Basic会禁止proxy使用用户名密码这种鉴权方式,反之空就可以使用-Djsse.enablesSNIExtension=false ## SNI支持，默认开启，开启会造成ssl握手警告-XX:+HeapDumpOnOutOfMemoryError ## 表示当JVM发生OOM时，自动生成DUMP文件-XX:HeapDumpPath=D:/data/log ## 表示生成DUMP文件的路径，也可以指定文件名称，如果不指定文件名，默认为：java_&lt;pid&gt;_&lt;date&gt;_&lt;time&gt;_heapDump.hprof。 -XX:-OmitStackTraceInFastThrow ## 省略异常栈信息从而快速抛出,这个配置抛出这个异常非常快，不用额外分配内存，也不用爬栈,但是出问题看不到stack trace，不利于排查问题-Dfile.encoding=UTF-8-Duser.name=qhong-XX:NewRatio=3 ## 新生代与年老代的比例。比如为3，则新生代占堆的1/4，年老代占3/4。-XX:SurvivorRatio=8 ## 新生代中调整eden区与survivor区的比例，默认为8，即eden区为80%的大小，两个survivor分别为10%的大小。 -XX:PretenureSizeThreshold=10m ## 晋升年老代的对象大小。默认为0，比如设为10M，则超过10M的对象将不在eden区分配，而直接进入年老代。-XX:MaxTenuringThreshold=15 ## 晋升老年代的最大年龄。默认为15，比如设为10，则对象在10次普通GC后将会被放入年老代。-XX:MaxTenuringThreshold=0 ## 垃圾最大年龄，如果设置为0的话,则年轻代对象不经过Survivor区,直接进入年老代，该参数只有在串行GC时才有效-XX:+HeapDumpBeforeFullGC ## 当JVM 执行 FullGC 前执行 dump-XX:+HeapDumpAfterFullGC ## 当JVM 执行 FullGC 后执行 dump-XX:+HeapDumpOnCtrlBreak ## 交互式获取dump。在控制台按下快捷键Ctrl + Break时，JVM就会转存一下堆快照-XX:+PrintGC ## 输出GC日志-verbose:gc ## 同PrintGC,输出GC日志-XX:+PrintGCDateStamps ## 输出GC的时间戳（以日期的形式，如 2013-05-04T21:53:59.234+0800）-XX:+PrintFlagsInitial ## 显示所有可设置参数及默认值 -enablesystemassertions ## 激活系统类的断言-esa ## 同上-disablesystemassertions ## 关闭系统类的断言-dsa ## 同上-XX:+ScavengeBeforeFullGC ## FullGC前回收年轻代内存，默认开启-XX:+CMSScavengeBeforeRemark ## CMS remark前回收年轻代内存 -XX:+CMSIncrementalMode ## 采用增量式的标记方式，减少标记时应用停顿时间-XX:+CMSClassUnloadingEnabled ## 相对于并行收集器，CMS收集器默认不会对永久代进行垃圾回收。如果希望回收，就使用该标志，注意，即使没有设置这个标志，一旦永久代耗尽空间也会尝试进行垃圾回收，但是收集不会是并行的，而再一次进行Full GC-XX:+CMSConcurrentMTEnabled ## 当该标志被启用时，并发的CMS阶段将以多线程执行(因此，多个GC线程","link":"/2021/04/19/2021/JVM%E8%BF%90%E8%A1%8C%E7%AE%A1%E7%90%86%E4%B8%8E%E8%B0%83%E8%AF%95/"},{"title":"Mysql事务开启","text":"//查看当前事物级别：SELECT @@tx_isolation; //设置read uncommitted级别： 未提交读set session transaction isolation level read uncommitted; //设置read committed级别： 已提交读set session transaction isolation level read committed; //设置repeatable read级别： 可重复读set session transaction isolation level repeatable read; //设置serializable级别： 可串行化set session transaction isolation level serializable; 手动开启事务:begin;select xxxcommit;","link":"/2021/04/27/2021/Mysql%E4%BA%8B%E5%8A%A1%E5%BC%80%E5%90%AF/"},{"title":"NACOS源码解读(2.0.0版本)","text":"nacos使用方面概述概述 nacos作用不在赘述直接进入正题。 官网：https://nacos.io/zh-cn/ github： https://github.com/alibaba/nacos 工程简介。 站在前人肩膀，少走弯路，快速切入入口；文章属于较早的，本文解读从2.0.0开始。1234参考文章：1. https://blog.csdn.net/ZhangQingmu/article/details/105212470 2. https://blog.csdn.net/CX610602108/article/details/110099591 3. https://www.cnblogs.com/HendSame-JMZ/p/13046614.html划重点：上述3篇文章仅供参考，实际需要根据自己的版本所建立 nacos-console: nacos主体项目入口和启动项目 nacos-naming: nacos注册发现业务。 nacos-config: nacos的配置中心服务 nacos-api: 用户nacos客户端和服务端进行通信的定义 nacos-client: nacos客户端，进行和服务端通信 nacos-test: 测试用例 启动demo 执行脚本 （MySQL）12create database nacos_config;\\distribution\\conf\\nacos-db.sql IDEA 找到 nacos-console项目并运行 Nacos.java1234567jvm参数配置如下：-Dnacos.standalone=true-DuseAddressServer=false-Ddb.num=1-Ddb.url=jdbc:mysql://localhost:3306/nacos_config-Ddb.user=nacos-Ddb.password=nacos 编译源码jar包启动 选择nacos-distribution项目执行:mvn clean install -Dmaven.test.skip=true -P release-nacos 选择对应的压缩包.进行传输 解压压缩包到bin目录:sh startup.sh -m standalone 如果使用ubuntu或者运行脚本报错提示[[符号找不到，可尝试如下运行:bash startup.sh -m standalone 修改链接数据等前往conf目录. 运行控制台页面 12http://localhost:8848/nacos/index.html#/login用户名密码 nacos/nacos 项目分析解读 nacos-test12345671. 包下面的结构还是挺清晰的，每个不同的模块都会聚集在一个包下面。以下举例config。2. 第一个类：ConfigAPI_CITCase-&gt;nacos_getconfig_13. 测试方法用于一个配置注册和删除，在进行获取。4. 启动该测试类的会启动:Nacos.class（参照上面demo启动）。5. 随后用nacos-client包下的类进行远程调用进行各项方法。总结：test方法会一同启动nacos服务，同时用client进行调用。这里会进行一个全链路的测试。这个一个很好的方法，学习了。 #nacos理念 数据一致性 nacos由AP CP组成混合使用； 临时节点使用AP模式，进行服务端存储，存在在一个Map中 1AP协议：Distro协议。Distro是阿里巴巴的私有协议，目前流行的 Nacos服务管理框架就采用了 Distro协议。Distro 协议被定位为 临时数据的一致性协议 ：该类型协议， 不需要把数据存储到磁盘或者数据库 ，因为临时数据通常和服务器保持一个session会话， 该会话只要存在，数据就不会丢失 。 持久化节点使用CP模式（集群Leader），该数据会序列化进磁盘中。备注：nacos1.4之前使用raft自己实现，之后版本使用了:蚂蚁金服的jraft。 1Raft 适用于一个管理日志一致性的协议，相比于 Paxos 协议 Raft 更易于理解和去实现它。为了提高理解性，Raft 将一致性算法分为了几个部分，包括领导选取（leader selection）、日志复制（log replication）、安全（safety），并且使用了更强的一致性来减少了必须需要考虑的状态。 参考文章:Nacos注册中心设计分析-CP模式(重点) 参考文章：蚂蚁金服开源 SOFAJRaft：生产级 Java Raft 算法库 参考文章:Nacos中Distro协议梳理 参考文章:Nacos 实现 AP+CP原理Raft 算法 参考文章:Raft协议动态图2.0版本 新增gprc。 支持长链接…","link":"/2021/04/14/2021/NACOS%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/"},{"title":"nginx配置HTTP1.x|2","text":"nginx配置nginx概念 nginx反向代理这里不在赘述了. nginx在配置中,默认是用http1.0进行代理的. http1.0在压测中也能发现问题.一旦QPS量大后,会出现很多的time_wait.连接不复用.吞吐量无法提升 nginx1.1的配置 1.1的持久化连接,可以复用是提高吞吐量的秘诀 {PATH}:根据自己的电脑路径设置 {URLDOMIAN}:根据自己需要的域名设置.12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849upstream test-local { server 127.0.0.1:8443; # 配置连接数量,超时时间.线上根据实际情况配置 keepalive 50; keepalive_requests 20;}http配置server { listen 80; server_name {URLDOMIAN}; # 没有可以忽略 access_log {PATH}/local.log; location / { proxy_pass https://test-local; proxy_set_header Connection &quot;keep-alive&quot;; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header Reverse-Proxy nginx; }}# HTTPS server 需要安装https证书server { listen 443 ssl; server_name {URLDOMIAN}; access_log {PATH}/local.log; ssl_certificate {PATH}/localhost_ca.cer; ssl_certificate_key {PATH}/localhost_ca.pvk; # 以下参数根据自己的情况以及服务的量来制定.在后面有部分说明字段的含义 ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; # 必须声明HTTP的版本 proxy_http_version 1.1; location / { proxy_pass https://test-local/; # 中间代理了一层,要告诉服务器,持久化链接 proxy_set_header Connection &quot;keep-alive&quot;; # 以下参数根据实际情况来配置 proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header Reverse-Proxy nginx; }} http2的配置 经过一个空接口压测,http2压测继续比http1.1的吞吐量上升.没有了http头堵塞.但tcp头堵塞还在1234567891011121314151617181920212223242526272829303132333435363738394041424344454647 upstream test-local { server 127.0.0.1:8443; # 配置连接数量,超时时间.线上根据实际情况配置 keepalive 50; keepalive_requests 20;}http配置server { listen 80; server_name {URLDOMIAN}; # 没有可以忽略 access_log {PATH}/local.log; location / { proxy_pass https://test-local; proxy_set_header Connection &quot;keep-alive&quot;; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header Reverse-Proxy nginx; }}# HTTPS server 需要安装https证书server { # 配置一下这个就好了.学会了就很简单 listen 443 ssl http2; server_name {URLDOMIAN}; access_log {PATH}/local.log; ssl_certificate {PATH}/localhost_ca.cer; ssl_certificate_key {PATH}/localhost_ca.pvk; # 以下参数根据自己的情况以及服务的量来制定.在后面有部分说明字段的含义 ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; location / { proxy_pass https://test-local/; # 中间代理了一层,要告诉服务器,持久化链接 proxy_set_header Connection &quot;keep-alive&quot;; # 以下参数根据实际情况来配置 proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header Reverse-Proxy nginx; }} 部分字段说明 禁止不安全的 SSL 协议，使用安全协议:ssl_protocols TLSv1 TLSv1.1 TLSv1.2; 禁止已经不安全的加密算法: ssl_ciphers HIGH:!aNULL:!MD5; (写法百度下) 缓存连接凭据:ssl_session_cache shared:SSL:20m; ssl_session_timeout 60m; 缓解 BEAST 攻击:ssl_prefer_server_ciphers on;","link":"/2021/06/16/2021/NGINX%E9%85%8D%E7%BD%AEHTTP1.x%7C2/"},{"title":"rocketmq安装","text":"官网地址本文使用的是4.9.0 官网12大写的备注:第一次下载的是:rocketmq-all-4.9.0-source-release.zip,想自己编译,编译后运行broker一直抛出链接不上nameserver,一开始怀疑配置,后面重新下载低版本的通过.重新下载回该版本,下载了一个编译的好的包.一运行直接通过了.要么自行编译时候需要改参数(官网没看到).要么编译的代码就有问题.耗时4小时 启动rocketmq 这里是单机测试,修改jvm使用的内存.默认的会占用4+8=12G内存. cd rocketmq-all-4.9.0-bin-release/ vim bin/runserver.sh 和 vim bin/runbroker.sh123找到一行带有设置内存的,修改为下面的一句话runserver : JAVA_OPT=&quot;${JAVA_OPT} -server -Xms512m -Xmx512m -Xmn256m -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m&quot;runbroker : JAVA_OPT=&quot;${JAVA_OPT} -server -Xms1g -Xmx1g -Xmn512m&quot; 开启 Name Server123&gt; nohup sh bin/mqnamesrv &amp;&gt; tail -f ~/logs/rocketmqlogs/namesrv.log The Name Server boot success... 开启Broker12345678 备注:测试中我是在docker中,需要指定一下外网ip&gt; vim conf/broker.conf (加入以下.根据个人需求来定) # brokerIP1和brokerIP2默认获取本地ip地址,在云服务器上会获取内网ip地址,因此必须显式设置 brokerIP1=192.168.0.x brokerIP2=192.168.0.x &gt; nohup sh bin/mqbroker -n 192.168.0.149:9876 -c conf/broker.conf &amp; &gt; tail -f ~/logs/rocketmqlogs/broker.log The broker[%s, 172.30.30.233:10911] boot success... 启动rocketmq console github:https://github.com/apache/rocketmq-externals 进入到文件夹:rocketmq-console123mvn clean package -Dmaven.test.skip=truenohup java -jar target/rocketmq-console-ng-2.0.0.jar &gt; /dev/null 2&gt;&amp;1 &amp;tail -100f ~/logs/consolelogs/rocketmq-console.log 启动后在管理台上有填入集群地址.进行查看","link":"/2021/07/13/2021/RocketMQ%E5%AE%89%E8%A3%85/"},{"title":"Runcher2.0安装","text":"hello word开始 使用的ubuntu 20.04. 安装1.6版本 镜像地址:https://hub.docker.com/r/rancher/server 启动docker:docker run -d –restart=unless-stopped -p 8082:8080 –name rancher1.6 rancher/server 问题 添加主机的时候,如果是单机版本,住下docker-agent的dns错误.可参考下面: https://github.com/rancher/rancher/issues/110812345678我用的是:vim /etc/default/docker# replace# # DOCKER_OPTS=&quot;--dns 8.8.8.8 --dns 8.8.4.4&quot;# byDOCKER_OPTS=&quot;--dns 8.8.8.8 --dns 8.8.4.4&quot;# then restart Docker service docker restar 安装2.5版本 官方中文文档:http://docs.rancher.cn/docs/rancher2.5/installation/other-installation-methods/single-node-docker/_index 安装rancher（v2.5）:直接通过docker镜像来运行我们的rancher，首先，先从镜像中心下载rancher镜像，如果是1.x系列的，镜像名为rancher/server，而2.x是rancher/rancher，我们使用2.x版本的，所以，执行如下命令即可： 1docker pull rancher/rancher 执行如下命令，在宿主机创建两个挂载目录.(根据情况来使用,就只看看不用了); 123mkdir -p /docker_volume/rancher_home/ranchermkdir -p /docker_volume/rancher_home/auditlogmkdir -p /home/rancher/ssl 生成签名证书:http://docs.rancher.cn/docs/rancher2/installation/resources/advanced/self-signed-ssl/_index 1官方文档有很好的解决 接下来我们启动rancher容器:(端口根据自己需要来定义.我这里有其他端口被占用了).2.5版本中docker需要提权加:–privileged 12345678 docker run -d --privileged --restart=unless-stopped \\-p 8081:80 -p 8443:443 \\-e NO_PROXY=&quot;localhost,127.0.0.1,0.0.0.0,10.0.0.0/8,192.168.0.0/24,124.160.111.194&quot; \\-v /home/rancher/ssl:/container/certs \\-e SSL_CERT_DIR=&quot;/container/certs&quot; \\-v /docker_volume/rancher_home/rancher:/var/lib/rancher \\-v /docker_volume/rancher_home/auditlog:/var/log/auditlog \\--name rancher rancher/rancher:v2.5-head 查看日志: 1docker logs -f $ID 单机(测试)使用 端口映射选择集群IP. 高级选项中:网络是用主机网络 rancher如果是1.5版本,网络选择桥接,方便单机中使用.备注: 端口映射的是使用的iptables,非docker的端口映射.这里选择是为了方便,使用其他类型需要做网络转发. rancher重新安装12345678910111213141516171819docker stop $(docker ps -a -q)docker system prune -fdocker volume rm $(docker volume ls -q)docker rm -f $(docker ps -a -q)rm -rf /etc/ceph \\ /etc/cni \\ /etc/kubernetes \\ /opt/cni \\ /opt/rke \\ /run/secrets/kubernetes.io \\ /run/calico \\ /run/flannel \\ /var/lib/calico \\ /var/lib/etcd \\ /var/lib/cni \\ /var/lib/kubelet \\ /var/lib/rancher/rke/log \\ /var/log/containers \\ /var/log/pods \\","link":"/2021/06/26/2021/Runcher%E5%AE%89%E8%A3%85/"},{"title":"SpringCloud系统性能优化","text":"背景 需要对系统进行流程性测试，查找系统瓶颈点所在，当大流量来临能有效应对。现将优化处理方法进行梳理总结，供大家参考学习 系统参数 系统服务名 服务器数量 CPU(核) 内存(G) nginx 2 4 8 gateway 4 8 16 course(不同服务器类型) 2 2 4 course(不同服务器类型) 2 8 64 user 2 2 4 login 2 2 4 数据库1 1 8 16 数据库2 1 8 16 redis 1 2 2 服务器说明：在测试中有直连进行测试，实际测试某一个服务中，未全部使用服务器，会根据测试内容临时下线机器，具体方案会在后续说到。 启动参数中：gateway使用内存配置为4g。 其他应用服务启动参数内存为2g 压测优化点内容gateway优化项 网关核心功能 路由转发 流量计算/限流 统一登录验证 spring cloud gateway文档：https://docs.spring.io/spring-cloud-gateway/docs/2.2.6.RELEASE/reference/html/#gateway-starter -Dreactor.netty.ioWorkerCount=64 问题1：线程数量设置过小。 被压测接口：返回当前系统时间。接口响应平均响应时间在1毫秒不到 压测方法：直连tomcat压测，和通过gateway在连接对比压测 压测QPS：tomcat直连：3W+ 。 gateway链接：1500+ 说明：gateway有进行redis的登录验证操作，耗时在2、3毫秒左右，redis的瓶颈在1W左右 压测过程中，对比后发现gateway服务器的cpu利用率很低，对比发现属于redis验证阻塞了主线程，导致请求无法及时转发。 gateway使用reactor netty进行作为转发框架。默认设置为cpu数量同等线程数，但只适合cpu密集型任务，对于路由转发任务需要调高线程数量，以便于提高cpu利用率参考文章：https://blog.csdn.net/trecn001/article/details/107286396 问题2：登录验证redis存在大key 被压测接口：同问题1一致 压测方法：同问题1一致 压测QPS：同问题1一致 说明：同问题1一致 经过解决问题1后，QPS依然维持在1W左右，通过计算，用户登录后存储在redis中字节数为1388个字节，redis带宽为128Mbit/s。换算后redis的带宽瓶颈为QPS：1W+。去掉中间程序因素，只能维持在1w左右 追踪程序后，用户登录使用的为jwt验证。会将用户所有数据进行加密存储为accessToken和一个refreshToken。参考文章：https://www.cnblogs.com/ruoruchujian/p/11271285.html redis存储信息包含：用户id，用户类型，accessToken,refreshToken,deviceId,jti。同时：根据jwt的规则accessToken加密串已经包含了所有的信息，所以不需要在单独存储。同时查看目前系统登录逻辑refreshToken暂时并没有使用，只是用于一个扩展项。 对登录用户信息进行优化，redis不在存储refreshToken，同时对加密token进行字段缩减。只放入userId，deviceId必要字段，加密串大大减少。缩减后剩余388个字节。redis带宽可同步增长3~4倍 应用服务优化项 spring actuator至性能衰减 华为云redis查询QPS过低排查 spring mvc transactional导致性能瓶颈 应用服务tomcat连接数配置,此项不作说明，需要根据业务系统来定 1234server.tomcat.max-threads=300 // springboot默认是200server.tomcat.accept-count=200 // springboot默认是100server.tomcat.max-connections=8192 // springboot默认是8192 . 1024*8。server.tomcat.min-spare-threads=50 // springboot默认是10 hystrix使用信号量配置减少CPU上下文切换,此项不作说明，需要根据业务系统来定 121. 参考文章：https://blog.csdn.net/dap769815768/article/details/946302762. 系统使用了okhttp，本身有配置相应线程池，不需要在使用hystrix进行线程池。以减少cpu争用 优化总结 在分布式系统中，需要定位问题点，问题点对应了才能进行解决。上面解决方案非常简单，但难点是定位到各个问题点。同时有可能是多不同问题点叠加产生瓶颈。 定位问题中需要进行分解目标点,参考附录大致图中。以下是定位gateway网关的思路。其他接口也可以参照以下思路。使用排除法一步步测试 系统经过第一次的压测，将应用服务进行了优化。随后进行第二轮压测，定位至网关redis瓶颈和线程数。定位过程如下 在前面压测中，由于应用服务存在瓶颈点，一直未打满gateway，导致无法压测出gateway有瓶颈。本次进行全流程的压测，其中有一个响应在几毫秒内的接口。对比tomcat和网关后发现有巨大差异。 压测中需要进行一步步排除差异，第一步：先进行了tomcat压测，排除nginx和gateway，第二步：直连其中一台gateway进行压测，排除nginx，第三步：外网域名压测。 结果对比后第二步有巨大差异，而且波动很大。第三步由于nginx有2台，gateway有4台。在物理设备中有增加，但同时也同第一步的结果差异较大 通过第二步对比tomcat和经过网关在转发的QPS数后,准备了一个不进行登录验证空接口进行测试（下文该接口记录为A），同时网关有进行登录验证，在准备一个需要登录验证的空接口（下文该接口记录为B）。 直接进行tomcat压测，确定应用服务是否存在瓶颈点。对tomcat链接瓶颈疑问直连进行压测。确定tomcat参数正常，不存在相应瓶颈 进行第二步操作细化，先使用了A接口进行压测。对比发现QPS相差较小，由于经过网关一层有相比较有下降，稍QPS少一点为正常现象。 确定了A接口不存在问题。这时候在使用B接口进行测试，运行效果相差特别大。QPS有10的倍数下降。这时候可以确定为网关登录验证出现问题 当前问题进行了细化，网关的登录验证产生瓶颈。这时候定位出2个问题。 首先查看了redis瓶颈，通过监控发现redis没有瓶颈，带宽使用量也不高，那么就确定为redis的客户端也就是gateway存在其他瓶颈。 首先对gateway的redis连接数进行优化，调高参数，进行再次压测。但调高参数发现并没有效果，同时调高的参数并没有被使用上。在细化后瓶颈点不在redis连接获取数据上 对gateway的流程进行梳理，查看开启的线程数量为8个。同时经过跟踪后，redis的操作是在主线程进行。主线程数量不足导致的并发数无法提高 提高主线程并发数量，QPS响应开始以倍数提高。最终测试通过 参考文章:https://www.cnblogs.com/binyue/p/6141088.html","link":"/2021/02/02/2021/SpringCloud%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"},{"title":"jvm垃圾回收讲解","text":"2篇文章 java 虚拟机（ jvm ） 的垃圾收集器的发展史 垃圾收集器 垃圾收集器 zgc jdk8统计gc的使用 (转载) JVM结构、GC工作机制详解 (转载)JVM内存泄漏和溢出 (转载)java类加载机制","link":"/2021/02/23/2021/jvm%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/"},{"title":"SpringMvc启动初始化过程","text":"springmvcweb.xml 配置解释 放在全局中,格式如下 12345&lt;!--全局提前初始化的使用 --&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring-mvc.xml&lt;/param-value&gt; &lt;/context-param&gt; 同spring的dispatchServlet放在一起 1234567891011&lt;!--configure the setting of springmvcDispatcherServlet and configure the mapping --&gt;&lt;!-- 如果把下面注释掉，会默认使用servlet-name的值拼上serlvet。找WEB-INF下的类。--&gt;&lt;servlet&gt; &lt;servlet-name&gt;spring-mvc&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring-mvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt; spring-mvc下的servlet中init-param可以省略掉。如果省略掉会默认使用：servlet-name的value值拼上servlet.xml。如上文则是:(spring-mvc-servlet.xml).查找路径需在WEB-INF下。和web.xml一致 12345678910类名：XmlWebApplicationContext加载文件方法：protected void loadBeanDefinitions(XmlBeanDefinitionReader reader) throws IOException { String[] configLocations = getConfigLocations(); if (configLocations != null) { for (String configLocation : configLocations) { reader.loadBeanDefinitions(configLocation); } }} springmvc的差别(谁加载了context-param的参数?) servelt的init-param的contextConfigLocation是为了加载DispatcherServlet的. 而context-param参数 的applicationContext.xm是为了加载web程序需要加载的数据库等等配置。 问题 问题一：放context-param和init-param区别? Context-param（上下文参数），在这个元素中可以定义多个组成的键值对，但是要注意这里定义的键值对作用于是application，而且在有些应用中会提前定义自己的键值对，所以可以通过这种方式配置某些技术，同时这里也可以自定义一些参数，然后在业务逻辑中使用。获取键值对的方式如下 1ServletContextEvent .getServletContext().getInitParameter(&quot;urlrewrite&quot;); 的作用范围则是当前对应的Servlet，只有对应的Servlet才能够调用到，有些提前定义的Servlet中也会判断是否有某些配置的键值对，如果有则根据配置的键值对处理逻辑，没有则根据默认的逻辑处理，同时也可以自定义键值对在后期自定义的Servlet当中使用。获取键值对的方式如下 1this.getInitParameter(&quot;param1&quot;) 备注： 注意以上两者获取键值对的方式的区别，第一个必须获取ServletContext之后才能够获取，因为第一个的键值对属于整个应用，而第二个则是通过this获取，因为这里获取的键值对仅仅属于当前的Servlet。 流程 启动一个WEB项目的时候,容器(如:Tomcat)会去读它的配置文件web.xml.读两个节点:和 紧接着,容器创建一个ServletContext(上下文),这个WEB项目所有部分都将共享这个上下文. 容器将转化为键值对,并交给ServletContext. 容器创建中的类实例,即创建监听. 在监听中会有contextInitialized(ServletContextEvent args)初始化方法,在这个方法中获得ServletContext =ServletContextEvent.getServletContext();context-param的值 =ServletContext.getInitParameter(“context-param的键”); 得到这个context-param的值之后,你就可以做一些操作了.注意,这个时候你的WEB项目还没有完全启动完成.这个动作会比所有的Servlet都要早.换句话说,这个时候,你对中的键值做的操作,将在你的WEB项目完全启动之前被执行. 举例.你可能想在项目启动之前就打开数据库.那么这里就可以在中设置数据库的连接方式,在监听类中初始化数据库的连接. 这个监听是自己写的一个类,除了初始化方法,它还有销毁方法.用于关闭应用前释放资源.比如说数据库连接的关闭. 1234567891011如:&lt;!-- 加载spring的配置文件 --&gt;&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;/WEB-INF/applicationContext.xml,/WEB-INF/action-servlet.xml,/WEB-INF/jason-servlet.xml&lt;/param-value&gt;&lt;/context-param&gt;&lt;listener&gt;&lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;&lt;/listener&gt;","link":"/2021/05/21/2021/springmvc%E5%90%AF%E5%8A%A8%E5%88%9D%E5%A7%8B%E5%8C%96%E8%BF%87%E7%A8%8B/"},{"title":"微博热搜的实现","text":"微博实现原理 网上没有具体的，看该内容涉及几个词。也进行一个总结记录 抽样检查 1用于计算和存储相关数据 热词排名方法一：贝叶斯平均法（Bayesian average)/热词排名法二：牛顿冷却定律 1已关键字进行求值分数,在用优先级队列进行求TOP","link":"/2021/04/26/2021/%E5%BE%AE%E5%8D%9A%E7%83%AD%E6%90%9C%E5%AE%9E%E7%8E%B0/"},{"title":"linux限制目录大小","text":"概念解读 linux没有磁盘分区,新建镜像处理 方法如下 dd if=/dev/zero of=/root/disk1.img bs=1M count=10 // 1M*10=10M zero 是dev下的文件，创建镜像1这里进行创建镜像,需要大小根据自己的需求制定,bs是区块,一个区块大小.count是10个块. losetup /dev/loop10 /root/disk1.img // 挂载硬盘为/dev/loop11这里要自己查找一下可用的回环设备./dev/loop为linux的回环设备,losetup /dev/loop0~x.一个个试一下为空的就可以用.也可以直接fdisk -l查看哪个没有 mkfs.ext3 /dev/loop1 // 格式化文件系统1格式化系统 mkdir /test1 // 创建文件 mount /dev/loop10 /data // 挂载硬盘，/test1目录的容量为20M 1挂载设备 卸载方法如下 umount test11卸载设备 losetup -d /dev/loop1 1删除挂载镜像","link":"/2021/09/07/2021/Ubuntu%E9%99%90%E5%88%B6%E7%9B%AE%E5%BD%95%E5%A4%A7%E5%B0%8F/"},{"title":"web基础学习和动态编译","text":"web框架加载过程记录 项目使用了gradle,为springmvc的结构.当前进行调试测试用例, gradle使用tomcat运行,类打包了到了build的目录,同时idea设置的自动编译目录为out目录.这里就出现一个问题,热部署时候类不在一起,不过发现类会在2个目录存在,估计为同时会产生编译 1maven项目的为target目录.同时idea也会设置成这个.猜想maven自行设置的 springmvc项目进行test用例时候运行,找不到WEB-INF下的资源.这就回到编译目录来看,运行的测试环境使用的是选择的是idea,不是gradle.所以WEB-INF不在范围内.1gradle中有单独参数设置webapp目录project.webAppDirName springboot的maven项目如何结合servlet. 1231. Application中添加@ServletComponentScan2. 定义一个类贴上注解:@WebServlet(name = &quot;MyServlet&quot;,urlPatterns = &quot;/myServlet&quot;).这时候可以使用普通的servlet3. 普通servlet堆栈信息很简单,这时候如果要用filter需要使用原生的注解,可以百度,这里不在赘述 动态编译 idea有自带动态编译的功能,在tomcat或者springboot类的on aciont中选择:update class and resources 121. 这里需要注意你的如果是gradle项目,注意你选择对你的项目编译采用的gradle还是idea.2. gradle默认的编译目录不一致,有可能会导致热部署失效,注意检查一下. 使用三方工具arthas.优秀的一款工具,具体使用可以参照说明文档. springmvc和springboot以及servlet springmvc只是需要指定webapp路径 springboot已经使用了servlet3.0+ 可以使用注解来进行,不要再配置web.xml 如果项目需要springboot但同时又需要web.xml的.更改springboot的注册方式(存疑)","link":"/2021/05/28/2021/web%E5%9F%BA%E7%A1%80%E7%90%86%E8%A7%A3%E5%92%8C%E5%8A%A8%E6%80%81%E7%BC%96%E8%AF%91/"},{"title":"性能优化","text":"spring mvc transactional导致性能瓶颈 华为云redis带宽限制 spring actuator至性能瓶颈(https://www.shuzhiduo.com/A/rV57PbN9dP/) 优化项：tomcat进行并发配置 hystrix信号量配置减少CPU上下文切换","link":"/2021/01/23/2021/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"},{"title":"数据一致性协议","text":"数据一致性协议 raft协议图解网站 Paxos协议 使用 实际使用中会有参考然后重新实现或者变种 zab协议，zookeeper使用。根据paxos协议而来","link":"/2021/04/09/2021/%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%E5%8D%8F%E8%AE%AE/"},{"title":"数据库存储概念","text":"数据存储区别OLTP &amp; OLAP TIDB(行列交换) TiDB 行式与列式 行式存储VS列式存储 处理海量数据：列式存储综述（存储篇） 写入性能高 写入性能高理解：顺序写入，使用LSM树，利用内存将随机写转换为顺序写。小树合并为大树。（ES）","link":"/2021/05/06/2021/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AD%98%E5%82%A8%E6%A6%82%E5%BF%B5/"},{"title":"树型结构数据与应用","text":"算法类 Aho-Corasick算法 11. 进行全文匹配关键字，比如：敏感词匹配。需要预处理数据 Boyer- Moore算法 11. 字符串查找。需要预处理数据 KMP算法 11. 字符串查找。需要预处理数据 Manacher算法 11. 中心扩展，计算最长回文子串。需要辅助空间 树(字符串类) 字典树(前缀树) 11. 利用字符串的公共前缀来减少无谓的字符串比较以达到提高查询效率的目的 后缀树 11. 快速解决很多关于字符串的问题；百度上说，具体应用待学习 编码类 霍夫曼编码(哈夫曼树) 11. 压缩数据存储，需要辅助空间。 树遍历构造 二叉树遍历：前序，中序，后序，Morris 树构造：状态机 知识界限 个人理解，以下内容在于多多学习，学习其中思想理念，能够在使用中想到有什么解决方案。","link":"/2021/05/11/2021/%E6%A0%91%E5%9E%8B%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95%E5%BA%94%E7%94%A8/"},{"title":"概念理解","text":"概念解读 http://upheart.cn/ https://juejin.cn/post/6960478730300948494?utm_source=gold_browser_extension mysql的锁和mysql的隔离级别的关系。有哪些锁 Innodb中的事务隔离级别和锁的关系 深入理解MySQL锁类型和加锁原理备注： mysql RR级别已经利用mvcc解决了幻读 mysql一条查询语句干了啥 一条 select 语句MySQL怎么做 grpc的特性 聊聊gRPC的特性和背后设计的原则(一) 聊聊gRPC的接口描述语言ProtoBuffer（二） gRPC之流式调用原理http2协议分析1文中有一句HACK压缩头算法，写错了是HPACK 服务器load的分析与排查 cpu load过高问题排查 kafka性能高原因 什么场景选用什么mq java线程释放原理1线程中断，运行结束 java的syc锁升级原理，轻量级什么锁，重量级什么锁 轻量级锁、重量级锁 juc下面有什么包？引入queue的问题 cas aqs 限流算法怎么做 tcp连接的状态 TCP连接及11种状态总结 LockSupport的理解 LockSupport：一个很灵活的线程工具类","link":"/2021/04/27/2021/%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E6%A6%82%E5%BF%B5%E7%90%86%E8%A7%A3/"},{"title":"问题故障解析","text":"mq故障 事故现象：服务开始出现请求缓慢，进而系统全面崩溃 1234568:00，收到系统故障提醒,并立即进行故障的排查； 8:00至16:00，分析问题，从CPU、内存、连接数量、系统日志等进行分析均未发现明显异常，尝试各种解决方案，包括限流、熔断、服务降级、服务重启等均无法有效解决； 16:00, 发现到消息队列服务器有阻塞现象，对消息队列服务器进行重启； 16:30，完成所有相关的服务器重启，系统恢复正常，并开始验证服务的稳定性； 17:20，对外恢复服务； 问题出现原因。 123451. 出现问题原因在于生产者发送消息过快，mq出现消息堆积，同时消费者处理过慢。2. 由于消息持续堆积引发了rabbitmq自己的保护机制，开始阻塞生产者写入消息。3. 生产者开启的是线程，线程被阻塞无法释放，线程不断开启，重启服务后没过几分钟服务又开始宕机。4. 虽然看见mq消费堆积，服务重启后依然在不断消费，所以还未察觉到是mq有问题。5. mq的阻塞写入造成一个循环，消费慢，写入快，系统服务级联反应。造成系统持续不可用。 执行过程。 12341. 线上出现问题，第一要点保证服务尽快可用。2. 对于中间件重启，第一要点恢复数据，防止数据丢失。3. mq由于本次消费堆积，进行了和相应业务方对接，对mq消息进行区分。哪些可以直接删除(需要参照业务)。哪些重新导出写脚本进行补偿。4. mq重启后服务一切正常，系统恢复可用状态 rabbitmq阻塞说明:https://cloud.tencent.com/developer/article/1454194 1234567891. 因为RabbitMQ服务器在启动时会计算系统内存总大小。然后会根据vm_memory_high_watermark参数指定的百分比，进行控制2. 当RabbitMQ的磁盘空闲空间小于50M（默认），生产者将被BLOCK，并且阻塞信息发布前，会尝试把内存中的信息输出到磁盘上``` # redis故障1. 事故现象：个别服务大量redis timeout。导致涉及缓存接口不可用。```$xslt1. 重启redis，数据抓紧恢复，影响1小时 问题出现原因。本次问题出现为3个原因进行叠加。1231. redis存在大量的大key，导致redis服务的压力过大。2. 中间件的不合理，由于开发者不了解jedis，对jedis在外面在包装一个线程池，导致线程池套用线程池。redis服务的tcp连接非常多。3. redis目前为共享一个，线上服务多。最终问题出现压垮了redis。","link":"/2021/03/26/2021/%E7%BA%BF%E4%B8%8AMQ%E5%92%8Credis%E6%95%85%E9%9A%9C%E8%AE%B0%E5%BD%95/"},{"title":"系统重构的构想","text":"系统重构的构想重构前的确认 为什么要重构?1当前哪里不满意,需要进行重构.重构的原因是什么?要花多久?如何进行,方案是什么? 重构带来影响是什么?1重构能解决什么问题,不重构能解决吗?重构后业务会有什么变化 重构后有什么好处1重构能带什么好处,有什么提升,对业务?对技术? 问题的答案需要根据当前系统进行寻找,总体来说我认为有以下几点: 开发的效率提升,能够引入更方便引入相关脚手架 经过不断的迭代,项目中越来越臃肿,耦合度越来越深.当修改一项内容必然涉及很多功能.界限无法理清 重构进行中 重构之路 技术改造 升级当前的依赖和相关jar包 改变当前的整体框架内容.对整体变革 业务改造 相关不同业务进行剥离 未完","link":"/2021/06/09/2021/%E7%B3%BB%E7%BB%9F%E9%87%8D%E6%9E%84%E7%9A%84%E6%9E%84%E6%83%B3/"},{"title":"mysql-extra字段说明","text":"EXPLAIN字段说明执行explain中字段extra的含义。执行效率从上到下依次递减 using index ：使用覆盖索引的时候就会出现 using where：在查找使用索引的情况下，需要回表去查询所需的数据 using index condition：查找使用了索引，但是需要回表查询数据 using index &amp; using where：查找使用了索引，但是需要的数据都在索引列中能找到，所以不需要回表查询数据 using filesort 是通过相应的排序算法,将取得的数据在内存中进行排序:。 12345MySQL需要将数据在内存中进行排序，所使用的内存区域也就是我们通过sort_buffer_size 系统变量所设置的排序区。这个排序区是每个Thread 独享的，所以说可能在同一时刻在MySQL 中可能存在多个 sort buffer 内存区域。在MySQL中filesort 的实现算法实际上是有两种：双路排序：是首先根据相应的条件取出相应的排序字段和可以直接定位行数据的行指针信息，然后在sort buffer 中进行排序。单路排序：是一次性取出满足条件行的所有字段，然后在sort buffer中进行排序。 执行explain中字段type的含义。执行效率从上到下依次递减 system：系统表，少量数据，往往不需要进行磁盘IO const：常量连接 eq_ref：主键索引(primary key)或者非空唯一索引(unique not null)等值扫描 ref：非主键非唯一索引等值扫描 range：范围扫描 index：索引树扫描 ALL：全表扫描(full table scan)","link":"/2020/06/05/2020/mysqlExplain/"},{"title":"java线程池参数说明","text":"java线程池ThreadPoolExecutor来窥探线程池核心类的构造函数，我们需要理解每一个参数的作用，才能理解线程池的工作原理。 123456789public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) { ...... } corePoolSize：保留在池中的线程数，即使它们空闲，除非设置了 allowCoreThreadTimeOut，不然不会关闭。 maximumPoolSize：队列满后池中允许的最大线程数。 keepAliveTime、TimeUnit：如果线程数大于核心数，多余的空闲线程的保持的最长时间会被销毁。unit 是 keepAliveTime 参数的时间单位。当设置 allowCoreThreadTimeOut(true) 时，线程池中 corePoolSize 范围内的线程空闲时间达到 keepAliveTime 也将回收。 workQueue：当线程数达到 corePoolSize 后，新增的任务就放到工作队列 workQueue 里，而线程池中的线程则努力地从 workQueue 里拉活来干，也就是调用 poll 方法来获取任务。 ThreadFactory：创建线程的工厂，比如设置是否是后台线程、线程名等。 RejectedExecutionHandler：拒绝策略，处理程序因为达到了线程界限和队列容量执行拒绝策略。也可以自定义拒绝策略，只要实现 RejectedExecutionHandler 即可。默认的拒绝策略：AbortPolicy 拒绝任务并抛出 RejectedExecutionException 异常；CallerRunsPolicy 提交该任务的线程执行； 来分析下每个参数之间的关系：提交新任务的时候，如果线程池数 &lt; corePoolSize，则创建新的线程池执行任务，当线程数 = corePoolSize 时，新的任务就会被放到工作队列 workQueue 中，线程池中的线程尽量从队列里取任务来执行。如果任务很多，workQueue 满了，且 当前线程数 &lt; maximumPoolSize 时则临时创建线程执行任务，如果总线程数量超过 maximumPoolSize，则不再创建线程，而是执行拒绝策略。DiscardPolicy 什么都不做直接丢弃任务；DiscardOldestPolicy 丢弃最旧的未处理程序; tomcat线程池定制版的 ThreadPoolExecutor，继承了 java.util.concurrent.ThreadPoolExecutor。 对于线程池有两个很关键的参数： 线程个数。队列长度。 Tomcat 必然需要限定想着两个参数不然在高并发场景下可能导致 CPU 和内存有资源耗尽的风险。继承了 与 java.util.concurrent.ThreadPoolExecutor 相同，但实现的效率更高。其构造方法如下，跟 Java 官方的如出一辙 1234public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, RejectedExecutionHandler handler) { super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, handler); prestartAllCoreThreads(); } 在 Tomcat 中控制线程池的组件是 StandardThreadExecutor , 也是实现了生命周期接口，下面是启动线程池的代码 12345678910111213141516@Override protected void startInternal() throws LifecycleException { // 自定义任务队列 taskqueue = new TaskQueue(maxQueueSize); // 自定义线程工厂 TaskThreadFactory tf = new TaskThreadFactory(namePrefix,daemon,getThreadPriority()); // 创建定制版线程池 executor = new ThreadPoolExecutor(getMinSpareThreads(), getMaxThreads(), maxIdleTime, TimeUnit.MILLISECONDS,taskqueue, tf); executor.setThreadRenewalDelay(threadRenewalDelay); if (prestartminSpareThreads) { executor.prestartAllCoreThreads(); } taskqueue.setParent(executor); // 观察者模式，发布启动事件 setState(LifecycleState.STARTING); } 其中的关键点在于： Tomcat 有自己的定制版任务队列和线程工厂，并且可以限制任务队列的长度，它的最大长度是 maxQueueSize。Tomcat 对线程数也有限制，设置了核心线程数（minSpareThreads）和最大线程池数（maxThreads）。 除此之外， Tomcat 在官方原有基础上重新定义了自己的线程池处理流程，原生的处理流程上文已经说过。 前 corePoolSize 个任务时，来一个任务就创建一个新线程。还有任务提交，直接放到队列，队列满了，但是没有达到最大线程池数则创建临时线程救火。线程总线数达到 maximumPoolSize ，直接执行拒绝策略。 Tomcat 线程池扩展了原生的 ThreadPoolExecutor，通过重写 execute 方法实现了自己的任务处理逻辑： 前 corePoolSize 个任务时，来一个任务就创建一个新线程。还有任务提交，直接放到队列，队列满了，但是没有达到最大线程池数则创建临时线程救火。线程总线数达到 maximumPoolSize ，继续尝试把任务放到队列中。如果队列也满了，插入任务失败，才执行拒绝策略。 最大的差别在于 Tomcat 在线程总数达到最大数时，不是立即执行拒绝策略，而是再尝试向任务队列添加任务，添加失败后再执行拒绝策略。代码如下所示: 1234567891011121314151617181920212223242526272829public void execute(Runnable command, long timeout, TimeUnit unit) { // 记录提交任务数 +1 submittedCount.incrementAndGet(); try { // 调用 java 原生线程池来执行任务，当原生抛出拒绝策略 super.execute(command); } catch (RejectedExecutionException rx) { //总线程数达到 maximumPoolSize，Java 原生会执行拒绝策略 if (super.getQueue() instanceof TaskQueue) { final TaskQueue queue = (TaskQueue)super.getQueue(); try { // 尝试把任务放入队列中 if (!queue.force(command, timeout, unit)) { submittedCount.decrementAndGet(); // 队列还是满的，插入失败则执行拒绝策略 throw new RejectedExecutionException(&quot;Queue capacity is full.&quot;); } } catch (InterruptedException x) { submittedCount.decrementAndGet(); throw new RejectedExecutionException(x); } } else { // 提交任务书 -1 submittedCount.decrementAndGet(); throw rx; } }} Tomcat 线程池是用 submittedCount 来维护已经提交到了线程池，这跟 Tomcat 的定制版的任务队列有关。Tomcat 的任务队列 TaskQueue 扩展了 Java 中的 LinkedBlockingQueue，我们知道 LinkedBlockingQueue 默认情况下长度是没有限制的，除非给它一个 capacity。因此 Tomcat 给了它一个 capacity，TaskQueue 的构造函数中有个整型的参数 capacity，TaskQueue 将 capacity 传给父类 LinkedBlockingQueue 的构造函数，防止无限添加任务导致内存溢出。而且默认是无限制，就会导致当前线程数达到核心线程数之后，再来任务的话线程池会把任务添加到任务队列，并且总是会成功，这样永远不会有机会创建新线程了。为了解决这个问题，TaskQueue 重写了 LinkedBlockingQueue 的 offer 方法，在合适的时机返回 false，返回 false 表示任务添加失败，这时线程池会创建新的线程。 123456789101112131415161718192021222324252627public class TaskQueue extends LinkedBlockingQueue&lt;Runnable&gt; { ... @Override // 线程池调用任务队列的方法时，当前线程数肯定已经大于核心线程数了 public boolean offer(Runnable o) { // 如果线程数已经到了最大值，不能创建新线程了，只能把任务添加到任务队列。 if (parent.getPoolSize() == parent.getMaximumPoolSize()) return super.offer(o); // 执行到这里，表明当前线程数大于核心线程数，并且小于最大线程数。 // 表明是可以创建新线程的，那到底要不要创建呢？分两种情况： //1. 如果已提交的任务数小于当前线程数，表示还有空闲线程，无需创建新线程 if (parent.getSubmittedCount()&lt;=(parent.getPoolSize())) return super.offer(o); //2. 如果已提交的任务数大于当前线程数，线程不够用了，返回 false 去创建新线程 if (parent.getPoolSize()&lt;parent.getMaximumPoolSize()) return false; // 默认情况下总是把任务添加到任务队列 return super.offer(o); }} 只有当前线程数大于核心线程数、小于最大线程数，并且已提交的任务个数大于当前线程数时，也就是说线程不够用了，但是线程数又没达到极限，才会去创建新的线程。这就是为什么 Tomcat 需要维护已提交任务数这个变量，它的目的就是在任务队列的长度无限制的情况下，让线程池有机会创建新的线程。可以通过设置 maxQueueSize 参数来限制任务队列的长度。","link":"/2020/08/20/2020/javaThread/"},{"title":"mysql事务理解","text":"mysql知识点事务的说明探讨参考：1 mysql知识点 事务四大特征：原子性，一致性，隔离性和持久性(ACID) 12这 4 条特性，是事务管理的基石，一定要透彻理解。此外还要明确，这四个家伙当中，谁才是最终目标？理解：原子性是基础，隔离性是手段，持久性是目的，最终目标就是一致性。数据不一致了，就相当于数据错位了。所以说，这三个小弟都是跟着“一致性”这个老大混，为他全心全意服务。 mysql隔离级别：是为了处理事务中隔离性的工具 12345SQL标准定义的四个隔离级别为： READ UNCOMMITTED READ COMMITTED REPEATABLE READ SERIALIZABLE","link":"/2020/10/10/2020/mysql%E4%BA%8B%E5%8A%A1%E7%90%86%E8%A7%A3/"},{"title":"中型系统的技术知识","text":"需要掌握的系统知识中级需要具备 进阶（高级系统,未学习）等待补充 中间件的大规模使用 双A 高可用","link":"/2020/06/23/2020/%E4%B8%AD%E5%9E%8B%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%8A%80%E6%9C%AF%E7%9F%A5%E8%AF%86/"},{"title":"前缀树","text":"定义问题描述： 字典树(前缀树)Trie树，即字典树，又称单词查找树或键树，是一种树形结构，是一种哈希树的变种。典型应用是用于统计和排序大量的字符串（但不仅限于字符串），所以经常被搜索引擎系统用于文本词频统计。它的优点是：最大限度地减少无谓的字符串比较，查询效率比哈希表高。 Trie的核心思想是空间换时间。利用字符串的公共前缀来降低查询时间的开销以达到提高效率的目的。 1234它有3个基本性质： 根节点不包含字符，除根节点外每一个节点都只包含一个字符。 从根节点到某一节点，路径上经过的字符连接起来，为该节点对应的字符串。 每个节点的所有子节点包含的字符都不相同。 Aho-Corasick算法 应用 java敏感词过滤实现","link":"/2020/10/15/2020/%E5%89%8D%E7%BC%80%E6%A0%91/"},{"title":"布隆过滤器","text":"定义 布隆过滤器（Bloom Filter）是1970年由布隆提出的。它实际上是一个很长的二进制向量和一系列随机映射函数。布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都比一般的算法要好的多，缺点是有一定的误识别率和删除困难。 优点 12相比于其它的数据结构，布隆过滤器在空间和时间方面都有巨大的优势。布隆过滤器存储空间和插入/查询时间都是常数。另外, Hash函数相互之间没有关系，方便由硬件并行实现。布隆过滤器不需要存储元素本身，在某些对保密要求非常严格的场合有优势。布隆过滤器可以表示全集，其它任何数据结构都不能。 缺点 123但是布隆过滤器的缺点和优点一样明显。误算率是其中之一。随着存入的元素数量增加，误算率随之增加。常见的补救办法是建立一个小的白名单，存储那些可能被误判的元素。但是如果元素数量太少，则使用散列表足矣。另外，一般情况下不能从布隆过滤器中删除元素。我们很容易想到把位列阵变成整数数组，每插入一个元素相应的计数器加1, 这样删除元素时将计数器减掉就可以了。然而要保证安全的删除元素并非如此简单。首先我们必须保证删除的元素的确在布隆过滤器里面. 这一点单凭这个过滤器是无法保证的。另外计数器回绕也会造成问题。在降低误算率方面，有不少工作，使得出现了很多布隆过滤器的变种。 应用 网页URL的去重，垃圾邮件的判别，集合重复元素的判别，查询加速（比如基于key-value的存储系统）、数据库防止查询击穿， 使用BloomFilter来减少不存在的行或列的磁盘查找。","link":"/2020/10/15/2020/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/"},{"title":"快速连接","text":"首页 其他工具 mysql激活,优秀一个人 githubXX-Net https://github.com/btpka3/btpka3.github.com https://github.com/btpka3/btpka3.github.com/tree/master/js/angular/my-angular-webpack 线上调试必备 JVM性能调试 JVM死循环定位 java开发 (转载)spring cloud eureka asciiflow1这玩意画出来的图是可以直接复制成文本的，控制好尺寸就可以解决大部分情况，也可以想象之前网上有一些很奇葩的注释是不是就是用这个工具或者同样的原理画出来的，附上一副之前文章缺的一张图： 数据/协议 raft协议图解网站 可视化数据结构演示网站 倒排索引&amp;正排索引 reids第二版文章 elasticsearch和mongodb对比 rabbitmq精选讲解 mongodb采用B树理解 synchronized原理和锁膨胀过程 优秀 美团精选 儒猿技术窝 计算和存储分离","link":"/2020/06/24/2020/%E6%94%B6%E8%97%8F%E7%BD%91%E5%9D%80%E9%93%BE%E6%8E%A5/"},{"title":"数据结构与算法在线演示网站","text":"演示网站DataStructureVisualizations一个数据可视化和算法可视化的网站，用它可以生成各种各样的数据结构，模拟它们添加和删除的过程，而且还可以用它来演示算法的执行过程。 地址 VisuAlgo此网站包含了更多的算法，这个从首页就可以看出来，不仅如此，它还支持关键字检索 地址 algorithm-visualizer此网站也支持很多算法，并且此网站提供算法的具体代码实现，它支持的语言有：Java，C++，JS 等，还有控制台也会输出整个执行的过程，能帮你更好的理解算法 地址","link":"/2020/06/23/2020/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E5%9C%A8%E7%BA%BF%E6%BC%94%E7%A4%BA%E7%BD%91%E7%AB%99/"},{"title":"无限极分类设计","text":"方案一(Adjacency List) 1. 文章说明 1. 文章说明 1. 文章说明 方案二(Path Enumeration) 方案三(Nested Sets) 文章说明 方案四(Closure Table)","link":"/2020/08/27/2020/%E6%97%A0%E9%99%90%E6%9E%81%E5%88%86%E7%B1%BB%E8%AE%BE%E8%AE%A1/"},{"title":"java线程池状态","text":"Java线程不同状态下中断机制的效果 状态 中断效果 描述NEW 无 RUNNABLE 设置中断标志位 用户自己判断是否中断，以及如何处理 BLOCKED 设置中断标志位 用户自己判断是否中断，以及如何处理 WAITING 抛InterruptedException异常，并清空中断标志位 TIMED_WAITING 抛InterruptedException异常，并清空中断标志位 TERMINATED 死亡状态","link":"/2021/03/18/2020/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"},{"title":"马拉车算法（Manacher）","text":"算法讲解 1234567891011121314151617算法解决的问题是求最长回文子串。给定一个字符串 s，找到 s 中最长的回文子串。你可以假设 s 的最大长度为 1000。示例 1：输入: &quot;babad&quot;输出: &quot;bab&quot;注意: &quot;aba&quot; 也是一个有效答案。示例 2：输入: &quot;cbbd&quot;输出: &quot;bb&quot;来源：力扣（LeetCode）链接：https://leetcode-cn.com/problems/longest-palindromic-substring著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 类似解法还有：中心扩散法。该方法时间复杂度为O(n2)。马拉车算法降低到n","link":"/2020/08/27/2020/%E9%A9%AC%E6%8B%89%E8%BD%A6%E7%AE%97%E6%B3%95/"},{"title":"网络基础","text":"网络tcp/ip使用协议 网络osi模型作用 tcp协议解析 各层常用协议","link":"/2020/10/09/2020/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"刷题","slug":"刷题","link":"/tags/%E5%88%B7%E9%A2%98/"},{"name":"笔记","slug":"笔记","link":"/tags/%E7%AC%94%E8%AE%B0/"},{"name":"nodeJs","slug":"nodeJs","link":"/tags/nodeJs/"},{"name":"java开发","slug":"java开发","link":"/tags/java%E5%BC%80%E5%8F%91/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"java开发工具","slug":"java开发工具","link":"/tags/java%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"},{"name":"grails&#x2F;groovy","slug":"grails-groovy","link":"/tags/grails-groovy/"},{"name":"xcode","slug":"xcode","link":"/tags/xcode/"},{"name":"存储层","slug":"存储层","link":"/tags/%E5%AD%98%E5%82%A8%E5%B1%82/"},{"name":"协议&#x2F;算法&#x2F;数据","slug":"协议-算法-数据","link":"/tags/%E5%8D%8F%E8%AE%AE-%E7%AE%97%E6%B3%95-%E6%95%B0%E6%8D%AE/"},{"name":"源码解读","slug":"源码解读","link":"/tags/%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB/"},{"name":"快速访问","slug":"快速访问","link":"/tags/%E5%BF%AB%E9%80%9F%E8%AE%BF%E9%97%AE/"},{"name":"网络基础","slug":"网络基础","link":"/tags/%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/"}],"categories":[{"name":"leetcode","slug":"leetcode","link":"/categories/leetcode/"},{"name":"性能","slug":"性能","link":"/categories/%E6%80%A7%E8%83%BD/"},{"name":"spring","slug":"spring","link":"/categories/spring/"}]}